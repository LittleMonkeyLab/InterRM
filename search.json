[
  {
    "objectID": "week00/chapter.html",
    "href": "week00/chapter.html",
    "title": "Chapter 2 - Week 2 Stuff",
    "section": "",
    "text": "insert week 2 stuff",
    "crumbs": [
      "Schedule",
      "Content",
      "Week00",
      "Chapter 2 - Week 2 Stuff"
    ]
  },
  {
    "objectID": "week00/chapter.html#week-2-stuff",
    "href": "week00/chapter.html#week-2-stuff",
    "title": "Chapter 2 - Week 2 Stuff",
    "section": "",
    "text": "insert week 2 stuff",
    "crumbs": [
      "Schedule",
      "Content",
      "Week00",
      "Chapter 2 - Week 2 Stuff"
    ]
  },
  {
    "objectID": "week00/chapter 2.html",
    "href": "week00/chapter 2.html",
    "title": "Chapter 2 - Week 2 Stuff",
    "section": "",
    "text": "insert week 2 stuff",
    "crumbs": [
      "Schedule",
      "Content",
      "Week00",
      "Chapter 2 - Week 2 Stuff"
    ]
  },
  {
    "objectID": "week00/chapter 2.html#week-2-stuff",
    "href": "week00/chapter 2.html#week-2-stuff",
    "title": "Chapter 2 - Week 2 Stuff",
    "section": "",
    "text": "insert week 2 stuff",
    "crumbs": [
      "Schedule",
      "Content",
      "Week00",
      "Chapter 2 - Week 2 Stuff"
    ]
  },
  {
    "objectID": "webexercises.html",
    "href": "webexercises.html",
    "title": "Psychology of Deception: Web Exercises",
    "section": "",
    "text": "This is a Web Exercise template created by the psychology teaching team at the University of Glasgow, based on ideas from Software Carpentry. This template shows how instructors can easily create interactive web documents that students can use in self-guided learning.\nThe {webexercises} package provides a number of functions that you use in inline R code or through code chunk options to create HTML widgets (text boxes, pull down menus, buttons that reveal hidden content). Examples are given below. Render this file to HTML to see how it works.\nNOTE: To use the widgets in the compiled HTML file, you need to have a JavaScript-enabled browser.",
    "crumbs": [
      "Schedule",
      "Content",
      "Psychology of Deception: Web Exercises"
    ]
  },
  {
    "objectID": "webexercises.html#example-questions",
    "href": "webexercises.html#example-questions",
    "title": "Psychology of Deception: Web Exercises",
    "section": "Example Questions",
    "text": "Example Questions\n\nFill-In-The-Blanks (fitb())\nCreate fill-in-the-blank questions using fitb(), providing the answer as the first argument.\n\n2 + 2 is \n\nYou can also create these questions dynamically, using variables from your R session.\n\nThe square root of 36 is: \n\nThe blanks are case-sensitive; if you don’t care about case, use the argument ignore_case = TRUE.\n\nWhat is the letter after D? \n\nIf you want to ignore differences in whitespace use, use the argument ignore_ws = TRUE (which is the default) and include spaces in your answer anywhere they could be acceptable.\n\nHow do you load the tidyverse package? \n\nYou can set more than one possible correct answer by setting the answers as a vector.\n\nType a vowel: \n\nYou can use regular expressions to test answers against more complex rules.\n\nType any 3 letters: \n\n\n\nMultiple Choice (mcq())\n\n“Never gonna give you up, never gonna: let you goturn you downrun awaylet you down”\n“I bless the rainsguess it rainssense the rain down in Africa” -Toto\n\n\n\nTrue or False (torf())\n\nTrue or False? You can permute values in a vector using sample(). TRUEFALSE\n\n\n\nLonger MCQs (longmcq())\nWhen your answers are very long, sometimes a drop-down select box gets formatted oddly. You can use longmcq() to deal with this. Since the answers are long, It’s probably best to set up the options inside an R chunk with echo=FALSE.\nWhat is a p-value?\n\n the probability that the null hypothesis is true the probability of the observed, or more extreme, data, under the assumption that the null-hypothesis is true the probability of making an error in your conclusion\n\nWhat is true about a 95% confidence interval of the mean?\n\n if you repeated the process many times, 95% of intervals calculated in this way contain the true mean there is a 95% probability that the true mean lies within this range 95% of the data fall within this range",
    "crumbs": [
      "Schedule",
      "Content",
      "Psychology of Deception: Web Exercises"
    ]
  },
  {
    "objectID": "webexercises.html#checked-sections",
    "href": "webexercises.html#checked-sections",
    "title": "Psychology of Deception: Web Exercises",
    "section": "Checked sections",
    "text": "Checked sections\nCreate sections with the class webex-check to add a button that hides feedback until it is pressed. Add the class webex-box to draw a box around the section (or use your own styles).\n\nI am going to learn a lot: TRUEFALSE\nWhat is a p-value?\n\n the probability that the null hypothesis is true the probability of the observed, or more extreme, data, under the assumption that the null-hypothesis is true the probability of making an error in your conclusion",
    "crumbs": [
      "Schedule",
      "Content",
      "Psychology of Deception: Web Exercises"
    ]
  },
  {
    "objectID": "webexercises.html#hidden-solutions-and-hints",
    "href": "webexercises.html#hidden-solutions-and-hints",
    "title": "Psychology of Deception: Web Exercises",
    "section": "Hidden solutions and hints",
    "text": "Hidden solutions and hints\nYou can fence off a solution area that will be hidden behind a button using hide() before the solution and unhide() after, each as inline R code. Pass the text you want to appear on the button to the hide() function.\nIf the solution is a code chunk, instead of using hide() and unhide(), simply set the webex.hide chunk option to TRUE, or set it to the string you wish to display on the button.\nRecreate the scatterplot below, using the built-in cars dataset.\n\n\n\n\n\n\n\n\n\n\n\nI need a hint\n\nSee the documentation for plot() (?plot)\n\n\n\n\n\nClick here to see the solution\n\nplot(cars$speed, cars$dist)\n\n\nThis set of exercises will test your knowledge about various aspects of deception in psychology. Answer the questions to check your understanding of key concepts, theories, and research findings in this area.",
    "crumbs": [
      "Schedule",
      "Content",
      "Psychology of Deception: Web Exercises"
    ]
  },
  {
    "objectID": "webexercises.html#fill-in-the-blanks",
    "href": "webexercises.html#fill-in-the-blanks",
    "title": "Psychology of Deception: Web Exercises",
    "section": "Fill-In-The-Blanks",
    "text": "Fill-In-The-Blanks\n\nThe tendency for people to believe they are less likely to be deceived than others is known as the  to deception.\nIn deception research, the  is an actor who works with the experimenter to deceive the actual participant.\nThe  is a genuine smile that involves both the mouth and the eyes, making it harder to fake in deceptive situations.",
    "crumbs": [
      "Schedule",
      "Content",
      "Psychology of Deception: Web Exercises"
    ]
  },
  {
    "objectID": "webexercises.html#multiple-choice",
    "href": "webexercises.html#multiple-choice",
    "title": "Psychology of Deception: Web Exercises",
    "section": "Multiple Choice",
    "text": "Multiple Choice\n\nWhich of the following is NOT typically considered a reliable indicator of deception?\n\nIncreased blinkingReduced hand gesturesLack of eye contactIncreased speech errors\n\nThe theory that proposes that lying is more cognitively demanding than telling the truth is called:\n\nInterpersonal Deception TheoryCognitive Load TheoryFour-Factor TheorySelf-Presentation Theory\n\nIn a typical deception study, who is usually unaware of the true nature of the experiment?\n\nParticipantExperimenterConfederateResearch Assistant",
    "crumbs": [
      "Schedule",
      "Content",
      "Psychology of Deception: Web Exercises"
    ]
  },
  {
    "objectID": "webexercises.html#true-or-false",
    "href": "webexercises.html#true-or-false",
    "title": "Psychology of Deception: Web Exercises",
    "section": "True or False",
    "text": "True or False\n\nPolygraph tests are highly accurate and widely accepted in scientific communities as reliable lie detectors. TRUEFALSE\nPeople are generally better at detecting lies told by strangers than by those close to them. TRUEFALSE\nMicroexpressions are brief, involuntary facial expressions that can potentially reveal concealed emotions in deceptive situations. TRUEFALSE",
    "crumbs": [
      "Schedule",
      "Content",
      "Psychology of Deception: Web Exercises"
    ]
  },
  {
    "objectID": "webexercises.html#longer-mcqs",
    "href": "webexercises.html#longer-mcqs",
    "title": "Psychology of Deception: Web Exercises",
    "section": "Longer MCQs",
    "text": "Longer MCQs\nWhich of the following best describes the “Truth-Default Theory” in deception research?\n\n The theory that humans are naturally inclined to always tell the truth The theory that humans tend to believe others are telling the truth unless given reason to think otherwise The theory that truth-telling is easier and requires less cognitive effort than lying The theory that cultural norms universally prioritize truthfulness over deception\n\nWhat is the primary focus of Interpersonal Deception Theory (IDT)?\n\n The neurological processes involved in creating and maintaining a lie The psychological motivations that drive individuals to engage in deceptive behavior The dynamic interaction between the deceiver and the target of deception The cultural variations in perceptions and acceptance of deceptive practices",
    "crumbs": [
      "Schedule",
      "Content",
      "Psychology of Deception: Web Exercises"
    ]
  },
  {
    "objectID": "webexercises.html#checked-sections-1",
    "href": "webexercises.html#checked-sections-1",
    "title": "Psychology of Deception: Web Exercises",
    "section": "Checked sections",
    "text": "Checked sections\n\nResearch suggests that detecting deception is:\nEasy for most peopleOnly possible with specialized trainingDifficult, with accuracy rates often only slightly above chanceImpossible without technological aids\nExplain why detecting deception is challenging for most people:\n\n\nClick for explanation\n\nDetecting deception is challenging for several reasons:\n\nMany common beliefs about deception cues (e.g., lack of eye contact) are not reliable indicators.\nLiars often strategically control their behavior to appear truthful.\nIndividual differences in baseline behavior make it hard to identify deviations.\nThe cognitive load of trying to detect lies can impair judgment.\nConfirmation bias can lead people to interpret ambiguous cues in line with their expectations.",
    "crumbs": [
      "Schedule",
      "Content",
      "Psychology of Deception: Web Exercises"
    ]
  },
  {
    "objectID": "webexercises.html#hidden-solutions-and-hints-1",
    "href": "webexercises.html#hidden-solutions-and-hints-1",
    "title": "Psychology of Deception: Web Exercises",
    "section": "Hidden solutions and hints",
    "text": "Hidden solutions and hints\nA researcher wants to study how cognitive load affects lying behavior. Describe a potential experimental design to investigate this.\n\n\nI need a hint\n\nConsider how you might manipulate cognitive load (e.g., through a secondary task) and measure lying behavior. Think about what control conditions you might need.\n\n\n\n\nClick here to see a possible experimental design\n\n# Possible Experimental Design:\n\n# Participants: 100 adults randomly assigned to two groups (50 each)\n# \n# Procedure:\n# 1. All participants are asked to lie about a recent experience\n# \n# 2. Experimental group: \n#    - Must count backwards from 100 by 7s while lying (high cognitive load)\n# \n# 3. Control group:\n#    - Simply lie without additional task (normal cognitive load)\n# \n# 4. Measure dependent variables:\n#    - Speech hesitations\n#    - Speech rate\n#    - Amount of detail provided\n#    - Perceived believability (rated by independent judges)\n# \n# 5. Compare measures between groups to assess the effect of cognitive load on lying behavior\n\n# This design allows us to isolate the effect of increased cognitive load on various aspects of lying behavior.\n\n\nThis set of exercises covers various aspects of deception psychology, including theories, research methods, and key findings. It utilizes different question types to engage learners and test their understanding of the subject matter.",
    "crumbs": [
      "Schedule",
      "Content",
      "Psychology of Deception: Web Exercises"
    ]
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "funny",
    "section": "",
    "text": "content\n\n\ncontent",
    "crumbs": [
      "Schedule",
      "Content",
      "funny"
    ]
  },
  {
    "objectID": "schedule.html#this-is-a-subhead",
    "href": "schedule.html#this-is-a-subhead",
    "title": "funny",
    "section": "",
    "text": "content",
    "crumbs": [
      "Schedule",
      "Content",
      "funny"
    ]
  },
  {
    "objectID": "DataSkills/dataskills09.html",
    "href": "DataSkills/dataskills09.html",
    "title": "DataSkill 9: Data management and organization",
    "section": "",
    "text": "This session focuses on Data management and organization and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 9: Data management and organization"
    ]
  },
  {
    "objectID": "DataSkills/dataskills09.html#skill-overview",
    "href": "DataSkills/dataskills09.html#skill-overview",
    "title": "DataSkill 9: Data management and organization",
    "section": "",
    "text": "This session focuses on Data management and organization and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 9: Data management and organization"
    ]
  },
  {
    "objectID": "DataSkills/dataskills09.html#learning-objectives",
    "href": "DataSkills/dataskills09.html#learning-objectives",
    "title": "DataSkill 9: Data management and organization",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this session, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 9: Data management and organization"
    ]
  },
  {
    "objectID": "DataSkills/dataskills09.html#key-concepts",
    "href": "DataSkills/dataskills09.html#key-concepts",
    "title": "DataSkill 9: Data management and organization",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 9: Data management and organization"
    ]
  },
  {
    "objectID": "DataSkills/dataskills09.html#practical-exercise",
    "href": "DataSkills/dataskills09.html#practical-exercise",
    "title": "DataSkill 9: Data management and organization",
    "section": "Practical Exercise",
    "text": "Practical Exercise\n[Brief description of a hands-on exercise related to Data management and organization]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 9: Data management and organization"
    ]
  },
  {
    "objectID": "DataSkills/dataskills09.html#tips-and-best-practices",
    "href": "DataSkills/dataskills09.html#tips-and-best-practices",
    "title": "DataSkill 9: Data management and organization",
    "section": "Tips and Best Practices",
    "text": "Tips and Best Practices\n\n[Tip 1]\n[Tip 2]\n[Tip 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 9: Data management and organization"
    ]
  },
  {
    "objectID": "DataSkills/dataskills09.html#additional-resources",
    "href": "DataSkills/dataskills09.html#additional-resources",
    "title": "DataSkill 9: Data management and organization",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n[Resource 1: e.g., software download link, tutorial video, etc.]\n[Resource 2]\n[Resource 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 9: Data management and organization"
    ]
  },
  {
    "objectID": "DataSkills/dataskills09.html#reflection-questions",
    "href": "DataSkills/dataskills09.html#reflection-questions",
    "title": "DataSkill 9: Data management and organization",
    "section": "Reflection Questions",
    "text": "Reflection Questions\n\nHow might Data management and organization enhance your research capabilities?\nWhat challenges did you face when learning about or applying Data management and organization?\nHow could you integrate Data management and organization into your current or future research projects?",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 9: Data management and organization"
    ]
  },
  {
    "objectID": "DataSkills/dataskills05.html",
    "href": "DataSkills/dataskills05.html",
    "title": "DataSkill 5: Survey design and data consideration",
    "section": "",
    "text": "This session focuses on Survey design and data consideration and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 5: Survey design and data consideration"
    ]
  },
  {
    "objectID": "DataSkills/dataskills05.html#skill-overview",
    "href": "DataSkills/dataskills05.html#skill-overview",
    "title": "DataSkill 5: Survey design and data consideration",
    "section": "",
    "text": "This session focuses on Survey design and data consideration and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 5: Survey design and data consideration"
    ]
  },
  {
    "objectID": "DataSkills/dataskills05.html#learning-objectives",
    "href": "DataSkills/dataskills05.html#learning-objectives",
    "title": "DataSkill 5: Survey design and data consideration",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this session, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 5: Survey design and data consideration"
    ]
  },
  {
    "objectID": "DataSkills/dataskills05.html#key-concepts",
    "href": "DataSkills/dataskills05.html#key-concepts",
    "title": "DataSkill 5: Survey design and data consideration",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 5: Survey design and data consideration"
    ]
  },
  {
    "objectID": "DataSkills/dataskills05.html#practical-exercise",
    "href": "DataSkills/dataskills05.html#practical-exercise",
    "title": "DataSkill 5: Survey design and data consideration",
    "section": "Practical Exercise",
    "text": "Practical Exercise\n[Brief description of a hands-on exercise related to Survey design and data consideration]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 5: Survey design and data consideration"
    ]
  },
  {
    "objectID": "DataSkills/dataskills05.html#tips-and-best-practices",
    "href": "DataSkills/dataskills05.html#tips-and-best-practices",
    "title": "DataSkill 5: Survey design and data consideration",
    "section": "Tips and Best Practices",
    "text": "Tips and Best Practices\n\n[Tip 1]\n[Tip 2]\n[Tip 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 5: Survey design and data consideration"
    ]
  },
  {
    "objectID": "DataSkills/dataskills05.html#additional-resources",
    "href": "DataSkills/dataskills05.html#additional-resources",
    "title": "DataSkill 5: Survey design and data consideration",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n[Resource 1: e.g., software download link, tutorial video, etc.]\n[Resource 2]\n[Resource 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 5: Survey design and data consideration"
    ]
  },
  {
    "objectID": "DataSkills/dataskills05.html#reflection-questions",
    "href": "DataSkills/dataskills05.html#reflection-questions",
    "title": "DataSkill 5: Survey design and data consideration",
    "section": "Reflection Questions",
    "text": "Reflection Questions\n\nHow might Survey design and data consideration enhance your research capabilities?\nWhat challenges did you face when learning about or applying Survey design and data consideration?\nHow could you integrate Survey design and data consideration into your current or future research projects?",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 5: Survey design and data consideration"
    ]
  },
  {
    "objectID": "DataSkills/dataskills01.html",
    "href": "DataSkills/dataskills01.html",
    "title": "DataSkill 1: Introduction to reference management software",
    "section": "",
    "text": "This session focuses on Introduction to reference management software and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 1: Introduction to reference management software"
    ]
  },
  {
    "objectID": "DataSkills/dataskills01.html#skill-overview",
    "href": "DataSkills/dataskills01.html#skill-overview",
    "title": "DataSkill 1: Introduction to reference management software",
    "section": "",
    "text": "This session focuses on Introduction to reference management software and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 1: Introduction to reference management software"
    ]
  },
  {
    "objectID": "DataSkills/dataskills01.html#learning-objectives",
    "href": "DataSkills/dataskills01.html#learning-objectives",
    "title": "DataSkill 1: Introduction to reference management software",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this session, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 1: Introduction to reference management software"
    ]
  },
  {
    "objectID": "DataSkills/dataskills01.html#key-concepts",
    "href": "DataSkills/dataskills01.html#key-concepts",
    "title": "DataSkill 1: Introduction to reference management software",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 1: Introduction to reference management software"
    ]
  },
  {
    "objectID": "DataSkills/dataskills01.html#practical-exercise",
    "href": "DataSkills/dataskills01.html#practical-exercise",
    "title": "DataSkill 1: Introduction to reference management software",
    "section": "Practical Exercise",
    "text": "Practical Exercise\n[Brief description of a hands-on exercise related to Introduction to reference management software]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 1: Introduction to reference management software"
    ]
  },
  {
    "objectID": "DataSkills/dataskills01.html#tips-and-best-practices",
    "href": "DataSkills/dataskills01.html#tips-and-best-practices",
    "title": "DataSkill 1: Introduction to reference management software",
    "section": "Tips and Best Practices",
    "text": "Tips and Best Practices\n\n[Tip 1]\n[Tip 2]\n[Tip 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 1: Introduction to reference management software"
    ]
  },
  {
    "objectID": "DataSkills/dataskills01.html#additional-resources",
    "href": "DataSkills/dataskills01.html#additional-resources",
    "title": "DataSkill 1: Introduction to reference management software",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n[Resource 1: e.g., software download link, tutorial video, etc.]\n[Resource 2]\n[Resource 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 1: Introduction to reference management software"
    ]
  },
  {
    "objectID": "DataSkills/dataskills01.html#reflection-questions",
    "href": "DataSkills/dataskills01.html#reflection-questions",
    "title": "DataSkill 1: Introduction to reference management software",
    "section": "Reflection Questions",
    "text": "Reflection Questions\n\nHow might Introduction to reference management software enhance your research capabilities?\nWhat challenges did you face when learning about or applying Introduction to reference management software?\nHow could you integrate Introduction to reference management software into your current or future research projects?",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 1: Introduction to reference management software"
    ]
  },
  {
    "objectID": "DataSkills/dataskills17.html",
    "href": "DataSkills/dataskills17.html",
    "title": "DataSkill 17: Creating tables and visualizations",
    "section": "",
    "text": "This session focuses on Creating tables and visualizations and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 17: Creating tables and visualizations"
    ]
  },
  {
    "objectID": "DataSkills/dataskills17.html#skill-overview",
    "href": "DataSkills/dataskills17.html#skill-overview",
    "title": "DataSkill 17: Creating tables and visualizations",
    "section": "",
    "text": "This session focuses on Creating tables and visualizations and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 17: Creating tables and visualizations"
    ]
  },
  {
    "objectID": "DataSkills/dataskills17.html#learning-objectives",
    "href": "DataSkills/dataskills17.html#learning-objectives",
    "title": "DataSkill 17: Creating tables and visualizations",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this session, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 17: Creating tables and visualizations"
    ]
  },
  {
    "objectID": "DataSkills/dataskills17.html#key-concepts",
    "href": "DataSkills/dataskills17.html#key-concepts",
    "title": "DataSkill 17: Creating tables and visualizations",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 17: Creating tables and visualizations"
    ]
  },
  {
    "objectID": "DataSkills/dataskills17.html#practical-exercise",
    "href": "DataSkills/dataskills17.html#practical-exercise",
    "title": "DataSkill 17: Creating tables and visualizations",
    "section": "Practical Exercise",
    "text": "Practical Exercise\n[Brief description of a hands-on exercise related to Creating tables and visualizations]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 17: Creating tables and visualizations"
    ]
  },
  {
    "objectID": "DataSkills/dataskills17.html#tips-and-best-practices",
    "href": "DataSkills/dataskills17.html#tips-and-best-practices",
    "title": "DataSkill 17: Creating tables and visualizations",
    "section": "Tips and Best Practices",
    "text": "Tips and Best Practices\n\n[Tip 1]\n[Tip 2]\n[Tip 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 17: Creating tables and visualizations"
    ]
  },
  {
    "objectID": "DataSkills/dataskills17.html#additional-resources",
    "href": "DataSkills/dataskills17.html#additional-resources",
    "title": "DataSkill 17: Creating tables and visualizations",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n[Resource 1: e.g., software download link, tutorial video, etc.]\n[Resource 2]\n[Resource 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 17: Creating tables and visualizations"
    ]
  },
  {
    "objectID": "DataSkills/dataskills17.html#reflection-questions",
    "href": "DataSkills/dataskills17.html#reflection-questions",
    "title": "DataSkill 17: Creating tables and visualizations",
    "section": "Reflection Questions",
    "text": "Reflection Questions\n\nHow might Creating tables and visualizations enhance your research capabilities?\nWhat challenges did you face when learning about or applying Creating tables and visualizations?\nHow could you integrate Creating tables and visualizations into your current or future research projects?",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 17: Creating tables and visualizations"
    ]
  },
  {
    "objectID": "DataSkills/dataskills15.html",
    "href": "DataSkills/dataskills15.html",
    "title": "DataSkill 15: Pre-Registration and Registered Reports",
    "section": "",
    "text": "This session focuses on Pre-Registration and Registered Reports and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 15: Pre-Registration and Registered Reports"
    ]
  },
  {
    "objectID": "DataSkills/dataskills15.html#skill-overview",
    "href": "DataSkills/dataskills15.html#skill-overview",
    "title": "DataSkill 15: Pre-Registration and Registered Reports",
    "section": "",
    "text": "This session focuses on Pre-Registration and Registered Reports and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 15: Pre-Registration and Registered Reports"
    ]
  },
  {
    "objectID": "DataSkills/dataskills15.html#learning-objectives",
    "href": "DataSkills/dataskills15.html#learning-objectives",
    "title": "DataSkill 15: Pre-Registration and Registered Reports",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this session, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 15: Pre-Registration and Registered Reports"
    ]
  },
  {
    "objectID": "DataSkills/dataskills15.html#key-concepts",
    "href": "DataSkills/dataskills15.html#key-concepts",
    "title": "DataSkill 15: Pre-Registration and Registered Reports",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 15: Pre-Registration and Registered Reports"
    ]
  },
  {
    "objectID": "DataSkills/dataskills15.html#practical-exercise",
    "href": "DataSkills/dataskills15.html#practical-exercise",
    "title": "DataSkill 15: Pre-Registration and Registered Reports",
    "section": "Practical Exercise",
    "text": "Practical Exercise\n[Brief description of a hands-on exercise related to Pre-Registration and Registered Reports]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 15: Pre-Registration and Registered Reports"
    ]
  },
  {
    "objectID": "DataSkills/dataskills15.html#tips-and-best-practices",
    "href": "DataSkills/dataskills15.html#tips-and-best-practices",
    "title": "DataSkill 15: Pre-Registration and Registered Reports",
    "section": "Tips and Best Practices",
    "text": "Tips and Best Practices\n\n[Tip 1]\n[Tip 2]\n[Tip 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 15: Pre-Registration and Registered Reports"
    ]
  },
  {
    "objectID": "DataSkills/dataskills15.html#additional-resources",
    "href": "DataSkills/dataskills15.html#additional-resources",
    "title": "DataSkill 15: Pre-Registration and Registered Reports",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n[Resource 1: e.g., software download link, tutorial video, etc.]\n[Resource 2]\n[Resource 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 15: Pre-Registration and Registered Reports"
    ]
  },
  {
    "objectID": "DataSkills/dataskills15.html#reflection-questions",
    "href": "DataSkills/dataskills15.html#reflection-questions",
    "title": "DataSkill 15: Pre-Registration and Registered Reports",
    "section": "Reflection Questions",
    "text": "Reflection Questions\n\nHow might Pre-Registration and Registered Reports enhance your research capabilities?\nWhat challenges did you face when learning about or applying Pre-Registration and Registered Reports?\nHow could you integrate Pre-Registration and Registered Reports into your current or future research projects?",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 15: Pre-Registration and Registered Reports"
    ]
  },
  {
    "objectID": "DataSkills/dataskills11.html",
    "href": "DataSkills/dataskills11.html",
    "title": "DataSkill 11: Qualitative data analysis software (e.g., NVivo)",
    "section": "",
    "text": "This session focuses on Qualitative data analysis software (e.g., NVivo) and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 11: Qualitative data analysis software (e.g., NVivo)"
    ]
  },
  {
    "objectID": "DataSkills/dataskills11.html#skill-overview",
    "href": "DataSkills/dataskills11.html#skill-overview",
    "title": "DataSkill 11: Qualitative data analysis software (e.g., NVivo)",
    "section": "",
    "text": "This session focuses on Qualitative data analysis software (e.g., NVivo) and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 11: Qualitative data analysis software (e.g., NVivo)"
    ]
  },
  {
    "objectID": "DataSkills/dataskills11.html#learning-objectives",
    "href": "DataSkills/dataskills11.html#learning-objectives",
    "title": "DataSkill 11: Qualitative data analysis software (e.g., NVivo)",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this session, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 11: Qualitative data analysis software (e.g., NVivo)"
    ]
  },
  {
    "objectID": "DataSkills/dataskills11.html#key-concepts",
    "href": "DataSkills/dataskills11.html#key-concepts",
    "title": "DataSkill 11: Qualitative data analysis software (e.g., NVivo)",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 11: Qualitative data analysis software (e.g., NVivo)"
    ]
  },
  {
    "objectID": "DataSkills/dataskills11.html#practical-exercise",
    "href": "DataSkills/dataskills11.html#practical-exercise",
    "title": "DataSkill 11: Qualitative data analysis software (e.g., NVivo)",
    "section": "Practical Exercise",
    "text": "Practical Exercise\n[Brief description of a hands-on exercise related to Qualitative data analysis software (e.g., NVivo)]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 11: Qualitative data analysis software (e.g., NVivo)"
    ]
  },
  {
    "objectID": "DataSkills/dataskills11.html#tips-and-best-practices",
    "href": "DataSkills/dataskills11.html#tips-and-best-practices",
    "title": "DataSkill 11: Qualitative data analysis software (e.g., NVivo)",
    "section": "Tips and Best Practices",
    "text": "Tips and Best Practices\n\n[Tip 1]\n[Tip 2]\n[Tip 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 11: Qualitative data analysis software (e.g., NVivo)"
    ]
  },
  {
    "objectID": "DataSkills/dataskills11.html#additional-resources",
    "href": "DataSkills/dataskills11.html#additional-resources",
    "title": "DataSkill 11: Qualitative data analysis software (e.g., NVivo)",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n[Resource 1: e.g., software download link, tutorial video, etc.]\n[Resource 2]\n[Resource 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 11: Qualitative data analysis software (e.g., NVivo)"
    ]
  },
  {
    "objectID": "DataSkills/dataskills11.html#reflection-questions",
    "href": "DataSkills/dataskills11.html#reflection-questions",
    "title": "DataSkill 11: Qualitative data analysis software (e.g., NVivo)",
    "section": "Reflection Questions",
    "text": "Reflection Questions\n\nHow might Qualitative data analysis software (e.g., NVivo) enhance your research capabilities?\nWhat challenges did you face when learning about or applying Qualitative data analysis software (e.g., NVivo)?\nHow could you integrate Qualitative data analysis software (e.g., NVivo) into your current or future research projects?",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 11: Qualitative data analysis software (e.g., NVivo)"
    ]
  },
  {
    "objectID": "DataSkills/dataskills04.html",
    "href": "DataSkills/dataskills04.html",
    "title": "DataSkill 4: Qualtrics, Python & Gorilla for Psychology",
    "section": "",
    "text": "This session focuses on Qualtrics, Python & Gorilla for Psychology and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 4: Qualtrics, Python & Gorilla for Psychology"
    ]
  },
  {
    "objectID": "DataSkills/dataskills04.html#skill-overview",
    "href": "DataSkills/dataskills04.html#skill-overview",
    "title": "DataSkill 4: Qualtrics, Python & Gorilla for Psychology",
    "section": "",
    "text": "This session focuses on Qualtrics, Python & Gorilla for Psychology and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 4: Qualtrics, Python & Gorilla for Psychology"
    ]
  },
  {
    "objectID": "DataSkills/dataskills04.html#learning-objectives",
    "href": "DataSkills/dataskills04.html#learning-objectives",
    "title": "DataSkill 4: Qualtrics, Python & Gorilla for Psychology",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this session, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 4: Qualtrics, Python & Gorilla for Psychology"
    ]
  },
  {
    "objectID": "DataSkills/dataskills04.html#key-concepts",
    "href": "DataSkills/dataskills04.html#key-concepts",
    "title": "DataSkill 4: Qualtrics, Python & Gorilla for Psychology",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 4: Qualtrics, Python & Gorilla for Psychology"
    ]
  },
  {
    "objectID": "DataSkills/dataskills04.html#practical-exercise",
    "href": "DataSkills/dataskills04.html#practical-exercise",
    "title": "DataSkill 4: Qualtrics, Python & Gorilla for Psychology",
    "section": "Practical Exercise",
    "text": "Practical Exercise\n[Brief description of a hands-on exercise related to Qualtrics, Python & Gorilla for Psychology]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 4: Qualtrics, Python & Gorilla for Psychology"
    ]
  },
  {
    "objectID": "DataSkills/dataskills04.html#tips-and-best-practices",
    "href": "DataSkills/dataskills04.html#tips-and-best-practices",
    "title": "DataSkill 4: Qualtrics, Python & Gorilla for Psychology",
    "section": "Tips and Best Practices",
    "text": "Tips and Best Practices\n\n[Tip 1]\n[Tip 2]\n[Tip 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 4: Qualtrics, Python & Gorilla for Psychology"
    ]
  },
  {
    "objectID": "DataSkills/dataskills04.html#additional-resources",
    "href": "DataSkills/dataskills04.html#additional-resources",
    "title": "DataSkill 4: Qualtrics, Python & Gorilla for Psychology",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n[Resource 1: e.g., software download link, tutorial video, etc.]\n[Resource 2]\n[Resource 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 4: Qualtrics, Python & Gorilla for Psychology"
    ]
  },
  {
    "objectID": "DataSkills/dataskills04.html#reflection-questions",
    "href": "DataSkills/dataskills04.html#reflection-questions",
    "title": "DataSkill 4: Qualtrics, Python & Gorilla for Psychology",
    "section": "Reflection Questions",
    "text": "Reflection Questions\n\nHow might Qualtrics, Python & Gorilla for Psychology enhance your research capabilities?\nWhat challenges did you face when learning about or applying Qualtrics, Python & Gorilla for Psychology?\nHow could you integrate Qualtrics, Python & Gorilla for Psychology into your current or future research projects?",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 4: Qualtrics, Python & Gorilla for Psychology"
    ]
  },
  {
    "objectID": "DataSkills/dataskills12.html",
    "href": "DataSkills/dataskills12.html",
    "title": "DataSkill 12: Text analysis and coding",
    "section": "",
    "text": "This session focuses on Text analysis and coding and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 12: Text analysis and coding"
    ]
  },
  {
    "objectID": "DataSkills/dataskills12.html#skill-overview",
    "href": "DataSkills/dataskills12.html#skill-overview",
    "title": "DataSkill 12: Text analysis and coding",
    "section": "",
    "text": "This session focuses on Text analysis and coding and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 12: Text analysis and coding"
    ]
  },
  {
    "objectID": "DataSkills/dataskills12.html#learning-objectives",
    "href": "DataSkills/dataskills12.html#learning-objectives",
    "title": "DataSkill 12: Text analysis and coding",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this session, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 12: Text analysis and coding"
    ]
  },
  {
    "objectID": "DataSkills/dataskills12.html#key-concepts",
    "href": "DataSkills/dataskills12.html#key-concepts",
    "title": "DataSkill 12: Text analysis and coding",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 12: Text analysis and coding"
    ]
  },
  {
    "objectID": "DataSkills/dataskills12.html#practical-exercise",
    "href": "DataSkills/dataskills12.html#practical-exercise",
    "title": "DataSkill 12: Text analysis and coding",
    "section": "Practical Exercise",
    "text": "Practical Exercise\n[Brief description of a hands-on exercise related to Text analysis and coding]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 12: Text analysis and coding"
    ]
  },
  {
    "objectID": "DataSkills/dataskills12.html#tips-and-best-practices",
    "href": "DataSkills/dataskills12.html#tips-and-best-practices",
    "title": "DataSkill 12: Text analysis and coding",
    "section": "Tips and Best Practices",
    "text": "Tips and Best Practices\n\n[Tip 1]\n[Tip 2]\n[Tip 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 12: Text analysis and coding"
    ]
  },
  {
    "objectID": "DataSkills/dataskills12.html#additional-resources",
    "href": "DataSkills/dataskills12.html#additional-resources",
    "title": "DataSkill 12: Text analysis and coding",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n[Resource 1: e.g., software download link, tutorial video, etc.]\n[Resource 2]\n[Resource 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 12: Text analysis and coding"
    ]
  },
  {
    "objectID": "DataSkills/dataskills12.html#reflection-questions",
    "href": "DataSkills/dataskills12.html#reflection-questions",
    "title": "DataSkill 12: Text analysis and coding",
    "section": "Reflection Questions",
    "text": "Reflection Questions\n\nHow might Text analysis and coding enhance your research capabilities?\nWhat challenges did you face when learning about or applying Text analysis and coding?\nHow could you integrate Text analysis and coding into your current or future research projects?",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 12: Text analysis and coding"
    ]
  },
  {
    "objectID": "DataSkills/dataskills14.html",
    "href": "DataSkills/dataskills14.html",
    "title": "DataSkill 14: Open Science Foundation & Arxiv",
    "section": "",
    "text": "This session focuses on Open Science Foundation & Arxiv and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 14: Open Science Foundation & Arxiv"
    ]
  },
  {
    "objectID": "DataSkills/dataskills14.html#skill-overview",
    "href": "DataSkills/dataskills14.html#skill-overview",
    "title": "DataSkill 14: Open Science Foundation & Arxiv",
    "section": "",
    "text": "This session focuses on Open Science Foundation & Arxiv and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 14: Open Science Foundation & Arxiv"
    ]
  },
  {
    "objectID": "DataSkills/dataskills14.html#learning-objectives",
    "href": "DataSkills/dataskills14.html#learning-objectives",
    "title": "DataSkill 14: Open Science Foundation & Arxiv",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this session, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 14: Open Science Foundation & Arxiv"
    ]
  },
  {
    "objectID": "DataSkills/dataskills14.html#key-concepts",
    "href": "DataSkills/dataskills14.html#key-concepts",
    "title": "DataSkill 14: Open Science Foundation & Arxiv",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 14: Open Science Foundation & Arxiv"
    ]
  },
  {
    "objectID": "DataSkills/dataskills14.html#practical-exercise",
    "href": "DataSkills/dataskills14.html#practical-exercise",
    "title": "DataSkill 14: Open Science Foundation & Arxiv",
    "section": "Practical Exercise",
    "text": "Practical Exercise\n[Brief description of a hands-on exercise related to Open Science Foundation & Arxiv]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 14: Open Science Foundation & Arxiv"
    ]
  },
  {
    "objectID": "DataSkills/dataskills14.html#tips-and-best-practices",
    "href": "DataSkills/dataskills14.html#tips-and-best-practices",
    "title": "DataSkill 14: Open Science Foundation & Arxiv",
    "section": "Tips and Best Practices",
    "text": "Tips and Best Practices\n\n[Tip 1]\n[Tip 2]\n[Tip 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 14: Open Science Foundation & Arxiv"
    ]
  },
  {
    "objectID": "DataSkills/dataskills14.html#additional-resources",
    "href": "DataSkills/dataskills14.html#additional-resources",
    "title": "DataSkill 14: Open Science Foundation & Arxiv",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n[Resource 1: e.g., software download link, tutorial video, etc.]\n[Resource 2]\n[Resource 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 14: Open Science Foundation & Arxiv"
    ]
  },
  {
    "objectID": "DataSkills/dataskills14.html#reflection-questions",
    "href": "DataSkills/dataskills14.html#reflection-questions",
    "title": "DataSkill 14: Open Science Foundation & Arxiv",
    "section": "Reflection Questions",
    "text": "Reflection Questions\n\nHow might Open Science Foundation & Arxiv enhance your research capabilities?\nWhat challenges did you face when learning about or applying Open Science Foundation & Arxiv?\nHow could you integrate Open Science Foundation & Arxiv into your current or future research projects?",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 14: Open Science Foundation & Arxiv"
    ]
  },
  {
    "objectID": "DataSkills/dataskills18.html",
    "href": "DataSkills/dataskills18.html",
    "title": "DataSkill 18: Tools for writing up",
    "section": "",
    "text": "This session focuses on Tools for writing up and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 18: Tools for writing up"
    ]
  },
  {
    "objectID": "DataSkills/dataskills18.html#skill-overview",
    "href": "DataSkills/dataskills18.html#skill-overview",
    "title": "DataSkill 18: Tools for writing up",
    "section": "",
    "text": "This session focuses on Tools for writing up and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 18: Tools for writing up"
    ]
  },
  {
    "objectID": "DataSkills/dataskills18.html#learning-objectives",
    "href": "DataSkills/dataskills18.html#learning-objectives",
    "title": "DataSkill 18: Tools for writing up",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this session, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 18: Tools for writing up"
    ]
  },
  {
    "objectID": "DataSkills/dataskills18.html#key-concepts",
    "href": "DataSkills/dataskills18.html#key-concepts",
    "title": "DataSkill 18: Tools for writing up",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 18: Tools for writing up"
    ]
  },
  {
    "objectID": "DataSkills/dataskills18.html#practical-exercise",
    "href": "DataSkills/dataskills18.html#practical-exercise",
    "title": "DataSkill 18: Tools for writing up",
    "section": "Practical Exercise",
    "text": "Practical Exercise\n[Brief description of a hands-on exercise related to Tools for writing up]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 18: Tools for writing up"
    ]
  },
  {
    "objectID": "DataSkills/dataskills18.html#tips-and-best-practices",
    "href": "DataSkills/dataskills18.html#tips-and-best-practices",
    "title": "DataSkill 18: Tools for writing up",
    "section": "Tips and Best Practices",
    "text": "Tips and Best Practices\n\n[Tip 1]\n[Tip 2]\n[Tip 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 18: Tools for writing up"
    ]
  },
  {
    "objectID": "DataSkills/dataskills18.html#additional-resources",
    "href": "DataSkills/dataskills18.html#additional-resources",
    "title": "DataSkill 18: Tools for writing up",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n[Resource 1: e.g., software download link, tutorial video, etc.]\n[Resource 2]\n[Resource 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 18: Tools for writing up"
    ]
  },
  {
    "objectID": "DataSkills/dataskills18.html#reflection-questions",
    "href": "DataSkills/dataskills18.html#reflection-questions",
    "title": "DataSkill 18: Tools for writing up",
    "section": "Reflection Questions",
    "text": "Reflection Questions\n\nHow might Tools for writing up enhance your research capabilities?\nWhat challenges did you face when learning about or applying Tools for writing up?\nHow could you integrate Tools for writing up into your current or future research projects?",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 18: Tools for writing up"
    ]
  },
  {
    "objectID": "week01/codeoptions.html",
    "href": "week01/codeoptions.html",
    "title": "codeoptions",
    "section": "",
    "text": "Show the code\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n1penguins |&gt;\n2  mutate(\n    bill_ratio = bill_depth_mm / bill_length_mm,\n    bill_area  = bill_depth_mm * bill_length_mm\n  ) \n\n\n\n1\n\nTake penguins, and then,\n\n2\n\nadd new columns for the bill ratio and bill area.\n\n\n\n\n# A tibble: 344 × 10\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 4 more variables: sex &lt;fct&gt;, year &lt;int&gt;, bill_ratio &lt;dbl&gt;, bill_area &lt;dbl&gt;",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "codeoptions"
    ]
  },
  {
    "objectID": "week01/codeoptions.html#version-1---chunk-fold-with-line-numbers",
    "href": "week01/codeoptions.html#version-1---chunk-fold-with-line-numbers",
    "title": "codeoptions",
    "section": "",
    "text": "Show the code\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n1penguins |&gt;\n2  mutate(\n    bill_ratio = bill_depth_mm / bill_length_mm,\n    bill_area  = bill_depth_mm * bill_length_mm\n  ) \n\n\n\n1\n\nTake penguins, and then,\n\n2\n\nadd new columns for the bill ratio and bill area.\n\n\n\n\n# A tibble: 344 × 10\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 4 more variables: sex &lt;fct&gt;, year &lt;int&gt;, bill_ratio &lt;dbl&gt;, bill_area &lt;dbl&gt;",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "codeoptions"
    ]
  },
  {
    "objectID": "week01/codeoptions.html#version-2---standard-tabset-with-code-and-code-yoda",
    "href": "week01/codeoptions.html#version-2---standard-tabset-with-code-and-code-yoda",
    "title": "codeoptions",
    "section": "Version 2 - Standard Tabset with code and Code Yoda",
    "text": "Version 2 - Standard Tabset with code and Code Yoda\n\nCodeCodeYoda (#| eval: false)\n\n\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\npenguins |&gt;                                     \n  mutate(                                       \n    bill_ratio = bill_depth_mm / bill_length_mm,\n    bill_area  = bill_depth_mm * bill_length_mm \n  )\n\n# A tibble: 344 × 10\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 4 more variables: sex &lt;fct&gt;, year &lt;int&gt;, bill_ratio &lt;dbl&gt;, bill_area &lt;dbl&gt;\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n1penguins |&gt;\n2  mutate(\n    bill_ratio = bill_depth_mm / bill_length_mm,\n    bill_area  = bill_depth_mm * bill_length_mm\n  )\n\n\n1\n\nTake penguins, and then,\n\n2\n\nadd new columns for the bill ratio and bill area.",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "codeoptions"
    ]
  },
  {
    "objectID": "week01/codeoptions.html#version-3---panelize-and-webr-coatless-and-cant-seem-to-get-annotations-to-work-echofalse-for-r",
    "href": "week01/codeoptions.html#version-3---panelize-and-webr-coatless-and-cant-seem-to-get-annotations-to-work-echofalse-for-r",
    "title": "codeoptions",
    "section": "Version 3 - Panelize and Webr (coatless) and can’t seem to get annotations to work (echo:false for R)",
    "text": "Version 3 - Panelize and Webr (coatless) and can’t seem to get annotations to work (echo:false for R)\n\nResultInteractive\n\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\npenguins |&gt;                                     \n  mutate(                                       \n    bill_ratio = bill_depth_mm / bill_length_mm,\n    bill_area  = bill_depth_mm * bill_length_mm \n  )         \n\n# A tibble: 344 × 10\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 4 more variables: sex &lt;fct&gt;, year &lt;int&gt;, bill_ratio &lt;dbl&gt;, bill_area &lt;dbl&gt;\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "codeoptions"
    ]
  },
  {
    "objectID": "week01/codeoptions.html#version-4---just-trying-to-get-the-code-annotations-to-work-eval-false",
    "href": "week01/codeoptions.html#version-4---just-trying-to-get-the-code-annotations-to-work-eval-false",
    "title": "codeoptions",
    "section": "Version 4 - Just trying to get the Code annotations to work (#| eval: false)",
    "text": "Version 4 - Just trying to get the Code annotations to work (#| eval: false)\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n1penguins |&gt;\n2  mutate(\n    bill_ratio = bill_depth_mm / bill_length_mm,\n    bill_area  = bill_depth_mm * bill_length_mm\n  )\n\n\n1\n\nTake penguins, and then,\n\n2\n\nadd new columns for the bill ratio and bill area.",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "codeoptions"
    ]
  },
  {
    "objectID": "week01/codeoptions.html#native-quarto",
    "href": "week01/codeoptions.html#native-quarto",
    "title": "codeoptions",
    "section": "Native Quarto",
    "text": "Native Quarto\n\n## With size spec \n## With embedpdf extension x3 from raw file\n  Download PDF File\n   \n    Unable to display PDF file. Download instead.\n  \n  \nraw file with size options\n  Download PDF File\n   \n    Unable to display PDF file. Download instead.\n  \n  \nurl with “”\n  Download PDF File\n   \n    Unable to display PDF file. Download instead.",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "codeoptions"
    ]
  },
  {
    "objectID": "week01/dataskills.html",
    "href": "week01/dataskills.html",
    "title": "Expectations",
    "section": "",
    "text": "stuff",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "Expectations"
    ]
  },
  {
    "objectID": "week01/dataskills.html#what-we-expect-from-you",
    "href": "week01/dataskills.html#what-we-expect-from-you",
    "title": "Expectations",
    "section": "",
    "text": "stuff",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "Expectations"
    ]
  },
  {
    "objectID": "week01/dataskills.html#what-you-can-expect-from-us",
    "href": "week01/dataskills.html#what-you-can-expect-from-us",
    "title": "Expectations",
    "section": "What you can expect from us!",
    "text": "What you can expect from us!",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "Expectations"
    ]
  },
  {
    "objectID": "CHIP/topics/topic16.html",
    "href": "CHIP/topics/topic16.html",
    "title": "Where is Psychology’s non-stick frying pan?",
    "section": "",
    "text": "Where is Psychology’s non-stick frying pan?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Where is Psychology's non-stick frying pan?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic16.html#chip-topic",
    "href": "CHIP/topics/topic16.html#chip-topic",
    "title": "Where is Psychology’s non-stick frying pan?",
    "section": "",
    "text": "Where is Psychology’s non-stick frying pan?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Where is Psychology's non-stick frying pan?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic16.html#overview",
    "href": "CHIP/topics/topic16.html#overview",
    "title": "Where is Psychology’s non-stick frying pan?",
    "section": "Overview",
    "text": "Overview\nThis week we will explore Where is Psychology’s non-stick frying pan? and its implications for psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Where is Psychology's non-stick frying pan?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic16.html#key-points",
    "href": "CHIP/topics/topic16.html#key-points",
    "title": "Where is Psychology’s non-stick frying pan?",
    "section": "Key Points",
    "text": "Key Points\n\n[Key point 1]\n[Key point 2]\n[Key point 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Where is Psychology's non-stick frying pan?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic16.html#discussion-questions",
    "href": "CHIP/topics/topic16.html#discussion-questions",
    "title": "Where is Psychology’s non-stick frying pan?",
    "section": "Discussion Questions",
    "text": "Discussion Questions\n\nHow does Where is Psychology’s non-stick frying pan? influence our understanding of psychological phenomena?\nWhat are the main challenges in addressing Where is Psychology’s non-stick frying pan? in psychological research?\nHow can researchers better incorporate considerations of Where is Psychology’s non-stick frying pan? in their work?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Where is Psychology's non-stick frying pan?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic16.html#further-reading",
    "href": "CHIP/topics/topic16.html#further-reading",
    "title": "Where is Psychology’s non-stick frying pan?",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Where is Psychology's non-stick frying pan?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic15.html",
    "href": "CHIP/topics/topic15.html",
    "title": "What stage is Psychology at?",
    "section": "",
    "text": "What stage is Psychology at?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "What stage is Psychology at?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic15.html#chip-topic",
    "href": "CHIP/topics/topic15.html#chip-topic",
    "title": "What stage is Psychology at?",
    "section": "",
    "text": "What stage is Psychology at?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "What stage is Psychology at?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic15.html#overview",
    "href": "CHIP/topics/topic15.html#overview",
    "title": "What stage is Psychology at?",
    "section": "Overview",
    "text": "Overview\nThis week we will explore What stage is Psychology at? and its implications for psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "What stage is Psychology at?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic15.html#key-points",
    "href": "CHIP/topics/topic15.html#key-points",
    "title": "What stage is Psychology at?",
    "section": "Key Points",
    "text": "Key Points\n\n[Key point 1]\n[Key point 2]\n[Key point 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "What stage is Psychology at?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic15.html#discussion-questions",
    "href": "CHIP/topics/topic15.html#discussion-questions",
    "title": "What stage is Psychology at?",
    "section": "Discussion Questions",
    "text": "Discussion Questions\n\nHow does What stage is Psychology at? influence our understanding of psychological phenomena?\nWhat are the main challenges in addressing What stage is Psychology at? in psychological research?\nHow can researchers better incorporate considerations of What stage is Psychology at? in their work?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "What stage is Psychology at?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic15.html#further-reading",
    "href": "CHIP/topics/topic15.html#further-reading",
    "title": "What stage is Psychology at?",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "What stage is Psychology at?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic06.html",
    "href": "CHIP/topics/topic06.html",
    "title": "Reproducibility in Psychological Science",
    "section": "",
    "text": "Reproducibility in Psychological Science",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Reproducibility in Psychological Science"
    ]
  },
  {
    "objectID": "CHIP/topics/topic06.html#chip-topic",
    "href": "CHIP/topics/topic06.html#chip-topic",
    "title": "Reproducibility in Psychological Science",
    "section": "",
    "text": "Reproducibility in Psychological Science",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Reproducibility in Psychological Science"
    ]
  },
  {
    "objectID": "CHIP/topics/topic06.html#overview",
    "href": "CHIP/topics/topic06.html#overview",
    "title": "Reproducibility in Psychological Science",
    "section": "Overview",
    "text": "Overview\nThis week we will explore Reproducibility in Psychological Science and its implications for psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Reproducibility in Psychological Science"
    ]
  },
  {
    "objectID": "CHIP/topics/topic06.html#key-points",
    "href": "CHIP/topics/topic06.html#key-points",
    "title": "Reproducibility in Psychological Science",
    "section": "Key Points",
    "text": "Key Points\n\n[Key point 1]\n[Key point 2]\n[Key point 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Reproducibility in Psychological Science"
    ]
  },
  {
    "objectID": "CHIP/topics/topic06.html#discussion-questions",
    "href": "CHIP/topics/topic06.html#discussion-questions",
    "title": "Reproducibility in Psychological Science",
    "section": "Discussion Questions",
    "text": "Discussion Questions\n\nHow does Reproducibility in Psychological Science influence our understanding of psychological phenomena?\nWhat are the main challenges in addressing Reproducibility in Psychological Science in psychological research?\nHow can researchers better incorporate considerations of Reproducibility in Psychological Science in their work?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Reproducibility in Psychological Science"
    ]
  },
  {
    "objectID": "CHIP/topics/topic06.html#further-reading",
    "href": "CHIP/topics/topic06.html#further-reading",
    "title": "Reproducibility in Psychological Science",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Reproducibility in Psychological Science"
    ]
  },
  {
    "objectID": "CHIP/topics/topic20.html",
    "href": "CHIP/topics/topic20.html",
    "title": "Cognitive enhancement via drugs and implants",
    "section": "",
    "text": "Cognitive enhancement via drugs and implants",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Cognitive enhancement via drugs and implants"
    ]
  },
  {
    "objectID": "CHIP/topics/topic20.html#chip-topic",
    "href": "CHIP/topics/topic20.html#chip-topic",
    "title": "Cognitive enhancement via drugs and implants",
    "section": "",
    "text": "Cognitive enhancement via drugs and implants",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Cognitive enhancement via drugs and implants"
    ]
  },
  {
    "objectID": "CHIP/topics/topic20.html#overview",
    "href": "CHIP/topics/topic20.html#overview",
    "title": "Cognitive enhancement via drugs and implants",
    "section": "Overview",
    "text": "Overview\nThis week we will explore Cognitive enhancement via drugs and implants and its implications for psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Cognitive enhancement via drugs and implants"
    ]
  },
  {
    "objectID": "CHIP/topics/topic20.html#key-points",
    "href": "CHIP/topics/topic20.html#key-points",
    "title": "Cognitive enhancement via drugs and implants",
    "section": "Key Points",
    "text": "Key Points\n\n[Key point 1]\n[Key point 2]\n[Key point 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Cognitive enhancement via drugs and implants"
    ]
  },
  {
    "objectID": "CHIP/topics/topic20.html#discussion-questions",
    "href": "CHIP/topics/topic20.html#discussion-questions",
    "title": "Cognitive enhancement via drugs and implants",
    "section": "Discussion Questions",
    "text": "Discussion Questions\n\nHow does Cognitive enhancement via drugs and implants influence our understanding of psychological phenomena?\nWhat are the main challenges in addressing Cognitive enhancement via drugs and implants in psychological research?\nHow can researchers better incorporate considerations of Cognitive enhancement via drugs and implants in their work?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Cognitive enhancement via drugs and implants"
    ]
  },
  {
    "objectID": "CHIP/topics/topic20.html#further-reading",
    "href": "CHIP/topics/topic20.html#further-reading",
    "title": "Cognitive enhancement via drugs and implants",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Cognitive enhancement via drugs and implants"
    ]
  },
  {
    "objectID": "CHIP/topics/topic10.html",
    "href": "CHIP/topics/topic10.html",
    "title": "The WEIRD Problem in Psychology",
    "section": "",
    "text": "The WEIRD Problem in Psychology",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The WEIRD Problem in Psychology"
    ]
  },
  {
    "objectID": "CHIP/topics/topic10.html#chip-topic",
    "href": "CHIP/topics/topic10.html#chip-topic",
    "title": "The WEIRD Problem in Psychology",
    "section": "",
    "text": "The WEIRD Problem in Psychology",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The WEIRD Problem in Psychology"
    ]
  },
  {
    "objectID": "CHIP/topics/topic10.html#overview",
    "href": "CHIP/topics/topic10.html#overview",
    "title": "The WEIRD Problem in Psychology",
    "section": "Overview",
    "text": "Overview\nThis week we will explore The WEIRD Problem in Psychology and its implications for psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The WEIRD Problem in Psychology"
    ]
  },
  {
    "objectID": "CHIP/topics/topic10.html#key-points",
    "href": "CHIP/topics/topic10.html#key-points",
    "title": "The WEIRD Problem in Psychology",
    "section": "Key Points",
    "text": "Key Points\n\n[Key point 1]\n[Key point 2]\n[Key point 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The WEIRD Problem in Psychology"
    ]
  },
  {
    "objectID": "CHIP/topics/topic10.html#discussion-questions",
    "href": "CHIP/topics/topic10.html#discussion-questions",
    "title": "The WEIRD Problem in Psychology",
    "section": "Discussion Questions",
    "text": "Discussion Questions\n\nHow does The WEIRD Problem in Psychology influence our understanding of psychological phenomena?\nWhat are the main challenges in addressing The WEIRD Problem in Psychology in psychological research?\nHow can researchers better incorporate considerations of The WEIRD Problem in Psychology in their work?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The WEIRD Problem in Psychology"
    ]
  },
  {
    "objectID": "CHIP/topics/topic10.html#further-reading",
    "href": "CHIP/topics/topic10.html#further-reading",
    "title": "The WEIRD Problem in Psychology",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The WEIRD Problem in Psychology"
    ]
  },
  {
    "objectID": "CHIP/topics/topic01.html",
    "href": "CHIP/topics/topic01.html",
    "title": "Philosophy of Science",
    "section": "",
    "text": "Philosophy of Science",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Philosophy of Science"
    ]
  },
  {
    "objectID": "CHIP/topics/topic01.html#chip-topic",
    "href": "CHIP/topics/topic01.html#chip-topic",
    "title": "Philosophy of Science",
    "section": "",
    "text": "Philosophy of Science",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Philosophy of Science"
    ]
  },
  {
    "objectID": "CHIP/topics/topic01.html#overview",
    "href": "CHIP/topics/topic01.html#overview",
    "title": "Philosophy of Science",
    "section": "Overview",
    "text": "Overview\nThis week we will explore Philosophy of Science and its implications for psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Philosophy of Science"
    ]
  },
  {
    "objectID": "CHIP/topics/topic01.html#key-points",
    "href": "CHIP/topics/topic01.html#key-points",
    "title": "Philosophy of Science",
    "section": "Key Points",
    "text": "Key Points\n\n[Key point 1]\n[Key point 2]\n[Key point 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Philosophy of Science"
    ]
  },
  {
    "objectID": "CHIP/topics/topic01.html#discussion-questions",
    "href": "CHIP/topics/topic01.html#discussion-questions",
    "title": "Philosophy of Science",
    "section": "Discussion Questions",
    "text": "Discussion Questions\n\nHow does Philosophy of Science influence our understanding of psychological phenomena?\nWhat are the main challenges in addressing Philosophy of Science in psychological research?\nHow can researchers better incorporate considerations of Philosophy of Science in their work?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Philosophy of Science"
    ]
  },
  {
    "objectID": "CHIP/topics/topic01.html#further-reading",
    "href": "CHIP/topics/topic01.html#further-reading",
    "title": "Philosophy of Science",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Philosophy of Science"
    ]
  },
  {
    "objectID": "CHIP/topics/topic13.html",
    "href": "CHIP/topics/topic13.html",
    "title": "The Role of Subjectivity in Qualitative Research",
    "section": "",
    "text": "The Role of Subjectivity in Qualitative Research",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The Role of Subjectivity in Qualitative Research"
    ]
  },
  {
    "objectID": "CHIP/topics/topic13.html#chip-topic",
    "href": "CHIP/topics/topic13.html#chip-topic",
    "title": "The Role of Subjectivity in Qualitative Research",
    "section": "",
    "text": "The Role of Subjectivity in Qualitative Research",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The Role of Subjectivity in Qualitative Research"
    ]
  },
  {
    "objectID": "CHIP/topics/topic13.html#overview",
    "href": "CHIP/topics/topic13.html#overview",
    "title": "The Role of Subjectivity in Qualitative Research",
    "section": "Overview",
    "text": "Overview\nThis week we will explore The Role of Subjectivity in Qualitative Research and its implications for psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The Role of Subjectivity in Qualitative Research"
    ]
  },
  {
    "objectID": "CHIP/topics/topic13.html#key-points",
    "href": "CHIP/topics/topic13.html#key-points",
    "title": "The Role of Subjectivity in Qualitative Research",
    "section": "Key Points",
    "text": "Key Points\n\n[Key point 1]\n[Key point 2]\n[Key point 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The Role of Subjectivity in Qualitative Research"
    ]
  },
  {
    "objectID": "CHIP/topics/topic13.html#discussion-questions",
    "href": "CHIP/topics/topic13.html#discussion-questions",
    "title": "The Role of Subjectivity in Qualitative Research",
    "section": "Discussion Questions",
    "text": "Discussion Questions\n\nHow does The Role of Subjectivity in Qualitative Research influence our understanding of psychological phenomena?\nWhat are the main challenges in addressing The Role of Subjectivity in Qualitative Research in psychological research?\nHow can researchers better incorporate considerations of The Role of Subjectivity in Qualitative Research in their work?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The Role of Subjectivity in Qualitative Research"
    ]
  },
  {
    "objectID": "CHIP/topics/topic13.html#further-reading",
    "href": "CHIP/topics/topic13.html#further-reading",
    "title": "The Role of Subjectivity in Qualitative Research",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The Role of Subjectivity in Qualitative Research"
    ]
  },
  {
    "objectID": "CHIP/topics/topic18.html",
    "href": "CHIP/topics/topic18.html",
    "title": "Can I opt out of informed consent?",
    "section": "",
    "text": "Can I opt out of informed consent?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Can I opt out of informed consent?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic18.html#chip-topic",
    "href": "CHIP/topics/topic18.html#chip-topic",
    "title": "Can I opt out of informed consent?",
    "section": "",
    "text": "Can I opt out of informed consent?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Can I opt out of informed consent?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic18.html#overview",
    "href": "CHIP/topics/topic18.html#overview",
    "title": "Can I opt out of informed consent?",
    "section": "Overview",
    "text": "Overview\nThis week we will explore Can I opt out of informed consent? and its implications for psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Can I opt out of informed consent?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic18.html#key-points",
    "href": "CHIP/topics/topic18.html#key-points",
    "title": "Can I opt out of informed consent?",
    "section": "Key Points",
    "text": "Key Points\n\n[Key point 1]\n[Key point 2]\n[Key point 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Can I opt out of informed consent?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic18.html#discussion-questions",
    "href": "CHIP/topics/topic18.html#discussion-questions",
    "title": "Can I opt out of informed consent?",
    "section": "Discussion Questions",
    "text": "Discussion Questions\n\nHow does Can I opt out of informed consent? influence our understanding of psychological phenomena?\nWhat are the main challenges in addressing Can I opt out of informed consent? in psychological research?\nHow can researchers better incorporate considerations of Can I opt out of informed consent? in their work?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Can I opt out of informed consent?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic18.html#further-reading",
    "href": "CHIP/topics/topic18.html#further-reading",
    "title": "Can I opt out of informed consent?",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Can I opt out of informed consent?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic05.html",
    "href": "CHIP/topics/topic05.html",
    "title": "Ethical Considerations in Psychological Research",
    "section": "",
    "text": "Ethical Considerations in Psychological Research",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Ethical Considerations in Psychological Research"
    ]
  },
  {
    "objectID": "CHIP/topics/topic05.html#chip-topic",
    "href": "CHIP/topics/topic05.html#chip-topic",
    "title": "Ethical Considerations in Psychological Research",
    "section": "",
    "text": "Ethical Considerations in Psychological Research",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Ethical Considerations in Psychological Research"
    ]
  },
  {
    "objectID": "CHIP/topics/topic05.html#overview",
    "href": "CHIP/topics/topic05.html#overview",
    "title": "Ethical Considerations in Psychological Research",
    "section": "Overview",
    "text": "Overview\nThis week we will explore Ethical Considerations in Psychological Research and its implications for psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Ethical Considerations in Psychological Research"
    ]
  },
  {
    "objectID": "CHIP/topics/topic05.html#key-points",
    "href": "CHIP/topics/topic05.html#key-points",
    "title": "Ethical Considerations in Psychological Research",
    "section": "Key Points",
    "text": "Key Points\n\n[Key point 1]\n[Key point 2]\n[Key point 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Ethical Considerations in Psychological Research"
    ]
  },
  {
    "objectID": "CHIP/topics/topic05.html#discussion-questions",
    "href": "CHIP/topics/topic05.html#discussion-questions",
    "title": "Ethical Considerations in Psychological Research",
    "section": "Discussion Questions",
    "text": "Discussion Questions\n\nHow does Ethical Considerations in Psychological Research influence our understanding of psychological phenomena?\nWhat are the main challenges in addressing Ethical Considerations in Psychological Research in psychological research?\nHow can researchers better incorporate considerations of Ethical Considerations in Psychological Research in their work?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Ethical Considerations in Psychological Research"
    ]
  },
  {
    "objectID": "CHIP/topics/topic05.html#further-reading",
    "href": "CHIP/topics/topic05.html#further-reading",
    "title": "Ethical Considerations in Psychological Research",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Ethical Considerations in Psychological Research"
    ]
  },
  {
    "objectID": "CHIP/topics/smopic01.html",
    "href": "CHIP/topics/smopic01.html",
    "title": "Exemplary Title for a CHIP topic",
    "section": "",
    "text": "Not vinegar title x x x subtitle x\nauthor x x x description x x date x x x image",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Exemplary Title for a CHIP topic"
    ]
  },
  {
    "objectID": "CHIP/topics/smopic01.html#chip-stuff",
    "href": "CHIP/topics/smopic01.html#chip-stuff",
    "title": "Exemplary Title for a CHIP topic",
    "section": "",
    "text": "Not vinegar title x x x subtitle x\nauthor x x x description x x date x x x image",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Exemplary Title for a CHIP topic"
    ]
  },
  {
    "objectID": "CHIP/topics/topic19.html",
    "href": "CHIP/topics/topic19.html",
    "title": "Stanford Prison and Milgram - how do classic studies fare?",
    "section": "",
    "text": "Stanford Prison and Milgram - how do classic studies fare?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Stanford Prison and Milgram - how do classic studies fare?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic19.html#chip-topic",
    "href": "CHIP/topics/topic19.html#chip-topic",
    "title": "Stanford Prison and Milgram - how do classic studies fare?",
    "section": "",
    "text": "Stanford Prison and Milgram - how do classic studies fare?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Stanford Prison and Milgram - how do classic studies fare?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic19.html#overview",
    "href": "CHIP/topics/topic19.html#overview",
    "title": "Stanford Prison and Milgram - how do classic studies fare?",
    "section": "Overview",
    "text": "Overview\nThis week we will explore Stanford Prison and Milgram - how do classic studies fare? and its implications for psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Stanford Prison and Milgram - how do classic studies fare?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic19.html#key-points",
    "href": "CHIP/topics/topic19.html#key-points",
    "title": "Stanford Prison and Milgram - how do classic studies fare?",
    "section": "Key Points",
    "text": "Key Points\n\n[Key point 1]\n[Key point 2]\n[Key point 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Stanford Prison and Milgram - how do classic studies fare?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic19.html#discussion-questions",
    "href": "CHIP/topics/topic19.html#discussion-questions",
    "title": "Stanford Prison and Milgram - how do classic studies fare?",
    "section": "Discussion Questions",
    "text": "Discussion Questions\n\nHow does Stanford Prison and Milgram - how do classic studies fare? influence our understanding of psychological phenomena?\nWhat are the main challenges in addressing Stanford Prison and Milgram - how do classic studies fare? in psychological research?\nHow can researchers better incorporate considerations of Stanford Prison and Milgram - how do classic studies fare? in their work?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Stanford Prison and Milgram - how do classic studies fare?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic19.html#further-reading",
    "href": "CHIP/topics/topic19.html#further-reading",
    "title": "Stanford Prison and Milgram - how do classic studies fare?",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Stanford Prison and Milgram - how do classic studies fare?"
    ]
  },
  {
    "objectID": "Reading/chapter10.html",
    "href": "Reading/chapter10.html",
    "title": "Chapter 10: Data Management and Sharing",
    "section": "",
    "text": "This chapter focuses on Data Management and Sharing and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 10: Data Management and Sharing"
    ]
  },
  {
    "objectID": "Reading/chapter10.html#chapter-overview",
    "href": "Reading/chapter10.html#chapter-overview",
    "title": "Chapter 10: Data Management and Sharing",
    "section": "",
    "text": "This chapter focuses on Data Management and Sharing and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 10: Data Management and Sharing"
    ]
  },
  {
    "objectID": "Reading/chapter10.html#learning-objectives",
    "href": "Reading/chapter10.html#learning-objectives",
    "title": "Chapter 10: Data Management and Sharing",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter reading this chapter, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 10: Data Management and Sharing"
    ]
  },
  {
    "objectID": "Reading/chapter10.html#key-concepts",
    "href": "Reading/chapter10.html#key-concepts",
    "title": "Chapter 10: Data Management and Sharing",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 10: Data Management and Sharing"
    ]
  },
  {
    "objectID": "Reading/chapter10.html#summary",
    "href": "Reading/chapter10.html#summary",
    "title": "Chapter 10: Data Management and Sharing",
    "section": "Summary",
    "text": "Summary\n[Brief summary of the chapter’s main points]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 10: Data Management and Sharing"
    ]
  },
  {
    "objectID": "Reading/chapter10.html#critical-thinking-questions",
    "href": "Reading/chapter10.html#critical-thinking-questions",
    "title": "Chapter 10: Data Management and Sharing",
    "section": "Critical Thinking Questions",
    "text": "Critical Thinking Questions\n\nHow does Data Management and Sharing contribute to our understanding of psychological research?\nWhat are some potential challenges or limitations in applying Data Management and Sharing to real-world research scenarios?\nHow might advances in technology or methodology impact our approach to Data Management and Sharing in the future?",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 10: Data Management and Sharing"
    ]
  },
  {
    "objectID": "Reading/chapter10.html#further-reading",
    "href": "Reading/chapter10.html#further-reading",
    "title": "Chapter 10: Data Management and Sharing",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 10: Data Management and Sharing"
    ]
  },
  {
    "objectID": "Reading/chapter12.html",
    "href": "Reading/chapter12.html",
    "title": "Chapter 12: Qualitative Data Analysis",
    "section": "",
    "text": "This chapter focuses on Qualitative Data Analysis and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 12: Qualitative Data Analysis"
    ]
  },
  {
    "objectID": "Reading/chapter12.html#chapter-overview",
    "href": "Reading/chapter12.html#chapter-overview",
    "title": "Chapter 12: Qualitative Data Analysis",
    "section": "",
    "text": "This chapter focuses on Qualitative Data Analysis and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 12: Qualitative Data Analysis"
    ]
  },
  {
    "objectID": "Reading/chapter12.html#learning-objectives",
    "href": "Reading/chapter12.html#learning-objectives",
    "title": "Chapter 12: Qualitative Data Analysis",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter reading this chapter, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 12: Qualitative Data Analysis"
    ]
  },
  {
    "objectID": "Reading/chapter12.html#key-concepts",
    "href": "Reading/chapter12.html#key-concepts",
    "title": "Chapter 12: Qualitative Data Analysis",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 12: Qualitative Data Analysis"
    ]
  },
  {
    "objectID": "Reading/chapter12.html#summary",
    "href": "Reading/chapter12.html#summary",
    "title": "Chapter 12: Qualitative Data Analysis",
    "section": "Summary",
    "text": "Summary\n[Brief summary of the chapter’s main points]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 12: Qualitative Data Analysis"
    ]
  },
  {
    "objectID": "Reading/chapter12.html#critical-thinking-questions",
    "href": "Reading/chapter12.html#critical-thinking-questions",
    "title": "Chapter 12: Qualitative Data Analysis",
    "section": "Critical Thinking Questions",
    "text": "Critical Thinking Questions\n\nHow does Qualitative Data Analysis contribute to our understanding of psychological research?\nWhat are some potential challenges or limitations in applying Qualitative Data Analysis to real-world research scenarios?\nHow might advances in technology or methodology impact our approach to Qualitative Data Analysis in the future?",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 12: Qualitative Data Analysis"
    ]
  },
  {
    "objectID": "Reading/chapter12.html#further-reading",
    "href": "Reading/chapter12.html#further-reading",
    "title": "Chapter 12: Qualitative Data Analysis",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 12: Qualitative Data Analysis"
    ]
  },
  {
    "objectID": "Reading/chapter03.html",
    "href": "Reading/chapter03.html",
    "title": "Chapter 3: Critical Analysis in Psychology",
    "section": "",
    "text": "This chapter focuses on Critical Analysis in Psychology and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 3: Critical Analysis in Psychology"
    ]
  },
  {
    "objectID": "Reading/chapter03.html#chapter-overview",
    "href": "Reading/chapter03.html#chapter-overview",
    "title": "Chapter 3: Critical Analysis in Psychology",
    "section": "",
    "text": "This chapter focuses on Critical Analysis in Psychology and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 3: Critical Analysis in Psychology"
    ]
  },
  {
    "objectID": "Reading/chapter03.html#learning-objectives",
    "href": "Reading/chapter03.html#learning-objectives",
    "title": "Chapter 3: Critical Analysis in Psychology",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter reading this chapter, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 3: Critical Analysis in Psychology"
    ]
  },
  {
    "objectID": "Reading/chapter03.html#key-concepts",
    "href": "Reading/chapter03.html#key-concepts",
    "title": "Chapter 3: Critical Analysis in Psychology",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 3: Critical Analysis in Psychology"
    ]
  },
  {
    "objectID": "Reading/chapter03.html#summary",
    "href": "Reading/chapter03.html#summary",
    "title": "Chapter 3: Critical Analysis in Psychology",
    "section": "Summary",
    "text": "Summary\n[Brief summary of the chapter’s main points]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 3: Critical Analysis in Psychology"
    ]
  },
  {
    "objectID": "Reading/chapter03.html#critical-thinking-questions",
    "href": "Reading/chapter03.html#critical-thinking-questions",
    "title": "Chapter 3: Critical Analysis in Psychology",
    "section": "Critical Thinking Questions",
    "text": "Critical Thinking Questions\n\nHow does Critical Analysis in Psychology contribute to our understanding of psychological research?\nWhat are some potential challenges or limitations in applying Critical Analysis in Psychology to real-world research scenarios?\nHow might advances in technology or methodology impact our approach to Critical Analysis in Psychology in the future?",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 3: Critical Analysis in Psychology"
    ]
  },
  {
    "objectID": "Reading/chapter03.html#further-reading",
    "href": "Reading/chapter03.html#further-reading",
    "title": "Chapter 3: Critical Analysis in Psychology",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 3: Critical Analysis in Psychology"
    ]
  },
  {
    "objectID": "Reading/courseworkCP.html#suggested-outline",
    "href": "Reading/courseworkCP.html#suggested-outline",
    "title": "Critical Proposal",
    "section": "Suggested Outline",
    "text": "Suggested Outline\n\nSummary (Compulsory and Important)\nProvide a summary of the article in 150-200 words in which you capture the essentials of the Target Paper.\n(a) What is the research domain and core question of the paper and what is of interest to you?\n\n(b) What is the method that you are focussing on?\n\n(c) What are the relevant results?\n\n(d) Were there significant flaws or limitations in the study that might give you insight into your own research ahead?\n\n\nResearch Question\nDo the authors link their experiment to wider issues and theories in psychology? What question is the paper trying to answer? Is the hypothesis clear? Is it well-argued?\n\n\nMethod\nIs it clear and unambiguous? Could another (better) method have been used? Could you carry out a replication from this report? Is the design the most efficient for the purpose? Have broad theoretical constructs been well operationalized into specific variables?\n\n\nOutcome\nIs the Results section clear? Is the analysis unambiguous? Are all analyses and statistical choices appropriate? Did the experimenter answer the question?\n\n\nExperimental Design Schematic\nYou are required to complete details of one IV and an effect size (drawn from the target paper) at least!\n\n\nDiscussion\nAre the inferences from the results justified? Well-argued? Do they advance our knowledge? What further questions are raised by the results? What experiments might be done to answer them?\n\n\nSuggested Improvements\nWhich aspects of the research project could be improved? Is there a better research design? Are there extraneous or confounding variables? How would you remove them? Could the results be more clearly analysed and presented? Think also about which aspects of the paper itself could be improved. Were the hypotheses clearly reported and well-justified? Would you have displayed information differently (e.g., in figures or graphs)?\n\n\nCritical Reflection and Conclusion\n\nWhat were the key strengths and/or weaknesses of the paper? Did you find the paper clear? Do you think it provides a persuasive answer to the research question set out, or are there important limitations that limit its overall usefulness?\nHow will your Mini-Dissertation improve the research presented?\nWhy is it important that YOU do this research? How will you implement ‘Best Practice’ in the Mini-Dissertation?\nWhat has this exercise taught you, and how has it developed your metacognitive abilities?\n\n\n\n\nUseful Readings (available online in the library reading list):\n\nBell, P., Staines, P., & Mitchell, J. (2001). Evaluating, doing and writing research in psychology. London: Sage. (Chapters 5 & 6)\nHaslam, A., & McGrarty, C. (2014). Research Methods and Statistics in Psychology. London: Sage. (Checklists on pp. 29-",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Critical Proposal"
    ]
  },
  {
    "objectID": "Reading/courseworkCP.html#rubric",
    "href": "Reading/courseworkCP.html#rubric",
    "title": "Critical Proposal",
    "section": "Rubric",
    "text": "Rubric",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Critical Proposal"
    ]
  },
  {
    "objectID": "Reading/chapter05.html",
    "href": "Reading/chapter05.html",
    "title": "Chapter 5: Measurement in Psychology",
    "section": "",
    "text": "This chapter focuses on Measurement in Psychology and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 5: Measurement in Psychology"
    ]
  },
  {
    "objectID": "Reading/chapter05.html#chapter-overview",
    "href": "Reading/chapter05.html#chapter-overview",
    "title": "Chapter 5: Measurement in Psychology",
    "section": "",
    "text": "This chapter focuses on Measurement in Psychology and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 5: Measurement in Psychology"
    ]
  },
  {
    "objectID": "Reading/chapter05.html#learning-objectives",
    "href": "Reading/chapter05.html#learning-objectives",
    "title": "Chapter 5: Measurement in Psychology",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter reading this chapter, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 5: Measurement in Psychology"
    ]
  },
  {
    "objectID": "Reading/chapter05.html#key-concepts",
    "href": "Reading/chapter05.html#key-concepts",
    "title": "Chapter 5: Measurement in Psychology",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 5: Measurement in Psychology"
    ]
  },
  {
    "objectID": "Reading/chapter05.html#summary",
    "href": "Reading/chapter05.html#summary",
    "title": "Chapter 5: Measurement in Psychology",
    "section": "Summary",
    "text": "Summary\n[Brief summary of the chapter’s main points]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 5: Measurement in Psychology"
    ]
  },
  {
    "objectID": "Reading/chapter05.html#critical-thinking-questions",
    "href": "Reading/chapter05.html#critical-thinking-questions",
    "title": "Chapter 5: Measurement in Psychology",
    "section": "Critical Thinking Questions",
    "text": "Critical Thinking Questions\n\nHow does Measurement in Psychology contribute to our understanding of psychological research?\nWhat are some potential challenges or limitations in applying Measurement in Psychology to real-world research scenarios?\nHow might advances in technology or methodology impact our approach to Measurement in Psychology in the future?",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 5: Measurement in Psychology"
    ]
  },
  {
    "objectID": "Reading/chapter05.html#further-reading",
    "href": "Reading/chapter05.html#further-reading",
    "title": "Chapter 5: Measurement in Psychology",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 5: Measurement in Psychology"
    ]
  },
  {
    "objectID": "Reading/rubrics.html",
    "href": "Reading/rubrics.html",
    "title": "Rubrics",
    "section": "",
    "text": "Critical Proposal Rubric (1,800 words max)\n\n\n\n\n\n\n\n\n\n\n\n\nCriteria\nExplanation\nFail\n3rd\n2:2\n2:1\n1st\n\n\n\n\nSummary\nDoes the proposal summarise the chosen empirical article?\nNo summary of the chosen empirical paper.\nThe chosen empirical paper is described, but with inaccuracies or imprecision.\nThe chosen empirical paper is described, with only a few errors, gaps, or a minor lack of clarity.\nThe chosen empirical paper is clearly and fully summarised, with appropriate terminology and precision.\nThe chosen empirical paper is clearly and fully summarised, with excellent terminology, accuracy and accessibility, showing a comprehensive understanding of the paper.\n\n\nResearch Question\nDoes the proposal critique the research question and general domain?\nNo overview of the research domain or research question addressed.\nThe proposal summarises the research area and general question addressed, but does so imprecisely or with errors.\nThe proposal accurately summarises the domain of research and the specific question addressed in the paper.\nThe proposal accurately summarises the domain of research and the specific question addressed in the paper and does so in an accessible and precise manner.\nThe proposal accurately summarises the domain of research and the specific question addressed in the paper and does so in an accessible and precise manner while evaluating the merit or importance of the research.\n\n\nMethod\nDoes the proposal critically evaluate the chosen method and operationalisation of variables?\nNo attempt to evaluate the methods of the paper.\nEvaluation of the methods are few and preliminary.\nEvaluation of the method is clear, but doesn’t consider important aspects.\nEvaluation of the method is clear and focusses on important aspects.\nEvaluation of the method is clear, identifies the most important aspects, and the impact on possible results is argued.\n\n\nOutcome\nHas the proposal critically evaluated the analysis, reporting, and interpretation of the results?\nNo discernible evaluation of the results section.\nThe proposal makes few, superficial comments on the presentation and analysis of results.\nThe proposal makes a good attempt at presenting an evaluation of the results, but they are preliminary.\nThe proposal makes good suggestions for how the results may be more accurately presented and analysed.\nThe proposal shows insight in the evaluation of analysis, reporting and interpretation of the results of the chosen study.\n\n\nDiscussion\nDoes the proposal address how well results are integrated into the literature, and how the authors address limitations and opportunities for extension?\nThe proposal has failed to address how the results sit within the literature or the authors efforts to critique their own work.\nThe proposal presents preliminary ideas on how the research integrates results and appraises the research.\nThe proposal presents clear appraisal of how the research integrates results and appraises the research.\nThe proposal presents thoughtful evaluation of how the research integrates results and appraises the research.\nThe proposal examines how results are discussed well and presents a robust examination of the researchers discussion.\n\n\nImprovements\nDoes the proposal present means by which to avoid limitations and/or build on strengths of the study?\nThe proposal makes no effort to mitigate limitations or build on strengths.\nThe proposal has identified steps by which to EITHER avoid limitations or accentuate positive aspects of the study.\nThe proposal has dealt with limitations AND strengths and proposed improvements.\nThe proposal has identified important limitations and strengths and presented feasible improvements.\nThe proposal identifies and argues the most salient areas of improvement and presents carefully considered and supported suggestions for improvement.\n\n\nCritical Reflection/Conclusion\nDoes the proposal clearly summarise key points from the essay and propose specific means by which the student may improve research in this area?\nNo reflection on how the points made in the essay work together or how the student may feasibly improve work in this area.\nThere is an effort to synthesise the argument made during the essay and an attempt to illustrate how the author may improve research in this area, but it is vague.\nA conclusion is presented and it features reflections on future improvement that don’t tie together or have limited focus on priority.\nThe conclusion brings the main points of the critique together and a clear set of ideas presented by which the student may improve research in the area.\nThe conclusion synthesises the main points of the critique nicely with clear evaluation. The student has presented a thoughtful and focussed reflection on how they might make a meaningful improvement in the research field.\n\n\nFormat and Referencing\nIs the proposal well-written, well-presented, with appropriate in-text citations and references?\nThe proposal is poorly formatted and referencing is either absent or very poorly inserted / inaccurately listed at the end.\nThe format is adequate and there is some appropriate referencing, but there are also lots of inaccuracies and omissions.\nThe format and referencing is appropriate for the most part, but there are a number of minor errors.\nFormatting is good and references are inserted accurately and appropriately in the text and listed correctly at the end.\nThe format is clear and professional and referencing is to a high academic standard.\n\n\n\nNote: A declaration of AI use (or non-use) is compulsory.\n\n\nMini-Dissertation Rubric (1,800 words max)\n\n\n\n\n\n\n\n\n\n\n\n\nCriteria\nExplanation\nFail\n3rd\n2:2\n2:1\n1st\n\n\n\n\nStructure\nIs the Mini-Dissertation well-structured with clear sections?\nIncorrect or missing sections. APA formatting missing or poorly followed.\nPoor structure with possibly missing sections. Not according to APA formatting.\nReasonable structure with all relevant sections. Some minor errors in APA formatting.\nGood structure with all relevant sections. APA format followed generally well.\nExcellent structure with all relevant sections. APA format fully followed with excellent attention to detail.\n\n\nIntroduction: Background\nDoes the introduction set the scene and provide theoretical/empirical background?\nArea of interest unclear. Relevant background research missing or incorrectly reported.\nSome attempt at introducing area of interest and background research, but with errors or lack of clarity.\nIntroduces area of interest and background research reasonably clearly. Relationship between claims and evidence mostly clear.\nIntroduces area of interest clearly. Background research clearly presented, including relevant theory and/or empirical evidence.\nIntroduces area of interest thoughtfully. Background research very clearly presented and authoritative, with comprehensive overview.\n\n\nIntroduction: Research Question\nIs there a clear research question and justification for the study?\nLittle or no justification for the study. No outline of the research question.\nPoor justification for the study. Outline of the research question possibly not included.\nReasonable justification for the study. Outline of the research question included.\nClear justification for the study. Good outline of the research question included.\nVery clear justification for the study. Excellent outline of the research question included.\n\n\nMethod\nIs the method clearly described and appropriate?\nMethod missing or very poorly reported.\nMethod poorly reported with missing details.\nMethod reasonably reported with some minor details missing.\nMethod well reported, including all relevant details.\nMethod excellently reported, with all details clear and accurate.\n\n\nResults\nAre the results clearly presented and analyzed?\nResults missing or incomprehensible.\nResults poorly presented with errors or missing information.\nResults reasonably presented with some minor errors or unclear elements.\nResults well presented and analyzed.\nResults excellently presented and analyzed, adding to the narrative.\n\n\nDiscussion\nDoes the discussion interpret results and relate them to previous research?\nNo interpretation of results or relation to previous research.\nPoor attempt at interpreting results and relating to previous research.\nReasonable attempt at interpreting results and relating to previous research.\nClear interpretation of results and good relation to previous research.\nExcellent interpretation of results and insightful relation to previous research.\n\n\nCritical Reflection\nDoes the Mini-Dissertation demonstrate critical thinking and reflection?\nNo evidence of critical thinking or reflection.\nLimited evidence of critical thinking or reflection.\nSome evidence of critical thinking and reflection.\nClear evidence of critical thinking and reflection.\nExcellent critical thinking and insightful reflection throughout.\n\n\nSources\nDoes the Mini-Dissertation use a range of appropriate sources?\nInappropriate or no citations. No evidence of meaningful reading.\nSome appropriate citations but no evidence of wider reading.\nMostly appropriate citations with limited evidence of wider reading.\nWide range of appropriate citations with evidence of wider reading.\nWide range of appropriate and creative citations with clear demonstration of extensive reading.\n\n\nPresentation\nIs the Mini-Dissertation well-presented with correct APA referencing?\nPoor presentation and referencing.\nInadequate presentation and referencing with many errors.\nSatisfactory presentation and referencing with some minor errors.\nGood presentation and referencing with very few errors.\nExcellent presentation and referencing to a high academic standard.\n\n\n\nNote: A declaration of AI use (or non-use) is compulsory.\n\n\nCHIP Learning Log Rubric - Reflection 1 (600 words max including APA references)\nReflection on a Chosen CHIP Topic from 2 Perspectives\n\n\n\n\n\n\n\n\n\n\n\n\nCriteria\nExplanation\nFail\n3rd\n2:2\n2:1\n1st\n\n\n\n\nStructure\nIs the reflective account well-structured? Does it ask and answer a clear question?\nMost requirements not met. Missing key elements.\nSome requirements met but poorly achieved. Contains basic elements but lacks coherence.\nMost requirements met. Sets and addresses a question, but not explicitly.\nAll or most requirements met to a high standard. Addresses an explicit question well.\nAll requirements met to a very high standard. Addresses a clear question excellently.\n\n\nPerspectives\nDoes the reflective account adopt 2 out of 6 perspectives?\nPerspectives not mentioned or unclear.\nOne or two perspectives mentioned but poorly linked to the topic.\nTwo perspectives stated and partially linked to the topic.\nTwo perspectives explicitly stated and well-linked to the topic.\nTwo perspectives explicitly stated and linked to the topic thoughtfully and creatively.\n\n\nReflection\nDoes the account demonstrate reflection on lecture content and offer personal opinions?\nOnly repeats facts. No reflection or personal opinion.\nGives facts with little reflection. Opinions given without support.\nDemonstrates some reflection. Gives opinions but doesn’t relate to learning.\nDemonstrates good reflection. Gives opinions and shows how they’ve changed.\nDemonstrates thoughtful reflection. Gives insightful opinions and shows development.\n\n\nArgument\nIs the account well-argued with appropriate examples?\nIdeas hard to follow. No examples.\nIdeas not logically presented. Poor use of examples.\nIdeas mostly logical. Use of relevant examples.\nIdeas logical and well-argued. Good use of examples.\nAll ideas logical and exceptionally well-argued. Creative use of examples.\n\n\nSources\nDoes the account use a range of sources to support arguments?\nNo or inappropriate citations.\nSome appropriate citations but no wider reading.\nMostly appropriate citations with limited wider reading.\nWide range of citations with some wider reading.\nWide range of creative citations with clear wider reading.\n\n\nPresentation\nIs the account well-presented with correct APA referencing?\nPoor presentation and referencing.\nInadequate presentation and referencing with many errors.\nSatisfactory presentation and referencing with some minor errors.\nGood presentation and referencing with very few errors.\nExcellent presentation and referencing to a high academic standard.\n\n\n\nNote: A declaration of AI use (or non-use) is compulsory.\n\n\nCHIP Learning Log Rubric - Reflection 2 (600 words max including APA references)\nReflection on Specific ‘Reading Journey’ Within Another CHIP Topic\n\n\n\n\n\n\n\n\n\n\n\n\nCriteria\nExplanation\nFail\n3rd\n2:2\n2:1\n1st\n\n\n\n\nStructure\nIs the reflective account well-structured? Does it build on a specific reading and discuss a debate/issue?\nMost requirements not met. Doesn’t identify specific reading or discuss issue.\nSome requirements met but poorly achieved. Lacking in detail.\nMost requirements met. Identifies reading and presents limited discussion.\nAll or most requirements met to a high standard. Explicitly identifies reading and discusses in detail.\nAll requirements met to a very high standard. Explicit identification and comprehensive discussion.\n\n\nReflection\nDoes the account demonstrate reflection on lecture content and offer personal opinions?\nOnly repeats facts. No reflection or personal opinion.\nGives facts with little reflection. Opinions given without support.\nDemonstrates some reflection. Gives opinions but doesn’t relate to learning.\nDemonstrates good reflection. Gives opinions and relates to course content.\nDemonstrates thoughtful reflection. Gives insightful opinions showing development from course and reading.\n\n\nArgument\nIs the account well-argued with appropriate examples?\nIdeas hard to follow. No examples.\nIdeas not logically presented. Poor use of examples.\nIdeas mostly logical. Use of relevant examples.\nIdeas logical and well-argued. Good use of examples.\nAll ideas logical and exceptionally well-argued. Creative use of examples.\n\n\nSources\nDoes the account use a range of sources to support arguments?\nNo or inappropriate citations.\nSome appropriate citations but no wider reading.\nMostly appropriate citations with limited wider reading.\nWide range of citations with some wider reading.\nWide range of creative citations with clear wider reading.\n\n\nPresentation\nIs the account well-presented with correct APA referencing?\nPoor presentation and referencing.\nInadequate presentation and referencing with many errors.\nSatisfactory presentation and referencing with some minor errors.\nGood presentation and referencing with very few errors.\nExcellent presentation and referencing to a high academic standard.\n\n\n\nNote: A declaration of AI use (or non-use) is compulsory.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Rubrics"
    ]
  },
  {
    "objectID": "Reading/chapter14.html",
    "href": "Reading/chapter14.html",
    "title": "Chapter 14: Writing your MD | Overview",
    "section": "",
    "text": "This chapter focuses on Writing your MD | Overview and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 14: Writing your MD | Overview"
    ]
  },
  {
    "objectID": "Reading/chapter14.html#chapter-overview",
    "href": "Reading/chapter14.html#chapter-overview",
    "title": "Chapter 14: Writing your MD | Overview",
    "section": "",
    "text": "This chapter focuses on Writing your MD | Overview and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 14: Writing your MD | Overview"
    ]
  },
  {
    "objectID": "Reading/chapter14.html#learning-objectives",
    "href": "Reading/chapter14.html#learning-objectives",
    "title": "Chapter 14: Writing your MD | Overview",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter reading this chapter, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 14: Writing your MD | Overview"
    ]
  },
  {
    "objectID": "Reading/chapter14.html#key-concepts",
    "href": "Reading/chapter14.html#key-concepts",
    "title": "Chapter 14: Writing your MD | Overview",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 14: Writing your MD | Overview"
    ]
  },
  {
    "objectID": "Reading/chapter14.html#summary",
    "href": "Reading/chapter14.html#summary",
    "title": "Chapter 14: Writing your MD | Overview",
    "section": "Summary",
    "text": "Summary\n[Brief summary of the chapter’s main points]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 14: Writing your MD | Overview"
    ]
  },
  {
    "objectID": "Reading/chapter14.html#critical-thinking-questions",
    "href": "Reading/chapter14.html#critical-thinking-questions",
    "title": "Chapter 14: Writing your MD | Overview",
    "section": "Critical Thinking Questions",
    "text": "Critical Thinking Questions\n\nHow does Writing your MD | Overview contribute to our understanding of psychological research?\nWhat are some potential challenges or limitations in applying Writing your MD | Overview to real-world research scenarios?\nHow might advances in technology or methodology impact our approach to Writing your MD | Overview in the future?",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 14: Writing your MD | Overview"
    ]
  },
  {
    "objectID": "Reading/chapter14.html#further-reading",
    "href": "Reading/chapter14.html#further-reading",
    "title": "Chapter 14: Writing your MD | Overview",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 14: Writing your MD | Overview"
    ]
  },
  {
    "objectID": "Reading/chapter07.html",
    "href": "Reading/chapter07.html",
    "title": "Chapter 7: Psychological Assessment",
    "section": "",
    "text": "This chapter focuses on Psychological Assessment and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 7: Psychological Assessment"
    ]
  },
  {
    "objectID": "Reading/chapter07.html#chapter-overview",
    "href": "Reading/chapter07.html#chapter-overview",
    "title": "Chapter 7: Psychological Assessment",
    "section": "",
    "text": "This chapter focuses on Psychological Assessment and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 7: Psychological Assessment"
    ]
  },
  {
    "objectID": "Reading/chapter07.html#learning-objectives",
    "href": "Reading/chapter07.html#learning-objectives",
    "title": "Chapter 7: Psychological Assessment",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter reading this chapter, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 7: Psychological Assessment"
    ]
  },
  {
    "objectID": "Reading/chapter07.html#key-concepts",
    "href": "Reading/chapter07.html#key-concepts",
    "title": "Chapter 7: Psychological Assessment",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 7: Psychological Assessment"
    ]
  },
  {
    "objectID": "Reading/chapter07.html#summary",
    "href": "Reading/chapter07.html#summary",
    "title": "Chapter 7: Psychological Assessment",
    "section": "Summary",
    "text": "Summary\n[Brief summary of the chapter’s main points]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 7: Psychological Assessment"
    ]
  },
  {
    "objectID": "Reading/chapter07.html#critical-thinking-questions",
    "href": "Reading/chapter07.html#critical-thinking-questions",
    "title": "Chapter 7: Psychological Assessment",
    "section": "Critical Thinking Questions",
    "text": "Critical Thinking Questions\n\nHow does Psychological Assessment contribute to our understanding of psychological research?\nWhat are some potential challenges or limitations in applying Psychological Assessment to real-world research scenarios?\nHow might advances in technology or methodology impact our approach to Psychological Assessment in the future?",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 7: Psychological Assessment"
    ]
  },
  {
    "objectID": "Reading/chapter07.html#further-reading",
    "href": "Reading/chapter07.html#further-reading",
    "title": "Chapter 7: Psychological Assessment",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 7: Psychological Assessment"
    ]
  },
  {
    "objectID": "Reading/chapter09.html",
    "href": "Reading/chapter09.html",
    "title": "Chapter 9: ANOVA recap",
    "section": "",
    "text": "This chapter focuses on ANOVA recap and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 9: ANOVA recap"
    ]
  },
  {
    "objectID": "Reading/chapter09.html#chapter-overview",
    "href": "Reading/chapter09.html#chapter-overview",
    "title": "Chapter 9: ANOVA recap",
    "section": "",
    "text": "This chapter focuses on ANOVA recap and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 9: ANOVA recap"
    ]
  },
  {
    "objectID": "Reading/chapter09.html#learning-objectives",
    "href": "Reading/chapter09.html#learning-objectives",
    "title": "Chapter 9: ANOVA recap",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter reading this chapter, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 9: ANOVA recap"
    ]
  },
  {
    "objectID": "Reading/chapter09.html#key-concepts",
    "href": "Reading/chapter09.html#key-concepts",
    "title": "Chapter 9: ANOVA recap",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 9: ANOVA recap"
    ]
  },
  {
    "objectID": "Reading/chapter09.html#summary",
    "href": "Reading/chapter09.html#summary",
    "title": "Chapter 9: ANOVA recap",
    "section": "Summary",
    "text": "Summary\n[Brief summary of the chapter’s main points]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 9: ANOVA recap"
    ]
  },
  {
    "objectID": "Reading/chapter09.html#critical-thinking-questions",
    "href": "Reading/chapter09.html#critical-thinking-questions",
    "title": "Chapter 9: ANOVA recap",
    "section": "Critical Thinking Questions",
    "text": "Critical Thinking Questions\n\nHow does ANOVA recap contribute to our understanding of psychological research?\nWhat are some potential challenges or limitations in applying ANOVA recap to real-world research scenarios?\nHow might advances in technology or methodology impact our approach to ANOVA recap in the future?",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 9: ANOVA recap"
    ]
  },
  {
    "objectID": "Reading/chapter09.html#further-reading",
    "href": "Reading/chapter09.html#further-reading",
    "title": "Chapter 9: ANOVA recap",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 9: ANOVA recap"
    ]
  },
  {
    "objectID": "Reading/chapter18.html",
    "href": "Reading/chapter18.html",
    "title": "Chapter 18: Writing your MD | Discussion",
    "section": "",
    "text": "This chapter focuses on Writing your MD | Discussion and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 18: Writing your MD | Discussion"
    ]
  },
  {
    "objectID": "Reading/chapter18.html#chapter-overview",
    "href": "Reading/chapter18.html#chapter-overview",
    "title": "Chapter 18: Writing your MD | Discussion",
    "section": "",
    "text": "This chapter focuses on Writing your MD | Discussion and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 18: Writing your MD | Discussion"
    ]
  },
  {
    "objectID": "Reading/chapter18.html#learning-objectives",
    "href": "Reading/chapter18.html#learning-objectives",
    "title": "Chapter 18: Writing your MD | Discussion",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter reading this chapter, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 18: Writing your MD | Discussion"
    ]
  },
  {
    "objectID": "Reading/chapter18.html#key-concepts",
    "href": "Reading/chapter18.html#key-concepts",
    "title": "Chapter 18: Writing your MD | Discussion",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 18: Writing your MD | Discussion"
    ]
  },
  {
    "objectID": "Reading/chapter18.html#summary",
    "href": "Reading/chapter18.html#summary",
    "title": "Chapter 18: Writing your MD | Discussion",
    "section": "Summary",
    "text": "Summary\n[Brief summary of the chapter’s main points]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 18: Writing your MD | Discussion"
    ]
  },
  {
    "objectID": "Reading/chapter18.html#critical-thinking-questions",
    "href": "Reading/chapter18.html#critical-thinking-questions",
    "title": "Chapter 18: Writing your MD | Discussion",
    "section": "Critical Thinking Questions",
    "text": "Critical Thinking Questions\n\nHow does Writing your MD | Discussion contribute to our understanding of psychological research?\nWhat are some potential challenges or limitations in applying Writing your MD | Discussion to real-world research scenarios?\nHow might advances in technology or methodology impact our approach to Writing your MD | Discussion in the future?",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 18: Writing your MD | Discussion"
    ]
  },
  {
    "objectID": "Reading/chapter18.html#further-reading",
    "href": "Reading/chapter18.html#further-reading",
    "title": "Chapter 18: Writing your MD | Discussion",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 18: Writing your MD | Discussion"
    ]
  },
  {
    "objectID": "Reading/chapter11.html",
    "href": "Reading/chapter11.html",
    "title": "Chapter 11: Qualitative Research Methods",
    "section": "",
    "text": "This chapter focuses on Qualitative Research Methods and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 11: Qualitative Research Methods"
    ]
  },
  {
    "objectID": "Reading/chapter11.html#chapter-overview",
    "href": "Reading/chapter11.html#chapter-overview",
    "title": "Chapter 11: Qualitative Research Methods",
    "section": "",
    "text": "This chapter focuses on Qualitative Research Methods and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 11: Qualitative Research Methods"
    ]
  },
  {
    "objectID": "Reading/chapter11.html#learning-objectives",
    "href": "Reading/chapter11.html#learning-objectives",
    "title": "Chapter 11: Qualitative Research Methods",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter reading this chapter, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 11: Qualitative Research Methods"
    ]
  },
  {
    "objectID": "Reading/chapter11.html#key-concepts",
    "href": "Reading/chapter11.html#key-concepts",
    "title": "Chapter 11: Qualitative Research Methods",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 11: Qualitative Research Methods"
    ]
  },
  {
    "objectID": "Reading/chapter11.html#summary",
    "href": "Reading/chapter11.html#summary",
    "title": "Chapter 11: Qualitative Research Methods",
    "section": "Summary",
    "text": "Summary\n[Brief summary of the chapter’s main points]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 11: Qualitative Research Methods"
    ]
  },
  {
    "objectID": "Reading/chapter11.html#critical-thinking-questions",
    "href": "Reading/chapter11.html#critical-thinking-questions",
    "title": "Chapter 11: Qualitative Research Methods",
    "section": "Critical Thinking Questions",
    "text": "Critical Thinking Questions\n\nHow does Qualitative Research Methods contribute to our understanding of psychological research?\nWhat are some potential challenges or limitations in applying Qualitative Research Methods to real-world research scenarios?\nHow might advances in technology or methodology impact our approach to Qualitative Research Methods in the future?",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 11: Qualitative Research Methods"
    ]
  },
  {
    "objectID": "Reading/chapter11.html#further-reading",
    "href": "Reading/chapter11.html#further-reading",
    "title": "Chapter 11: Qualitative Research Methods",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 11: Qualitative Research Methods"
    ]
  },
  {
    "objectID": "Reading/chapter02.html",
    "href": "Reading/chapter02.html",
    "title": "Chapter 2: Developing Research Questions",
    "section": "",
    "text": "This chapter focuses on Developing Research Questions and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 2: Developing Research Questions"
    ]
  },
  {
    "objectID": "Reading/chapter02.html#chapter-overview",
    "href": "Reading/chapter02.html#chapter-overview",
    "title": "Chapter 2: Developing Research Questions",
    "section": "",
    "text": "This chapter focuses on Developing Research Questions and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 2: Developing Research Questions"
    ]
  },
  {
    "objectID": "Reading/chapter02.html#learning-objectives",
    "href": "Reading/chapter02.html#learning-objectives",
    "title": "Chapter 2: Developing Research Questions",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter reading this chapter, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 2: Developing Research Questions"
    ]
  },
  {
    "objectID": "Reading/chapter02.html#key-concepts",
    "href": "Reading/chapter02.html#key-concepts",
    "title": "Chapter 2: Developing Research Questions",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 2: Developing Research Questions"
    ]
  },
  {
    "objectID": "Reading/chapter02.html#summary",
    "href": "Reading/chapter02.html#summary",
    "title": "Chapter 2: Developing Research Questions",
    "section": "Summary",
    "text": "Summary\n[Brief summary of the chapter’s main points]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 2: Developing Research Questions"
    ]
  },
  {
    "objectID": "Reading/chapter02.html#critical-thinking-questions",
    "href": "Reading/chapter02.html#critical-thinking-questions",
    "title": "Chapter 2: Developing Research Questions",
    "section": "Critical Thinking Questions",
    "text": "Critical Thinking Questions\n\nHow does Developing Research Questions contribute to our understanding of psychological research?\nWhat are some potential challenges or limitations in applying Developing Research Questions to real-world research scenarios?\nHow might advances in technology or methodology impact our approach to Developing Research Questions in the future?",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 2: Developing Research Questions"
    ]
  },
  {
    "objectID": "Reading/chapter02.html#further-reading",
    "href": "Reading/chapter02.html#further-reading",
    "title": "Chapter 2: Developing Research Questions",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 2: Developing Research Questions"
    ]
  },
  {
    "objectID": "Reading/chapter13.html",
    "href": "Reading/chapter13.html",
    "title": "Chapter 13: Writing Qualitative Research Reports",
    "section": "",
    "text": "This chapter focuses on Writing Qualitative Research Reports and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 13: Writing Qualitative Research Reports"
    ]
  },
  {
    "objectID": "Reading/chapter13.html#chapter-overview",
    "href": "Reading/chapter13.html#chapter-overview",
    "title": "Chapter 13: Writing Qualitative Research Reports",
    "section": "",
    "text": "This chapter focuses on Writing Qualitative Research Reports and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 13: Writing Qualitative Research Reports"
    ]
  },
  {
    "objectID": "Reading/chapter13.html#learning-objectives",
    "href": "Reading/chapter13.html#learning-objectives",
    "title": "Chapter 13: Writing Qualitative Research Reports",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter reading this chapter, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 13: Writing Qualitative Research Reports"
    ]
  },
  {
    "objectID": "Reading/chapter13.html#key-concepts",
    "href": "Reading/chapter13.html#key-concepts",
    "title": "Chapter 13: Writing Qualitative Research Reports",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 13: Writing Qualitative Research Reports"
    ]
  },
  {
    "objectID": "Reading/chapter13.html#summary",
    "href": "Reading/chapter13.html#summary",
    "title": "Chapter 13: Writing Qualitative Research Reports",
    "section": "Summary",
    "text": "Summary\n[Brief summary of the chapter’s main points]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 13: Writing Qualitative Research Reports"
    ]
  },
  {
    "objectID": "Reading/chapter13.html#critical-thinking-questions",
    "href": "Reading/chapter13.html#critical-thinking-questions",
    "title": "Chapter 13: Writing Qualitative Research Reports",
    "section": "Critical Thinking Questions",
    "text": "Critical Thinking Questions\n\nHow does Writing Qualitative Research Reports contribute to our understanding of psychological research?\nWhat are some potential challenges or limitations in applying Writing Qualitative Research Reports to real-world research scenarios?\nHow might advances in technology or methodology impact our approach to Writing Qualitative Research Reports in the future?",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 13: Writing Qualitative Research Reports"
    ]
  },
  {
    "objectID": "Reading/chapter13.html#further-reading",
    "href": "Reading/chapter13.html#further-reading",
    "title": "Chapter 13: Writing Qualitative Research Reports",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 13: Writing Qualitative Research Reports"
    ]
  },
  {
    "objectID": "week03/chapter.html",
    "href": "week03/chapter.html",
    "title": "Chapter 2 - Week 2 Stuff",
    "section": "",
    "text": "insert week 2 stuff",
    "crumbs": [
      "Schedule",
      "Content",
      "Week03",
      "Chapter 2 - Week 2 Stuff"
    ]
  },
  {
    "objectID": "week03/chapter.html#week-2-stuff",
    "href": "week03/chapter.html#week-2-stuff",
    "title": "Chapter 2 - Week 2 Stuff",
    "section": "",
    "text": "insert week 2 stuff",
    "crumbs": [
      "Schedule",
      "Content",
      "Week03",
      "Chapter 2 - Week 2 Stuff"
    ]
  },
  {
    "objectID": "Reading/chapter04.html",
    "href": "Reading/chapter04.html",
    "title": "Chapter 4: Research Design in Psychology",
    "section": "",
    "text": "This chapter focuses on Research Design in Psychology and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 4: Research Design in Psychology"
    ]
  },
  {
    "objectID": "Reading/chapter04.html#chapter-overview",
    "href": "Reading/chapter04.html#chapter-overview",
    "title": "Chapter 4: Research Design in Psychology",
    "section": "",
    "text": "This chapter focuses on Research Design in Psychology and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 4: Research Design in Psychology"
    ]
  },
  {
    "objectID": "Reading/chapter04.html#learning-objectives",
    "href": "Reading/chapter04.html#learning-objectives",
    "title": "Chapter 4: Research Design in Psychology",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter reading this chapter, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 4: Research Design in Psychology"
    ]
  },
  {
    "objectID": "Reading/chapter04.html#key-concepts",
    "href": "Reading/chapter04.html#key-concepts",
    "title": "Chapter 4: Research Design in Psychology",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 4: Research Design in Psychology"
    ]
  },
  {
    "objectID": "Reading/chapter04.html#summary",
    "href": "Reading/chapter04.html#summary",
    "title": "Chapter 4: Research Design in Psychology",
    "section": "Summary",
    "text": "Summary\n[Brief summary of the chapter’s main points]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 4: Research Design in Psychology"
    ]
  },
  {
    "objectID": "Reading/chapter04.html#critical-thinking-questions",
    "href": "Reading/chapter04.html#critical-thinking-questions",
    "title": "Chapter 4: Research Design in Psychology",
    "section": "Critical Thinking Questions",
    "text": "Critical Thinking Questions\n\nHow does Research Design in Psychology contribute to our understanding of psychological research?\nWhat are some potential challenges or limitations in applying Research Design in Psychology to real-world research scenarios?\nHow might advances in technology or methodology impact our approach to Research Design in Psychology in the future?",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 4: Research Design in Psychology"
    ]
  },
  {
    "objectID": "Reading/chapter04.html#further-reading",
    "href": "Reading/chapter04.html#further-reading",
    "title": "Chapter 4: Research Design in Psychology",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 4: Research Design in Psychology"
    ]
  },
  {
    "objectID": "Reading/courseworkCHIP.html",
    "href": "Reading/courseworkCHIP.html",
    "title": "CHIP Learning Log",
    "section": "",
    "text": "Here’s an initial draft for the CHIP Learning Log briefing, covering the key elements and signposting areas for expansion or clarification:",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "CHIP Learning Log"
    ]
  },
  {
    "objectID": "Reading/courseworkCHIP.html#overview",
    "href": "Reading/courseworkCHIP.html#overview",
    "title": "CHIP Learning Log",
    "section": "Overview",
    "text": "Overview\nThe CHIP Learning Log is an opportunity for you to reflect on the conceptual, historical, and integrative perspectives covered during the year. It encourages you to engage deeply with the ideas presented in lectures and explore how they connect with your own development as a student, a future scientist, and a lifelong learner. The learning log is divided into two reflective accounts, allowing you to explore key topics from multiple perspectives and document your learning journey.\n\nKey Objectives:\n\nPresent two reflective accounts based on agreed-upon topics raised during the year.\nReflect on the relevance of psychology to your development as a scientist, a student, and an individual.\nDocument how your understanding of a chosen topic has evolved over time.\n\nA detailed rubric can be found [here].",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "CHIP Learning Log"
    ]
  },
  {
    "objectID": "Reading/courseworkCHIP.html#structure-and-requirements",
    "href": "Reading/courseworkCHIP.html#structure-and-requirements",
    "title": "CHIP Learning Log",
    "section": "Structure and Requirements",
    "text": "Structure and Requirements\n\n1. Two Reflective Accounts\nYou are required to submit two reflective accounts, each addressing different aspects of the course and your personal engagement with it. The reflections are not just summaries of the material but are intended to encourage critical thinking, personal reflection, and engagement with broader themes in psychology.\n\n\n2. Eligibility of Topics\nThe topics for your reflections must be proposed and agreed upon by the class. While this offers a great deal of flexibility, it is important that the topics are meaningful to you and fit within the broader themes explored during the course.\nAction Point:\nEarly in the year, keep track of lectures, readings, and discussions that resonate with you. Consider how they relate to your development as a psychology student or your future goals. Discuss potential topics with your peers and ensure they are approved.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "CHIP Learning Log"
    ]
  },
  {
    "objectID": "Reading/courseworkCHIP.html#first-reflective-account",
    "href": "Reading/courseworkCHIP.html#first-reflective-account",
    "title": "CHIP Learning Log",
    "section": "First Reflective Account",
    "text": "First Reflective Account\nThe first reflection must adopt two perspectives from the list below and engage with a topic raised during the year:\n\nAs a STUDENT of psychology: How has this topic influenced your understanding of psychology or your approach to learning?\nAs a TRAINEE psychologist: How does this topic relate to the skills and knowledge you are developing for future professional practice?\nIn relation to a RESEARCH application: How might this topic inform or inspire your future research endeavours?\nAs a HISTORIAN of psychology: What does this topic reveal about the development of psychological theories or practices over time?\nReporting on the CULTURE or PRACTICE of psychology: How does the topic reflect current trends or challenges in the field of psychology, either locally or across cultures?\nAs a critic or supporter of psychology’s status as a SCIENCE: Does this topic strengthen or weaken the argument that psychology is a rigorous science? Why?\n\nSignpost:\nChoose perspectives that resonate with you or reflect your aspirations as a psychology student or future psychologist. Ensure that your reflection is analytical, not just descriptive.\nGap:\nSome students may need more guidance on how to adopt multiple perspectives effectively. Providing examples of reflective writing could help clarify expectations.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "CHIP Learning Log"
    ]
  },
  {
    "objectID": "Reading/courseworkCHIP.html#second-reflective-account",
    "href": "Reading/courseworkCHIP.html#second-reflective-account",
    "title": "CHIP Learning Log",
    "section": "Second Reflective Account",
    "text": "Second Reflective Account\nThe second reflection focuses on one starting point—this could be a reading, TED Talk, cartoon, TikTok video, or another source of inspiration. From this starting point, you will log your journey of exploration into an approved topic. This reflection should focus on how your understanding has developed over time and the personal learning process you experienced.\n\nSuggested Approach:\n\nIdentify your starting point: Explain why this source resonated with you and how it links to the topic.\nDocument your learning journey: Describe how your understanding of the topic evolved as you explored it further. Did you encounter conflicting viewpoints, new theories, or surprising insights?\nReflect on your experience: How did you react to these new ideas? Did your initial assumptions change? What emotions or thoughts did the learning process evoke?\nConclude with your key takeaways: Summarize what you learned or rediscovered during this reflective process.\n\nExample:\nYou may start with a TED Talk on the replication crisis in psychology, which leads you to explore various debates in research methodology. Reflect on how your understanding of psychological science changed through this exploration and what this process taught you about the importance of research integrity.\nGap to address:\nProvide more examples of what might serve as an appropriate “starting point” and clarify how this should link back to course content.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "CHIP Learning Log"
    ]
  },
  {
    "objectID": "Reading/courseworkCHIP.html#writing-the-reflection",
    "href": "Reading/courseworkCHIP.html#writing-the-reflection",
    "title": "CHIP Learning Log",
    "section": "Writing the Reflection",
    "text": "Writing the Reflection\nWhen writing both reflective accounts, keep the following points in mind:\n\nTone and Style:\n\nReflective writing is personal, but it should still be analytical. You are not just recounting what happened; you are critiquing and exploring your thoughts, feelings, and reactions.\nUse the first person where appropriate, but balance this with academic rigour.\n\n\n\nStructure:\n\nIntroduction: Briefly introduce the topic and the perspectives or starting point.\nMain Body: Explore your chosen perspectives or journey in more detail. Ensure each reflection is well-structured and follows a logical progression.\nConclusion: Summarize your key insights and discuss how these reflections have influenced your development as a psychology student, future psychologist, or lifelong learner.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "CHIP Learning Log"
    ]
  },
  {
    "objectID": "Reading/courseworkCHIP.html#key-tips-for-success",
    "href": "Reading/courseworkCHIP.html#key-tips-for-success",
    "title": "CHIP Learning Log",
    "section": "Key Tips for Success",
    "text": "Key Tips for Success\n\nEngagement: Actively participate in lectures and class discussions to identify topics that resonate with you.\nDepth of Reflection: Go beyond summarizing course content. Use your reflections to critique, analyse, and engage with the broader themes of psychology.\nPersonal Connection: Consider how psychology as a discipline connects with your own development, both academically and personally. How do these reflections help shape your future goals as a psychologist or researcher?\nApproved Topics: Ensure that your topics are agreed upon by the class and relevant to the course materials.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "CHIP Learning Log"
    ]
  },
  {
    "objectID": "Reading/courseworkCHIP.html#final-thoughts",
    "href": "Reading/courseworkCHIP.html#final-thoughts",
    "title": "CHIP Learning Log",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nThe CHIP Learning Log is not just an academic exercise but an opportunity for you to reflect on your journey as a student and connect the ideas presented during the course to your own aspirations and understanding of psychology. Use this task to critically engage with psychology as a discipline, exploring both its challenges and its contributions to your development.\n\nThis draft lays out the key components of the CHIP Learning Log briefing. More specific guidance could be added for structuring the reflections, particularly in how to adopt multiple perspectives in the first reflective account. Providing examples or templates for reflective writing might also be useful for students new to this type of assessment.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "CHIP Learning Log"
    ]
  },
  {
    "objectID": "Reading/courseworkCHIP.html#rubric",
    "href": "Reading/courseworkCHIP.html#rubric",
    "title": "CHIP Learning Log",
    "section": "Rubric",
    "text": "Rubric",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "CHIP Learning Log"
    ]
  },
  {
    "objectID": "Reading/chapter17.html",
    "href": "Reading/chapter17.html",
    "title": "Chapter 17: Writing your MD | Results",
    "section": "",
    "text": "This chapter focuses on Writing your MD | Results and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 17: Writing your MD | Results"
    ]
  },
  {
    "objectID": "Reading/chapter17.html#chapter-overview",
    "href": "Reading/chapter17.html#chapter-overview",
    "title": "Chapter 17: Writing your MD | Results",
    "section": "",
    "text": "This chapter focuses on Writing your MD | Results and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 17: Writing your MD | Results"
    ]
  },
  {
    "objectID": "Reading/chapter17.html#learning-objectives",
    "href": "Reading/chapter17.html#learning-objectives",
    "title": "Chapter 17: Writing your MD | Results",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter reading this chapter, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 17: Writing your MD | Results"
    ]
  },
  {
    "objectID": "Reading/chapter17.html#key-concepts",
    "href": "Reading/chapter17.html#key-concepts",
    "title": "Chapter 17: Writing your MD | Results",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 17: Writing your MD | Results"
    ]
  },
  {
    "objectID": "Reading/chapter17.html#summary",
    "href": "Reading/chapter17.html#summary",
    "title": "Chapter 17: Writing your MD | Results",
    "section": "Summary",
    "text": "Summary\n[Brief summary of the chapter’s main points]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 17: Writing your MD | Results"
    ]
  },
  {
    "objectID": "Reading/chapter17.html#critical-thinking-questions",
    "href": "Reading/chapter17.html#critical-thinking-questions",
    "title": "Chapter 17: Writing your MD | Results",
    "section": "Critical Thinking Questions",
    "text": "Critical Thinking Questions\n\nHow does Writing your MD | Results contribute to our understanding of psychological research?\nWhat are some potential challenges or limitations in applying Writing your MD | Results to real-world research scenarios?\nHow might advances in technology or methodology impact our approach to Writing your MD | Results in the future?",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 17: Writing your MD | Results"
    ]
  },
  {
    "objectID": "Reading/chapter17.html#further-reading",
    "href": "Reading/chapter17.html#further-reading",
    "title": "Chapter 17: Writing your MD | Results",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 17: Writing your MD | Results"
    ]
  },
  {
    "objectID": "Reading/chapter01.html",
    "href": "Reading/chapter01.html",
    "title": "Chapter 1: Introduction to Psychological Research",
    "section": "",
    "text": "This chapter focuses on Introduction to Psychological Research and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 1: Introduction to Psychological Research"
    ]
  },
  {
    "objectID": "Reading/chapter01.html#chapter-overview",
    "href": "Reading/chapter01.html#chapter-overview",
    "title": "Chapter 1: Introduction to Psychological Research",
    "section": "",
    "text": "This chapter focuses on Introduction to Psychological Research and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 1: Introduction to Psychological Research"
    ]
  },
  {
    "objectID": "Reading/chapter01.html#learning-objectives",
    "href": "Reading/chapter01.html#learning-objectives",
    "title": "Chapter 1: Introduction to Psychological Research",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter reading this chapter, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 1: Introduction to Psychological Research"
    ]
  },
  {
    "objectID": "Reading/chapter01.html#key-concepts",
    "href": "Reading/chapter01.html#key-concepts",
    "title": "Chapter 1: Introduction to Psychological Research",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 1: Introduction to Psychological Research"
    ]
  },
  {
    "objectID": "Reading/chapter01.html#summary",
    "href": "Reading/chapter01.html#summary",
    "title": "Chapter 1: Introduction to Psychological Research",
    "section": "Summary",
    "text": "Summary\n[Brief summary of the chapter’s main points]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 1: Introduction to Psychological Research"
    ]
  },
  {
    "objectID": "Reading/chapter01.html#critical-thinking-questions",
    "href": "Reading/chapter01.html#critical-thinking-questions",
    "title": "Chapter 1: Introduction to Psychological Research",
    "section": "Critical Thinking Questions",
    "text": "Critical Thinking Questions\n\nHow does Introduction to Psychological Research contribute to our understanding of psychological research?\nWhat are some potential challenges or limitations in applying Introduction to Psychological Research to real-world research scenarios?\nHow might advances in technology or methodology impact our approach to Introduction to Psychological Research in the future?",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 1: Introduction to Psychological Research"
    ]
  },
  {
    "objectID": "Reading/chapter01.html#further-reading",
    "href": "Reading/chapter01.html#further-reading",
    "title": "Chapter 1: Introduction to Psychological Research",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 1: Introduction to Psychological Research"
    ]
  },
  {
    "objectID": "Reading/courseworkMD.html",
    "href": "Reading/courseworkMD.html",
    "title": "Mini-Dissertation",
    "section": "",
    "text": "Here’s an initial draft of your extended briefing for the Mini-Dissertation. I’ve added structure and signposted areas where more detail or guidance could be provided:",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Mini-Dissertation"
    ]
  },
  {
    "objectID": "Reading/courseworkMD.html#overview",
    "href": "Reading/courseworkMD.html#overview",
    "title": "Mini-Dissertation",
    "section": "Overview",
    "text": "Overview\nThe Mini-Dissertation is an integral part of your academic journey, contributing 70% of your module grade. It mirrors the structure of an APA lab report, similar to the reports you completed last year. However, in this task, nothing is pre-packaged – you and your group will make all the research decisions, with support from your teaching team, lab tutors, and personal tutors.\n\nKey Objectives:\n\nDuration: 20 weeks.\nGroup work: You will be working in a group of 3 or 4 students, but the project must be unique to your group.\nFocus: The project will require you to design and conduct an original psychological experiment.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Mini-Dissertation"
    ]
  },
  {
    "objectID": "Reading/courseworkMD.html#project-components",
    "href": "Reading/courseworkMD.html#project-components",
    "title": "Mini-Dissertation",
    "section": "Project Components",
    "text": "Project Components\n\n1. Identify an Area of Psychological Research\nYour first task is to select an area of research that interests you. This could be drawn from your past studies, ongoing debates in psychology, or gaps in the literature. You’ll need to ensure that this area lends itself to an experimental approach (using a 2x2 ANOVA design) and that it’s feasible within the timeframe and resources available.\nAction point:\nExplore journal articles or speak with your teaching team to help narrow down a research domain. Seek feedback from your lab tutors to confirm that the chosen area is appropriate.\n\n\n\n2. Literature Review and Critique\nOnce you’ve identified your research area, you will conduct a comprehensive literature review. This involves identifying relevant studies, summarizing their findings, critiquing their methodologies, and discussing how your project will build upon or diverge from the existing research.\nSuggested Outline: - Summarize key studies. - Identify methodological strengths and weaknesses. - Highlight unresolved issues or gaps in knowledge. - Justify how your experiment will address these issues.\nResources:\nMake use of the readings provided in your module, and ensure you use credible, peer-reviewed journal articles for your review.\n\n\n\n3. Design a 2x2 ANOVA Experiment\nThe experiment must follow a 2x2 factorial design, where you have two independent variables (IVs), each with two levels. This will allow for the examination of main effects and interaction effects between the variables. Importantly, your design should be unique to your group, even if other groups are working in the same general research area.\nConsiderations: - How do the IVs relate to the literature review? - How will you operationalize each variable? - What tools or resources will you need for data collection? - Can you feasibly recruit enough participants within the timeframe?\nGap to address:\nFurther guidance on common pitfalls in designing a 2x2 ANOVA experiment, especially if your group is unfamiliar with this type of analysis, could be beneficial.\n\n\n\n4. Develop a Testable Hypothesis\nYour hypothesis must be based on the literature you’ve reviewed and should clearly state what you expect to find in your 2x2 ANOVA. Ensure that it is testable and specific enough to guide your experiment.\nExample:\n“If IV1 and IV2 interact, participants in condition X will show significantly higher scores than in condition Y.”\nGap:\nIt would be helpful to provide more detailed guidance on formulating hypotheses, particularly for students who may struggle with writing testable predictions.\n\n\n\n5. Ethical Approval\nBefore any data collection, you will need to secure Ethical Approval. This involves submitting an ethics proposal outlining your study design, recruitment methods, data handling procedures, and how you will safeguard participant welfare.\nSignpost:\nWork closely with your lab tutor to ensure that your ethics submission is thorough. Templates and examples of successful applications may be made available, and students should adhere to institutional guidelines on ethical research practices.\n\n\n\n6. Data Collection\nYou will be required to collect REAL data for your experiment. This will involve recruiting participants, administering your experimental manipulations, and ensuring data is collected in a controlled, valid, and reliable manner.\nKey Tips: - Ensure consistency in administering your experiment across all participants. - Be prepared for potential challenges (e.g., low recruitment numbers, technical issues).\n\n\n\n7. Data Analysis: Conduct a 2x2 ANOVA\nOnce the data are collected, you will conduct a 2x2 ANOVA to test for main effects and interaction effects. This statistical analysis is essential to your Mini-Dissertation, so it’s important to understand the process.\nSupport:\nYou will have access to lab sessions and statistical support. Ensure that you attend these sessions and seek feedback if you are uncertain about your analysis.\n\n\n\n8. Write the APA Report\nYour report must be written in APA format and should not exceed 2,500 words (from the first word of the Introduction to the last word of the Discussion). You should include the following sections:\n\nTitle Page\nAbstract (150-250 words)\nIntroduction: Summarize your literature review, state your hypothesis, and justify the research.\nMethod: Describe the participants, materials, procedure, and design in detail.\nResults: Present your 2x2 ANOVA analysis, report the main effects and interactions, and include effect sizes.\nDiscussion: Interpret your findings, link back to the literature, and suggest implications for future research.\nReferences: APA-style references of the works cited.\n\n\n\n\n9. Supporting Materials\nAlong with your report, you must submit the following materials: - Open Data: The raw data you collected, anonymized where necessary. - Open Materials: Any instruments, surveys, or stimuli used in your experiment. - Critical Reflection (±300 words not included in 2,500 word limit of report - and you can write more if you wish): A brief statement reflecting on the decision-making process, challenges, and any adjustments that were made during the project.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Mini-Dissertation"
    ]
  },
  {
    "objectID": "Reading/courseworkMD.html#key-tips-for-success",
    "href": "Reading/courseworkMD.html#key-tips-for-success",
    "title": "Mini-Dissertation",
    "section": "Key Tips for Success",
    "text": "Key Tips for Success\n\nAttendance: Active participation in all group meetings and lab sessions is crucial.\nCollaboration: Work closely with your group members, but remember, the final write-up and some elements must be your individual work.\nReflection: Keep a reflective diary of decisions made, challenges faced, and changes in your understanding.\nConfidence: Mistakes are expected! The teaching team will not penalize you for early decisions that may seem ‘sub-optimal’.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Mini-Dissertation"
    ]
  },
  {
    "objectID": "Reading/courseworkMD.html#final-thoughts",
    "href": "Reading/courseworkMD.html#final-thoughts",
    "title": "Mini-Dissertation",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nThe Mini-Dissertation represents the culmination of the skills you’ve developed over the past year. While it may seem challenging, the extensive support materials and guidance provided are designed to help you every step of the way. The key to success is active engagement – from group discussions to lab sessions, don’t hesitate to ask for help when needed.\n\nThis draft provides a basic structure for the extended briefing. Additional information on specific challenges (e.g., ethical approval, data collection issues, and 2x2 ANOVA analysis) could be developed further, alongside advice on how to manage group dynamics and distribute responsibilities effectively.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Mini-Dissertation"
    ]
  },
  {
    "objectID": "Reading/courseworkMD.html#rubric",
    "href": "Reading/courseworkMD.html#rubric",
    "title": "Mini-Dissertation",
    "section": "Rubric",
    "text": "Rubric",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Mini-Dissertation"
    ]
  },
  {
    "objectID": "Reading/chapter15.html",
    "href": "Reading/chapter15.html",
    "title": "Chapter 15: Writing your MD | Lit Review & Intro",
    "section": "",
    "text": "This chapter focuses on Writing your MD | Lit Review & Intro and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 15: Writing your MD | Lit Review & Intro"
    ]
  },
  {
    "objectID": "Reading/chapter15.html#chapter-overview",
    "href": "Reading/chapter15.html#chapter-overview",
    "title": "Chapter 15: Writing your MD | Lit Review & Intro",
    "section": "",
    "text": "This chapter focuses on Writing your MD | Lit Review & Intro and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 15: Writing your MD | Lit Review & Intro"
    ]
  },
  {
    "objectID": "Reading/chapter15.html#learning-objectives",
    "href": "Reading/chapter15.html#learning-objectives",
    "title": "Chapter 15: Writing your MD | Lit Review & Intro",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter reading this chapter, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 15: Writing your MD | Lit Review & Intro"
    ]
  },
  {
    "objectID": "Reading/chapter15.html#key-concepts",
    "href": "Reading/chapter15.html#key-concepts",
    "title": "Chapter 15: Writing your MD | Lit Review & Intro",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 15: Writing your MD | Lit Review & Intro"
    ]
  },
  {
    "objectID": "Reading/chapter15.html#summary",
    "href": "Reading/chapter15.html#summary",
    "title": "Chapter 15: Writing your MD | Lit Review & Intro",
    "section": "Summary",
    "text": "Summary\n[Brief summary of the chapter’s main points]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 15: Writing your MD | Lit Review & Intro"
    ]
  },
  {
    "objectID": "Reading/chapter15.html#critical-thinking-questions",
    "href": "Reading/chapter15.html#critical-thinking-questions",
    "title": "Chapter 15: Writing your MD | Lit Review & Intro",
    "section": "Critical Thinking Questions",
    "text": "Critical Thinking Questions\n\nHow does Writing your MD | Lit Review & Intro contribute to our understanding of psychological research?\nWhat are some potential challenges or limitations in applying Writing your MD | Lit Review & Intro to real-world research scenarios?\nHow might advances in technology or methodology impact our approach to Writing your MD | Lit Review & Intro in the future?",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 15: Writing your MD | Lit Review & Intro"
    ]
  },
  {
    "objectID": "Reading/chapter15.html#further-reading",
    "href": "Reading/chapter15.html#further-reading",
    "title": "Chapter 15: Writing your MD | Lit Review & Intro",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 15: Writing your MD | Lit Review & Intro"
    ]
  },
  {
    "objectID": "Reading/chapter06.html",
    "href": "Reading/chapter06.html",
    "title": "Chapter 6: Open Science Practices",
    "section": "",
    "text": "This chapter focuses on Open Science Practices and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 6: Open Science Practices"
    ]
  },
  {
    "objectID": "Reading/chapter06.html#chapter-overview",
    "href": "Reading/chapter06.html#chapter-overview",
    "title": "Chapter 6: Open Science Practices",
    "section": "",
    "text": "This chapter focuses on Open Science Practices and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 6: Open Science Practices"
    ]
  },
  {
    "objectID": "Reading/chapter06.html#learning-objectives",
    "href": "Reading/chapter06.html#learning-objectives",
    "title": "Chapter 6: Open Science Practices",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter reading this chapter, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 6: Open Science Practices"
    ]
  },
  {
    "objectID": "Reading/chapter06.html#key-concepts",
    "href": "Reading/chapter06.html#key-concepts",
    "title": "Chapter 6: Open Science Practices",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 6: Open Science Practices"
    ]
  },
  {
    "objectID": "Reading/chapter06.html#summary",
    "href": "Reading/chapter06.html#summary",
    "title": "Chapter 6: Open Science Practices",
    "section": "Summary",
    "text": "Summary\n[Brief summary of the chapter’s main points]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 6: Open Science Practices"
    ]
  },
  {
    "objectID": "Reading/chapter06.html#critical-thinking-questions",
    "href": "Reading/chapter06.html#critical-thinking-questions",
    "title": "Chapter 6: Open Science Practices",
    "section": "Critical Thinking Questions",
    "text": "Critical Thinking Questions\n\nHow does Open Science Practices contribute to our understanding of psychological research?\nWhat are some potential challenges or limitations in applying Open Science Practices to real-world research scenarios?\nHow might advances in technology or methodology impact our approach to Open Science Practices in the future?",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 6: Open Science Practices"
    ]
  },
  {
    "objectID": "Reading/chapter06.html#further-reading",
    "href": "Reading/chapter06.html#further-reading",
    "title": "Chapter 6: Open Science Practices",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 6: Open Science Practices"
    ]
  },
  {
    "objectID": "Reading/coursework.html",
    "href": "Reading/coursework.html",
    "title": "Coursework for Research Methods PS52007D",
    "section": "",
    "text": "Here is information on the coursework.\n\n\nThis is a 30 credit module and you must complete attempts and pass all three coursework elements (Critical Proposal, Mini-Dissertation and CHIP Learning Log) in order to pass the module.\nThe module is anticipated to involve 300 hours of your time. This is a significant piece of work, and runs parallel to the rest of your programme. Time and project management is an integral part of this assessment.\n20 hours of lectures 40 hours of labs 240 hours of independent study (including literature search and review, reading, experimental design and development, data collection, analysis, interpretation of result and writing up) If you do not submit (or fail) any element, resubmission is possible by July 14th 2023.\nIf you do not pass at this point, resubmission (3rd attempt) would next be possible in March 2024 - meaning you would be eligible to enter year 3 in October 2024.\n\n\n\nYou are expected to attend and participate in your weekly labs and group work.\nAt the start of each lab session, you are required to complete the very short Lab ‘Pulses’ - brief check-in questionnaires - which will help us to monitor your well-being, your progress and survey the entire group for questions relevant to the module and forthcoming teaching.\nAt the end of each lab, you are given notice of the approaching end of the session and will be asked to document anything you feel is important and reflect on the progress made. These ‘generative activities’ are modest, extremely so, but will give you important information from which to develop an understanding of your learning - so called ‘metacognition’.\nModest milestones are in place throughout the course to help structure your efforts. Please listen to your Lab Tutors when they suggest these. They are not designed to be a burden, but rather to give you the best chance of success. It is common that you may not take them seriously, but in due course, it may become apparent that they were a good idea. The hope is that by having them in place this year, you can advisedly chose to include them in a project timeline for your Year 3 dissertation.\nThe coursework mentioned below has strict deadlines, with the normal RASA accommodations. If you will be using a RASA, please take the time to discuss it with the Teaching Team (in confidence) as on projects like your Mini-Dissertation, making use of various support is not something that happens right at the end of the process.\nApplications for Ethical approval (a compulsory step in the process of your Mini-Dissertation) are not permitted after the end of Term 1, and can be submitted at any time in Term 1, depending on your readiness.\nYou are not required to use your OneNote Lab Notebook apart from in a small number of very specific cases. Two examples are the Experimental Design page, and the Analysis Plan page. In these, you are asked to specify the design of your experiment and the analysis type you are going to use. These are important milestones, and ones that can often trip you up down the line, and we have learned that by ‘getting these down on paper’, you don’t second guess yourself, forget, or take a wrong turn at some point in the future.\n\n\n\nThe first deadline you have is the Critical Proposal.\nYou are asked to identify a peer-reviewed article from a Psychology journal which features a behavioural task or psychometric tool/measure which may be relevant to your research topic. You are asked to critically evaluate the paper, or a specific part of the paper (e.g. a single study out of a multi-study paper) and critically reflect on how you might consider building upon the strengths you outline, or improving on any weaknesses.\nThe mark is work 15% of the module grade and 70% of the mark is allocated towards the critical evaluation, with 30% being allocated towards the critical reflection and plans to develop your study.\nA detailed brief can be found here and a detailed rubric/marking guide can be found here\nLearning outcomes:\nTo encourage a deeper and more rigorous approach to reading published research Appraise the process of psychological research and assess the merits of particular studies Assess the reporting of research in published sources Critically reflect on how research practices may be improved, or strengths built upon, and the possible value of research increased in your forthcoming Mini-Dissertation nb. It is compulsory that you chose a peer-reviewed article. It must be an article that reports an empirical study (i.e. they collect and interpret data). It must be from a domain of psychology, and it must have an element that can feasible play a part in your study.\nIt is considered an error on your part to not give yourself time to consider if the paper you have chosen conforms to these parameters, and your Lab Tutor is able to assist you very overtly. It is encouraged. Choosing a good paper is part of the assessment.\n\n\n\nYour Mini-Dissertation is absolutely identical in structure and function to a normal APA lab-report - the type you did 3 of last year. The only difference is that nothing comes ‘ready-made’. To assist you in this process, you will have your group (3 or 4 student ONLY). You will have your Teaching Team (MC and LTs) and you will have your Personal Tutors cheering you on.\nThe Mini-Dissertation is worth 70% of your module grade.\nOver the course of 20 weeks, you will:\nIdentify an area of psychological research Review and critique the literature in this area Design a 2x2 ANOVA experiment that is unique to you but mobilised in your group. Develop a testable hypothesis Obtain Ethical Approval for your experiment Collect REAL data Analyse these data Write up the results in APA format report of no more than 2,500 words in length from first word of the Introduction to the last word of the Discussion Submit supporting materials (Open Data, Open Materials and a very modest Critical Reflection ± 200 words) A detailed rubric can be found here\nExtensive supporting materials are provided and you will be supported every step of the way. The only way you can have problems is by not contributing or attending. You are going to make lots of decisions, individually and as a group, and some may be ones that you later reflect on as ‘sub-optimal’ - fantastic. If you aren’t making mistakes, you aren’t doing it right. We do not let anyone impair their marks for decisions made early in the process. Please have confidence in that. Jump in!\n\n\n\nCHIP stands for Conceptual, Historical and Integrative Perspectives.\nDuring the course of the year, a range of concepts, debates and questions will be posed and presented in the lectures. Hopefully we will explore topics that are meaningful and salient to you as a group and as burgeoning scientists.\nOver the course of the year, we want you to consider these concepts, engage with these debates, or reflect on questions around how Psychology contributes or conflicts with you as an individual, a future scientist, or a developing life-long learner.\nA detailed rubric can be found here\nYou are asked to present 2 ‘reflections’ on topics raised during the year.\nTo be eligible as a ‘topic’ this must be proposed and agreed by the class, but it is as open as that.\nThe first reflective account requires you to adopt 2 perspectives from the following list and reflect on any of the topics raised during the year:\nAs a STUDENT of psychology As a TRAINEE psychologist In relation to a RESEARCH application in your future As an HISTORIAN of psychology Reporting on the culture or PRACTICE of psychology as it currently exists here or across cultures As a critic or supporter of psychology’s status as a SCIENCE The second reflective account takes a single identified starting point (a reading, a TED talk, a cartoon or TikTok video etc) but then logs your journey of exploration into an approved topic. How has your understanding developed? How did you pursue this idea? What reactions did you experience to new ideas? What have you learned or re-discovered during this process of learning?",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Coursework for Research Methods PS52007D"
    ]
  },
  {
    "objectID": "Reading/coursework.html#module-weight-and-progression-requirements",
    "href": "Reading/coursework.html#module-weight-and-progression-requirements",
    "title": "Coursework for Research Methods PS52007D",
    "section": "",
    "text": "This is a 30 credit module and you must complete attempts and pass all three coursework elements (Critical Proposal, Mini-Dissertation and CHIP Learning Log) in order to pass the module.\nThe module is anticipated to involve 300 hours of your time. This is a significant piece of work, and runs parallel to the rest of your programme. Time and project management is an integral part of this assessment.\n20 hours of lectures 40 hours of labs 240 hours of independent study (including literature search and review, reading, experimental design and development, data collection, analysis, interpretation of result and writing up) If you do not submit (or fail) any element, resubmission is possible by July 14th 2023.\nIf you do not pass at this point, resubmission (3rd attempt) would next be possible in March 2024 - meaning you would be eligible to enter year 3 in October 2024.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Coursework for Research Methods PS52007D"
    ]
  },
  {
    "objectID": "Reading/coursework.html#attendance-and-participation",
    "href": "Reading/coursework.html#attendance-and-participation",
    "title": "Coursework for Research Methods PS52007D",
    "section": "",
    "text": "You are expected to attend and participate in your weekly labs and group work.\nAt the start of each lab session, you are required to complete the very short Lab ‘Pulses’ - brief check-in questionnaires - which will help us to monitor your well-being, your progress and survey the entire group for questions relevant to the module and forthcoming teaching.\nAt the end of each lab, you are given notice of the approaching end of the session and will be asked to document anything you feel is important and reflect on the progress made. These ‘generative activities’ are modest, extremely so, but will give you important information from which to develop an understanding of your learning - so called ‘metacognition’.\nModest milestones are in place throughout the course to help structure your efforts. Please listen to your Lab Tutors when they suggest these. They are not designed to be a burden, but rather to give you the best chance of success. It is common that you may not take them seriously, but in due course, it may become apparent that they were a good idea. The hope is that by having them in place this year, you can advisedly chose to include them in a project timeline for your Year 3 dissertation.\nThe coursework mentioned below has strict deadlines, with the normal RASA accommodations. If you will be using a RASA, please take the time to discuss it with the Teaching Team (in confidence) as on projects like your Mini-Dissertation, making use of various support is not something that happens right at the end of the process.\nApplications for Ethical approval (a compulsory step in the process of your Mini-Dissertation) are not permitted after the end of Term 1, and can be submitted at any time in Term 1, depending on your readiness.\nYou are not required to use your OneNote Lab Notebook apart from in a small number of very specific cases. Two examples are the Experimental Design page, and the Analysis Plan page. In these, you are asked to specify the design of your experiment and the analysis type you are going to use. These are important milestones, and ones that can often trip you up down the line, and we have learned that by ‘getting these down on paper’, you don’t second guess yourself, forget, or take a wrong turn at some point in the future.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Coursework for Research Methods PS52007D"
    ]
  },
  {
    "objectID": "Reading/coursework.html#critical-proposal---1800-words-15-due-12pm-midday-1st-november-2024-end-of-wk-5",
    "href": "Reading/coursework.html#critical-proposal---1800-words-15-due-12pm-midday-1st-november-2024-end-of-wk-5",
    "title": "Coursework for Research Methods PS52007D",
    "section": "",
    "text": "The first deadline you have is the Critical Proposal.\nYou are asked to identify a peer-reviewed article from a Psychology journal which features a behavioural task or psychometric tool/measure which may be relevant to your research topic. You are asked to critically evaluate the paper, or a specific part of the paper (e.g. a single study out of a multi-study paper) and critically reflect on how you might consider building upon the strengths you outline, or improving on any weaknesses.\nThe mark is work 15% of the module grade and 70% of the mark is allocated towards the critical evaluation, with 30% being allocated towards the critical reflection and plans to develop your study.\nA detailed brief can be found here and a detailed rubric/marking guide can be found here\nLearning outcomes:\nTo encourage a deeper and more rigorous approach to reading published research Appraise the process of psychological research and assess the merits of particular studies Assess the reporting of research in published sources Critically reflect on how research practices may be improved, or strengths built upon, and the possible value of research increased in your forthcoming Mini-Dissertation nb. It is compulsory that you chose a peer-reviewed article. It must be an article that reports an empirical study (i.e. they collect and interpret data). It must be from a domain of psychology, and it must have an element that can feasible play a part in your study.\nIt is considered an error on your part to not give yourself time to consider if the paper you have chosen conforms to these parameters, and your Lab Tutor is able to assist you very overtly. It is encouraged. Choosing a good paper is part of the assessment.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Coursework for Research Methods PS52007D"
    ]
  },
  {
    "objectID": "Reading/coursework.html#mini-dissertation---2500-word-apa-format-labreport-with-open-data-open-materials-and-reflective-account---due-12pm-midday-28th-march-2025-end-of-week-20",
    "href": "Reading/coursework.html#mini-dissertation---2500-word-apa-format-labreport-with-open-data-open-materials-and-reflective-account---due-12pm-midday-28th-march-2025-end-of-week-20",
    "title": "Coursework for Research Methods PS52007D",
    "section": "",
    "text": "Your Mini-Dissertation is absolutely identical in structure and function to a normal APA lab-report - the type you did 3 of last year. The only difference is that nothing comes ‘ready-made’. To assist you in this process, you will have your group (3 or 4 student ONLY). You will have your Teaching Team (MC and LTs) and you will have your Personal Tutors cheering you on.\nThe Mini-Dissertation is worth 70% of your module grade.\nOver the course of 20 weeks, you will:\nIdentify an area of psychological research Review and critique the literature in this area Design a 2x2 ANOVA experiment that is unique to you but mobilised in your group. Develop a testable hypothesis Obtain Ethical Approval for your experiment Collect REAL data Analyse these data Write up the results in APA format report of no more than 2,500 words in length from first word of the Introduction to the last word of the Discussion Submit supporting materials (Open Data, Open Materials and a very modest Critical Reflection ± 200 words) A detailed rubric can be found here\nExtensive supporting materials are provided and you will be supported every step of the way. The only way you can have problems is by not contributing or attending. You are going to make lots of decisions, individually and as a group, and some may be ones that you later reflect on as ‘sub-optimal’ - fantastic. If you aren’t making mistakes, you aren’t doing it right. We do not let anyone impair their marks for decisions made early in the process. Please have confidence in that. Jump in!",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Coursework for Research Methods PS52007D"
    ]
  },
  {
    "objectID": "Reading/coursework.html#chip-learning-log---2x-600-word-reflective-accounts-on-different-topics-with-references---due-12pm-midday-11th-april-2025-weeks-after-end-of-term-2",
    "href": "Reading/coursework.html#chip-learning-log---2x-600-word-reflective-accounts-on-different-topics-with-references---due-12pm-midday-11th-april-2025-weeks-after-end-of-term-2",
    "title": "Coursework for Research Methods PS52007D",
    "section": "",
    "text": "CHIP stands for Conceptual, Historical and Integrative Perspectives.\nDuring the course of the year, a range of concepts, debates and questions will be posed and presented in the lectures. Hopefully we will explore topics that are meaningful and salient to you as a group and as burgeoning scientists.\nOver the course of the year, we want you to consider these concepts, engage with these debates, or reflect on questions around how Psychology contributes or conflicts with you as an individual, a future scientist, or a developing life-long learner.\nA detailed rubric can be found here\nYou are asked to present 2 ‘reflections’ on topics raised during the year.\nTo be eligible as a ‘topic’ this must be proposed and agreed by the class, but it is as open as that.\nThe first reflective account requires you to adopt 2 perspectives from the following list and reflect on any of the topics raised during the year:\nAs a STUDENT of psychology As a TRAINEE psychologist In relation to a RESEARCH application in your future As an HISTORIAN of psychology Reporting on the culture or PRACTICE of psychology as it currently exists here or across cultures As a critic or supporter of psychology’s status as a SCIENCE The second reflective account takes a single identified starting point (a reading, a TED talk, a cartoon or TikTok video etc) but then logs your journey of exploration into an approved topic. How has your understanding developed? How did you pursue this idea? What reactions did you experience to new ideas? What have you learned or re-discovered during this process of learning?",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Coursework for Research Methods PS52007D"
    ]
  },
  {
    "objectID": "Reading/chapter08.html",
    "href": "Reading/chapter08.html",
    "title": "Chapter 8: Ethics Deep Dive",
    "section": "",
    "text": "This chapter focuses on Ethics Deep Dive and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 8: Ethics Deep Dive"
    ]
  },
  {
    "objectID": "Reading/chapter08.html#chapter-overview",
    "href": "Reading/chapter08.html#chapter-overview",
    "title": "Chapter 8: Ethics Deep Dive",
    "section": "",
    "text": "This chapter focuses on Ethics Deep Dive and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 8: Ethics Deep Dive"
    ]
  },
  {
    "objectID": "Reading/chapter08.html#learning-objectives",
    "href": "Reading/chapter08.html#learning-objectives",
    "title": "Chapter 8: Ethics Deep Dive",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter reading this chapter, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 8: Ethics Deep Dive"
    ]
  },
  {
    "objectID": "Reading/chapter08.html#key-concepts",
    "href": "Reading/chapter08.html#key-concepts",
    "title": "Chapter 8: Ethics Deep Dive",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 8: Ethics Deep Dive"
    ]
  },
  {
    "objectID": "Reading/chapter08.html#summary",
    "href": "Reading/chapter08.html#summary",
    "title": "Chapter 8: Ethics Deep Dive",
    "section": "Summary",
    "text": "Summary\n[Brief summary of the chapter’s main points]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 8: Ethics Deep Dive"
    ]
  },
  {
    "objectID": "Reading/chapter08.html#critical-thinking-questions",
    "href": "Reading/chapter08.html#critical-thinking-questions",
    "title": "Chapter 8: Ethics Deep Dive",
    "section": "Critical Thinking Questions",
    "text": "Critical Thinking Questions\n\nHow does Ethics Deep Dive contribute to our understanding of psychological research?\nWhat are some potential challenges or limitations in applying Ethics Deep Dive to real-world research scenarios?\nHow might advances in technology or methodology impact our approach to Ethics Deep Dive in the future?",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 8: Ethics Deep Dive"
    ]
  },
  {
    "objectID": "Reading/chapter08.html#further-reading",
    "href": "Reading/chapter08.html#further-reading",
    "title": "Chapter 8: Ethics Deep Dive",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 8: Ethics Deep Dive"
    ]
  },
  {
    "objectID": "Reading/chapter16.html",
    "href": "Reading/chapter16.html",
    "title": "Chapter 16: Writing your MD | Methods",
    "section": "",
    "text": "This chapter focuses on Writing your MD | Methods and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 16: Writing your MD | Methods"
    ]
  },
  {
    "objectID": "Reading/chapter16.html#chapter-overview",
    "href": "Reading/chapter16.html#chapter-overview",
    "title": "Chapter 16: Writing your MD | Methods",
    "section": "",
    "text": "This chapter focuses on Writing your MD | Methods and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 16: Writing your MD | Methods"
    ]
  },
  {
    "objectID": "Reading/chapter16.html#learning-objectives",
    "href": "Reading/chapter16.html#learning-objectives",
    "title": "Chapter 16: Writing your MD | Methods",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter reading this chapter, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 16: Writing your MD | Methods"
    ]
  },
  {
    "objectID": "Reading/chapter16.html#key-concepts",
    "href": "Reading/chapter16.html#key-concepts",
    "title": "Chapter 16: Writing your MD | Methods",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 16: Writing your MD | Methods"
    ]
  },
  {
    "objectID": "Reading/chapter16.html#summary",
    "href": "Reading/chapter16.html#summary",
    "title": "Chapter 16: Writing your MD | Methods",
    "section": "Summary",
    "text": "Summary\n[Brief summary of the chapter’s main points]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 16: Writing your MD | Methods"
    ]
  },
  {
    "objectID": "Reading/chapter16.html#critical-thinking-questions",
    "href": "Reading/chapter16.html#critical-thinking-questions",
    "title": "Chapter 16: Writing your MD | Methods",
    "section": "Critical Thinking Questions",
    "text": "Critical Thinking Questions\n\nHow does Writing your MD | Methods contribute to our understanding of psychological research?\nWhat are some potential challenges or limitations in applying Writing your MD | Methods to real-world research scenarios?\nHow might advances in technology or methodology impact our approach to Writing your MD | Methods in the future?",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 16: Writing your MD | Methods"
    ]
  },
  {
    "objectID": "Reading/chapter16.html#further-reading",
    "href": "Reading/chapter16.html#further-reading",
    "title": "Chapter 16: Writing your MD | Methods",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 16: Writing your MD | Methods"
    ]
  },
  {
    "objectID": "Reading/chapter20.html",
    "href": "Reading/chapter20.html",
    "title": "Chapter 20: A review of the year and what you have achieved",
    "section": "",
    "text": "This chapter focuses on A review of the year and what you have achieved and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 20: A review of the year and what you have achieved"
    ]
  },
  {
    "objectID": "Reading/chapter20.html#chapter-overview",
    "href": "Reading/chapter20.html#chapter-overview",
    "title": "Chapter 20: A review of the year and what you have achieved",
    "section": "",
    "text": "This chapter focuses on A review of the year and what you have achieved and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 20: A review of the year and what you have achieved"
    ]
  },
  {
    "objectID": "Reading/chapter20.html#learning-objectives",
    "href": "Reading/chapter20.html#learning-objectives",
    "title": "Chapter 20: A review of the year and what you have achieved",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter reading this chapter, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 20: A review of the year and what you have achieved"
    ]
  },
  {
    "objectID": "Reading/chapter20.html#key-concepts",
    "href": "Reading/chapter20.html#key-concepts",
    "title": "Chapter 20: A review of the year and what you have achieved",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 20: A review of the year and what you have achieved"
    ]
  },
  {
    "objectID": "Reading/chapter20.html#summary",
    "href": "Reading/chapter20.html#summary",
    "title": "Chapter 20: A review of the year and what you have achieved",
    "section": "Summary",
    "text": "Summary\n[Brief summary of the chapter’s main points]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 20: A review of the year and what you have achieved"
    ]
  },
  {
    "objectID": "Reading/chapter20.html#critical-thinking-questions",
    "href": "Reading/chapter20.html#critical-thinking-questions",
    "title": "Chapter 20: A review of the year and what you have achieved",
    "section": "Critical Thinking Questions",
    "text": "Critical Thinking Questions\n\nHow does A review of the year and what you have achieved contribute to our understanding of psychological research?\nWhat are some potential challenges or limitations in applying A review of the year and what you have achieved to real-world research scenarios?\nHow might advances in technology or methodology impact our approach to A review of the year and what you have achieved in the future?",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 20: A review of the year and what you have achieved"
    ]
  },
  {
    "objectID": "Reading/chapter20.html#further-reading",
    "href": "Reading/chapter20.html#further-reading",
    "title": "Chapter 20: A review of the year and what you have achieved",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 20: A review of the year and what you have achieved"
    ]
  },
  {
    "objectID": "Reading/chapter19.html",
    "href": "Reading/chapter19.html",
    "title": "Chapter 19: Writing your MD | Everything else",
    "section": "",
    "text": "This chapter focuses on Writing your MD | Everything else and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 19: Writing your MD | Everything else"
    ]
  },
  {
    "objectID": "Reading/chapter19.html#chapter-overview",
    "href": "Reading/chapter19.html#chapter-overview",
    "title": "Chapter 19: Writing your MD | Everything else",
    "section": "",
    "text": "This chapter focuses on Writing your MD | Everything else and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 19: Writing your MD | Everything else"
    ]
  },
  {
    "objectID": "Reading/chapter19.html#learning-objectives",
    "href": "Reading/chapter19.html#learning-objectives",
    "title": "Chapter 19: Writing your MD | Everything else",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter reading this chapter, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 19: Writing your MD | Everything else"
    ]
  },
  {
    "objectID": "Reading/chapter19.html#key-concepts",
    "href": "Reading/chapter19.html#key-concepts",
    "title": "Chapter 19: Writing your MD | Everything else",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 19: Writing your MD | Everything else"
    ]
  },
  {
    "objectID": "Reading/chapter19.html#summary",
    "href": "Reading/chapter19.html#summary",
    "title": "Chapter 19: Writing your MD | Everything else",
    "section": "Summary",
    "text": "Summary\n[Brief summary of the chapter’s main points]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 19: Writing your MD | Everything else"
    ]
  },
  {
    "objectID": "Reading/chapter19.html#critical-thinking-questions",
    "href": "Reading/chapter19.html#critical-thinking-questions",
    "title": "Chapter 19: Writing your MD | Everything else",
    "section": "Critical Thinking Questions",
    "text": "Critical Thinking Questions\n\nHow does Writing your MD | Everything else contribute to our understanding of psychological research?\nWhat are some potential challenges or limitations in applying Writing your MD | Everything else to real-world research scenarios?\nHow might advances in technology or methodology impact our approach to Writing your MD | Everything else in the future?",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 19: Writing your MD | Everything else"
    ]
  },
  {
    "objectID": "Reading/chapter19.html#further-reading",
    "href": "Reading/chapter19.html#further-reading",
    "title": "Chapter 19: Writing your MD | Everything else",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "Reading",
      "Chapter 19: Writing your MD | Everything else"
    ]
  },
  {
    "objectID": "CHIP/overview.html",
    "href": "CHIP/overview.html",
    "title": "CHIP Listings",
    "section": "",
    "text": "It’s chips babies.\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\nReading Time\n\n\n\n\n\n\n\n\n\nFeb 10, 2025\n\n\nCognitive enhancement via drugs and implants\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nFeb 3, 2025\n\n\nStanford Prison and Milgram - how do classic studies fare?\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nJan 27, 2025\n\n\nCan I opt out of informed consent?\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nJan 20, 2025\n\n\nThe Ethics of Nudging\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nJan 13, 2025\n\n\nWhere is Psychology’s non-stick frying pan?\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nJan 6, 2025\n\n\nWhat stage is Psychology at?\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nDec 30, 2024\n\n\nHow to police and punish Scientific malpractice?\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nDec 23, 2024\n\n\nThe Role of Subjectivity in Qualitative Research\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nDec 16, 2024\n\n\nIs Thematic Analysis a method or a tool?\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nDec 9, 2024\n\n\nIdiographic nomothetic divide\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nDec 2, 2024\n\n\nThe WEIRD Problem in Psychology\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nNov 25, 2024\n\n\nWhat does Psychology have to say about AI?\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nNov 18, 2024\n\n\nThe Role of IQ Tests in Psychology\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nNov 11, 2024\n\n\nValidity and Reliability in Psychological Measurement\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nNov 4, 2024\n\n\nReproducibility in Psychological Science\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nOct 28, 2024\n\n\nEthical Considerations in Psychological Research\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nOct 21, 2024\n\n\nNature vs. Nurture Debate\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nOct 14, 2024\n\n\nReplication Crisis in Psychology\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nOct 7, 2024\n\n\nSociology of Science\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nSep 30, 2024\n\n\nPhilosophy of Science\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nSep 12, 2024\n\n\nExemplary Title for a CHIP topic\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "CHIP Listings"
    ]
  },
  {
    "objectID": "CHIP/overview.html#chip-from-top-to-bottom",
    "href": "CHIP/overview.html#chip-from-top-to-bottom",
    "title": "CHIP Listings",
    "section": "",
    "text": "It’s chips babies.\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\nReading Time\n\n\n\n\n\n\n\n\n\nFeb 10, 2025\n\n\nCognitive enhancement via drugs and implants\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nFeb 3, 2025\n\n\nStanford Prison and Milgram - how do classic studies fare?\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nJan 27, 2025\n\n\nCan I opt out of informed consent?\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nJan 20, 2025\n\n\nThe Ethics of Nudging\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nJan 13, 2025\n\n\nWhere is Psychology’s non-stick frying pan?\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nJan 6, 2025\n\n\nWhat stage is Psychology at?\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nDec 30, 2024\n\n\nHow to police and punish Scientific malpractice?\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nDec 23, 2024\n\n\nThe Role of Subjectivity in Qualitative Research\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nDec 16, 2024\n\n\nIs Thematic Analysis a method or a tool?\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nDec 9, 2024\n\n\nIdiographic nomothetic divide\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nDec 2, 2024\n\n\nThe WEIRD Problem in Psychology\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nNov 25, 2024\n\n\nWhat does Psychology have to say about AI?\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nNov 18, 2024\n\n\nThe Role of IQ Tests in Psychology\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nNov 11, 2024\n\n\nValidity and Reliability in Psychological Measurement\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nNov 4, 2024\n\n\nReproducibility in Psychological Science\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nOct 28, 2024\n\n\nEthical Considerations in Psychological Research\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nOct 21, 2024\n\n\nNature vs. Nurture Debate\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nOct 14, 2024\n\n\nReplication Crisis in Psychology\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nOct 7, 2024\n\n\nSociology of Science\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nSep 30, 2024\n\n\nPhilosophy of Science\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\n\n\nSep 12, 2024\n\n\nExemplary Title for a CHIP topic\n\n\nDr. Gordon Wright\n\n\n1 min\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "CHIP Listings"
    ]
  },
  {
    "objectID": "CHIP/topics/topic02.html",
    "href": "CHIP/topics/topic02.html",
    "title": "Sociology of Science",
    "section": "",
    "text": "Sociology of Science",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Sociology of Science"
    ]
  },
  {
    "objectID": "CHIP/topics/topic02.html#chip-topic",
    "href": "CHIP/topics/topic02.html#chip-topic",
    "title": "Sociology of Science",
    "section": "",
    "text": "Sociology of Science",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Sociology of Science"
    ]
  },
  {
    "objectID": "CHIP/topics/topic02.html#overview",
    "href": "CHIP/topics/topic02.html#overview",
    "title": "Sociology of Science",
    "section": "Overview",
    "text": "Overview\nThis week we will explore Sociology of Science and its implications for psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Sociology of Science"
    ]
  },
  {
    "objectID": "CHIP/topics/topic02.html#key-points",
    "href": "CHIP/topics/topic02.html#key-points",
    "title": "Sociology of Science",
    "section": "Key Points",
    "text": "Key Points\n\n[Key point 1]\n[Key point 2]\n[Key point 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Sociology of Science"
    ]
  },
  {
    "objectID": "CHIP/topics/topic02.html#discussion-questions",
    "href": "CHIP/topics/topic02.html#discussion-questions",
    "title": "Sociology of Science",
    "section": "Discussion Questions",
    "text": "Discussion Questions\n\nHow does Sociology of Science influence our understanding of psychological phenomena?\nWhat are the main challenges in addressing Sociology of Science in psychological research?\nHow can researchers better incorporate considerations of Sociology of Science in their work?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Sociology of Science"
    ]
  },
  {
    "objectID": "CHIP/topics/topic02.html#further-reading",
    "href": "CHIP/topics/topic02.html#further-reading",
    "title": "Sociology of Science",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Sociology of Science"
    ]
  },
  {
    "objectID": "CHIP/topics/topic11.html",
    "href": "CHIP/topics/topic11.html",
    "title": "Idiographic nomothetic divide",
    "section": "",
    "text": "Idiographic nomothetic divide",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Idiographic nomothetic divide"
    ]
  },
  {
    "objectID": "CHIP/topics/topic11.html#chip-topic",
    "href": "CHIP/topics/topic11.html#chip-topic",
    "title": "Idiographic nomothetic divide",
    "section": "",
    "text": "Idiographic nomothetic divide",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Idiographic nomothetic divide"
    ]
  },
  {
    "objectID": "CHIP/topics/topic11.html#overview",
    "href": "CHIP/topics/topic11.html#overview",
    "title": "Idiographic nomothetic divide",
    "section": "Overview",
    "text": "Overview\nThis week we will explore Idiographic nomothetic divide and its implications for psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Idiographic nomothetic divide"
    ]
  },
  {
    "objectID": "CHIP/topics/topic11.html#key-points",
    "href": "CHIP/topics/topic11.html#key-points",
    "title": "Idiographic nomothetic divide",
    "section": "Key Points",
    "text": "Key Points\n\n[Key point 1]\n[Key point 2]\n[Key point 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Idiographic nomothetic divide"
    ]
  },
  {
    "objectID": "CHIP/topics/topic11.html#discussion-questions",
    "href": "CHIP/topics/topic11.html#discussion-questions",
    "title": "Idiographic nomothetic divide",
    "section": "Discussion Questions",
    "text": "Discussion Questions\n\nHow does Idiographic nomothetic divide influence our understanding of psychological phenomena?\nWhat are the main challenges in addressing Idiographic nomothetic divide in psychological research?\nHow can researchers better incorporate considerations of Idiographic nomothetic divide in their work?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Idiographic nomothetic divide"
    ]
  },
  {
    "objectID": "CHIP/topics/topic11.html#further-reading",
    "href": "CHIP/topics/topic11.html#further-reading",
    "title": "Idiographic nomothetic divide",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Idiographic nomothetic divide"
    ]
  },
  {
    "objectID": "CHIP/topics/topic17.html",
    "href": "CHIP/topics/topic17.html",
    "title": "The Ethics of Nudging",
    "section": "",
    "text": "The Ethics of Nudging",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The Ethics of Nudging"
    ]
  },
  {
    "objectID": "CHIP/topics/topic17.html#chip-topic",
    "href": "CHIP/topics/topic17.html#chip-topic",
    "title": "The Ethics of Nudging",
    "section": "",
    "text": "The Ethics of Nudging",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The Ethics of Nudging"
    ]
  },
  {
    "objectID": "CHIP/topics/topic17.html#overview",
    "href": "CHIP/topics/topic17.html#overview",
    "title": "The Ethics of Nudging",
    "section": "Overview",
    "text": "Overview\nThis week we will explore The Ethics of Nudging and its implications for psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The Ethics of Nudging"
    ]
  },
  {
    "objectID": "CHIP/topics/topic17.html#key-points",
    "href": "CHIP/topics/topic17.html#key-points",
    "title": "The Ethics of Nudging",
    "section": "Key Points",
    "text": "Key Points\n\n[Key point 1]\n[Key point 2]\n[Key point 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The Ethics of Nudging"
    ]
  },
  {
    "objectID": "CHIP/topics/topic17.html#discussion-questions",
    "href": "CHIP/topics/topic17.html#discussion-questions",
    "title": "The Ethics of Nudging",
    "section": "Discussion Questions",
    "text": "Discussion Questions\n\nHow does The Ethics of Nudging influence our understanding of psychological phenomena?\nWhat are the main challenges in addressing The Ethics of Nudging in psychological research?\nHow can researchers better incorporate considerations of The Ethics of Nudging in their work?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The Ethics of Nudging"
    ]
  },
  {
    "objectID": "CHIP/topics/topic17.html#further-reading",
    "href": "CHIP/topics/topic17.html#further-reading",
    "title": "The Ethics of Nudging",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The Ethics of Nudging"
    ]
  },
  {
    "objectID": "CHIP/topics/topic07.html",
    "href": "CHIP/topics/topic07.html",
    "title": "Validity and Reliability in Psychological Measurement",
    "section": "",
    "text": "Validity and Reliability in Psychological Measurement",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Validity and Reliability in Psychological Measurement"
    ]
  },
  {
    "objectID": "CHIP/topics/topic07.html#chip-topic",
    "href": "CHIP/topics/topic07.html#chip-topic",
    "title": "Validity and Reliability in Psychological Measurement",
    "section": "",
    "text": "Validity and Reliability in Psychological Measurement",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Validity and Reliability in Psychological Measurement"
    ]
  },
  {
    "objectID": "CHIP/topics/topic07.html#overview",
    "href": "CHIP/topics/topic07.html#overview",
    "title": "Validity and Reliability in Psychological Measurement",
    "section": "Overview",
    "text": "Overview\nThis week we will explore Validity and Reliability in Psychological Measurement and its implications for psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Validity and Reliability in Psychological Measurement"
    ]
  },
  {
    "objectID": "CHIP/topics/topic07.html#key-points",
    "href": "CHIP/topics/topic07.html#key-points",
    "title": "Validity and Reliability in Psychological Measurement",
    "section": "Key Points",
    "text": "Key Points\n\n[Key point 1]\n[Key point 2]\n[Key point 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Validity and Reliability in Psychological Measurement"
    ]
  },
  {
    "objectID": "CHIP/topics/topic07.html#discussion-questions",
    "href": "CHIP/topics/topic07.html#discussion-questions",
    "title": "Validity and Reliability in Psychological Measurement",
    "section": "Discussion Questions",
    "text": "Discussion Questions\n\nHow does Validity and Reliability in Psychological Measurement influence our understanding of psychological phenomena?\nWhat are the main challenges in addressing Validity and Reliability in Psychological Measurement in psychological research?\nHow can researchers better incorporate considerations of Validity and Reliability in Psychological Measurement in their work?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Validity and Reliability in Psychological Measurement"
    ]
  },
  {
    "objectID": "CHIP/topics/topic07.html#further-reading",
    "href": "CHIP/topics/topic07.html#further-reading",
    "title": "Validity and Reliability in Psychological Measurement",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Validity and Reliability in Psychological Measurement"
    ]
  },
  {
    "objectID": "CHIP/topics/topic08.html",
    "href": "CHIP/topics/topic08.html",
    "title": "The Role of IQ Tests in Psychology",
    "section": "",
    "text": "The Role of IQ Tests in Psychology",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The Role of IQ Tests in Psychology"
    ]
  },
  {
    "objectID": "CHIP/topics/topic08.html#chip-topic",
    "href": "CHIP/topics/topic08.html#chip-topic",
    "title": "The Role of IQ Tests in Psychology",
    "section": "",
    "text": "The Role of IQ Tests in Psychology",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The Role of IQ Tests in Psychology"
    ]
  },
  {
    "objectID": "CHIP/topics/topic08.html#overview",
    "href": "CHIP/topics/topic08.html#overview",
    "title": "The Role of IQ Tests in Psychology",
    "section": "Overview",
    "text": "Overview\nThis week we will explore The Role of IQ Tests in Psychology and its implications for psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The Role of IQ Tests in Psychology"
    ]
  },
  {
    "objectID": "CHIP/topics/topic08.html#key-points",
    "href": "CHIP/topics/topic08.html#key-points",
    "title": "The Role of IQ Tests in Psychology",
    "section": "Key Points",
    "text": "Key Points\n\n[Key point 1]\n[Key point 2]\n[Key point 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The Role of IQ Tests in Psychology"
    ]
  },
  {
    "objectID": "CHIP/topics/topic08.html#discussion-questions",
    "href": "CHIP/topics/topic08.html#discussion-questions",
    "title": "The Role of IQ Tests in Psychology",
    "section": "Discussion Questions",
    "text": "Discussion Questions\n\nHow does The Role of IQ Tests in Psychology influence our understanding of psychological phenomena?\nWhat are the main challenges in addressing The Role of IQ Tests in Psychology in psychological research?\nHow can researchers better incorporate considerations of The Role of IQ Tests in Psychology in their work?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The Role of IQ Tests in Psychology"
    ]
  },
  {
    "objectID": "CHIP/topics/topic08.html#further-reading",
    "href": "CHIP/topics/topic08.html#further-reading",
    "title": "The Role of IQ Tests in Psychology",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "The Role of IQ Tests in Psychology"
    ]
  },
  {
    "objectID": "CHIP/topics/topic14.html",
    "href": "CHIP/topics/topic14.html",
    "title": "How to police and punish Scientific malpractice?",
    "section": "",
    "text": "How to police and punish Scientific malpractice?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "How to police and punish Scientific malpractice?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic14.html#chip-topic",
    "href": "CHIP/topics/topic14.html#chip-topic",
    "title": "How to police and punish Scientific malpractice?",
    "section": "",
    "text": "How to police and punish Scientific malpractice?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "How to police and punish Scientific malpractice?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic14.html#overview",
    "href": "CHIP/topics/topic14.html#overview",
    "title": "How to police and punish Scientific malpractice?",
    "section": "Overview",
    "text": "Overview\nThis week we will explore How to police and punish Scientific malpractice? and its implications for psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "How to police and punish Scientific malpractice?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic14.html#key-points",
    "href": "CHIP/topics/topic14.html#key-points",
    "title": "How to police and punish Scientific malpractice?",
    "section": "Key Points",
    "text": "Key Points\n\n[Key point 1]\n[Key point 2]\n[Key point 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "How to police and punish Scientific malpractice?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic14.html#discussion-questions",
    "href": "CHIP/topics/topic14.html#discussion-questions",
    "title": "How to police and punish Scientific malpractice?",
    "section": "Discussion Questions",
    "text": "Discussion Questions\n\nHow does How to police and punish Scientific malpractice? influence our understanding of psychological phenomena?\nWhat are the main challenges in addressing How to police and punish Scientific malpractice? in psychological research?\nHow can researchers better incorporate considerations of How to police and punish Scientific malpractice? in their work?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "How to police and punish Scientific malpractice?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic14.html#further-reading",
    "href": "CHIP/topics/topic14.html#further-reading",
    "title": "How to police and punish Scientific malpractice?",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "How to police and punish Scientific malpractice?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic03.html",
    "href": "CHIP/topics/topic03.html",
    "title": "Replication Crisis in Psychology",
    "section": "",
    "text": "Replication Crisis in Psychology",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Replication Crisis in Psychology"
    ]
  },
  {
    "objectID": "CHIP/topics/topic03.html#chip-topic",
    "href": "CHIP/topics/topic03.html#chip-topic",
    "title": "Replication Crisis in Psychology",
    "section": "",
    "text": "Replication Crisis in Psychology",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Replication Crisis in Psychology"
    ]
  },
  {
    "objectID": "CHIP/topics/topic03.html#overview",
    "href": "CHIP/topics/topic03.html#overview",
    "title": "Replication Crisis in Psychology",
    "section": "Overview",
    "text": "Overview\nThis week we will explore Replication Crisis in Psychology and its implications for psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Replication Crisis in Psychology"
    ]
  },
  {
    "objectID": "CHIP/topics/topic03.html#key-points",
    "href": "CHIP/topics/topic03.html#key-points",
    "title": "Replication Crisis in Psychology",
    "section": "Key Points",
    "text": "Key Points\n\n[Key point 1]\n[Key point 2]\n[Key point 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Replication Crisis in Psychology"
    ]
  },
  {
    "objectID": "CHIP/topics/topic03.html#discussion-questions",
    "href": "CHIP/topics/topic03.html#discussion-questions",
    "title": "Replication Crisis in Psychology",
    "section": "Discussion Questions",
    "text": "Discussion Questions\n\nHow does Replication Crisis in Psychology influence our understanding of psychological phenomena?\nWhat are the main challenges in addressing Replication Crisis in Psychology in psychological research?\nHow can researchers better incorporate considerations of Replication Crisis in Psychology in their work?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Replication Crisis in Psychology"
    ]
  },
  {
    "objectID": "CHIP/topics/topic03.html#further-reading",
    "href": "CHIP/topics/topic03.html#further-reading",
    "title": "Replication Crisis in Psychology",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Replication Crisis in Psychology"
    ]
  },
  {
    "objectID": "CHIP/topics/topic12.html",
    "href": "CHIP/topics/topic12.html",
    "title": "Is Thematic Analysis a method or a tool?",
    "section": "",
    "text": "Is Thematic Analysis a method or a tool?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Is Thematic Analysis a method or a tool?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic12.html#chip-topic",
    "href": "CHIP/topics/topic12.html#chip-topic",
    "title": "Is Thematic Analysis a method or a tool?",
    "section": "",
    "text": "Is Thematic Analysis a method or a tool?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Is Thematic Analysis a method or a tool?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic12.html#overview",
    "href": "CHIP/topics/topic12.html#overview",
    "title": "Is Thematic Analysis a method or a tool?",
    "section": "Overview",
    "text": "Overview\nThis week we will explore Is Thematic Analysis a method or a tool? and its implications for psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Is Thematic Analysis a method or a tool?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic12.html#key-points",
    "href": "CHIP/topics/topic12.html#key-points",
    "title": "Is Thematic Analysis a method or a tool?",
    "section": "Key Points",
    "text": "Key Points\n\n[Key point 1]\n[Key point 2]\n[Key point 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Is Thematic Analysis a method or a tool?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic12.html#discussion-questions",
    "href": "CHIP/topics/topic12.html#discussion-questions",
    "title": "Is Thematic Analysis a method or a tool?",
    "section": "Discussion Questions",
    "text": "Discussion Questions\n\nHow does Is Thematic Analysis a method or a tool? influence our understanding of psychological phenomena?\nWhat are the main challenges in addressing Is Thematic Analysis a method or a tool? in psychological research?\nHow can researchers better incorporate considerations of Is Thematic Analysis a method or a tool? in their work?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Is Thematic Analysis a method or a tool?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic12.html#further-reading",
    "href": "CHIP/topics/topic12.html#further-reading",
    "title": "Is Thematic Analysis a method or a tool?",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Is Thematic Analysis a method or a tool?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic09.html",
    "href": "CHIP/topics/topic09.html",
    "title": "What does Psychology have to say about AI?",
    "section": "",
    "text": "What does Psychology have to say about AI?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "What does Psychology have to say about AI?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic09.html#chip-topic",
    "href": "CHIP/topics/topic09.html#chip-topic",
    "title": "What does Psychology have to say about AI?",
    "section": "",
    "text": "What does Psychology have to say about AI?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "What does Psychology have to say about AI?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic09.html#overview",
    "href": "CHIP/topics/topic09.html#overview",
    "title": "What does Psychology have to say about AI?",
    "section": "Overview",
    "text": "Overview\nThis week we will explore What does Psychology have to say about AI? and its implications for psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "What does Psychology have to say about AI?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic09.html#key-points",
    "href": "CHIP/topics/topic09.html#key-points",
    "title": "What does Psychology have to say about AI?",
    "section": "Key Points",
    "text": "Key Points\n\n[Key point 1]\n[Key point 2]\n[Key point 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "What does Psychology have to say about AI?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic09.html#discussion-questions",
    "href": "CHIP/topics/topic09.html#discussion-questions",
    "title": "What does Psychology have to say about AI?",
    "section": "Discussion Questions",
    "text": "Discussion Questions\n\nHow does What does Psychology have to say about AI? influence our understanding of psychological phenomena?\nWhat are the main challenges in addressing What does Psychology have to say about AI? in psychological research?\nHow can researchers better incorporate considerations of What does Psychology have to say about AI? in their work?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "What does Psychology have to say about AI?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic09.html#further-reading",
    "href": "CHIP/topics/topic09.html#further-reading",
    "title": "What does Psychology have to say about AI?",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "What does Psychology have to say about AI?"
    ]
  },
  {
    "objectID": "CHIP/topics/topic04.html",
    "href": "CHIP/topics/topic04.html",
    "title": "Nature vs. Nurture Debate",
    "section": "",
    "text": "Nature vs. Nurture Debate",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Nature vs. Nurture Debate"
    ]
  },
  {
    "objectID": "CHIP/topics/topic04.html#chip-topic",
    "href": "CHIP/topics/topic04.html#chip-topic",
    "title": "Nature vs. Nurture Debate",
    "section": "",
    "text": "Nature vs. Nurture Debate",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Nature vs. Nurture Debate"
    ]
  },
  {
    "objectID": "CHIP/topics/topic04.html#overview",
    "href": "CHIP/topics/topic04.html#overview",
    "title": "Nature vs. Nurture Debate",
    "section": "Overview",
    "text": "Overview\nThis week we will explore Nature vs. Nurture Debate and its implications for psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Nature vs. Nurture Debate"
    ]
  },
  {
    "objectID": "CHIP/topics/topic04.html#key-points",
    "href": "CHIP/topics/topic04.html#key-points",
    "title": "Nature vs. Nurture Debate",
    "section": "Key Points",
    "text": "Key Points\n\n[Key point 1]\n[Key point 2]\n[Key point 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Nature vs. Nurture Debate"
    ]
  },
  {
    "objectID": "CHIP/topics/topic04.html#discussion-questions",
    "href": "CHIP/topics/topic04.html#discussion-questions",
    "title": "Nature vs. Nurture Debate",
    "section": "Discussion Questions",
    "text": "Discussion Questions\n\nHow does Nature vs. Nurture Debate influence our understanding of psychological phenomena?\nWhat are the main challenges in addressing Nature vs. Nurture Debate in psychological research?\nHow can researchers better incorporate considerations of Nature vs. Nurture Debate in their work?",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Nature vs. Nurture Debate"
    ]
  },
  {
    "objectID": "CHIP/topics/topic04.html#further-reading",
    "href": "CHIP/topics/topic04.html#further-reading",
    "title": "Nature vs. Nurture Debate",
    "section": "Further Reading",
    "text": "Further Reading\n\n[Suggested reading 1]\n[Suggested reading 2]\n[Suggested reading 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "CHIP",
      "Topics",
      "Nature vs. Nurture Debate"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to Intermediate Research Methods",
    "section": "",
    "text": "Setting up Intermediate Research Methods Text",
    "crumbs": [
      "Schedule",
      "Overview",
      "Syllabus"
    ]
  },
  {
    "objectID": "week01/06-ttests.html",
    "href": "week01/06-ttests.html",
    "title": "06-ttests",
    "section": "",
    "text": "Back in the day, William Sealy Gosset got a job working for Guinness Breweries. They make the famous Irish stout called Guinness. What happens next went something like this (total fabrication, but mostly on point).\nGuinness wanted all of their beers to be the best beers. No mistakes, no bad beers. They wanted to improve their quality control so that when Guinness was poured anywhere in the world, it would always comes out fantastic: 5 stars out of 5 every time, the best.\nGuinness had some beer tasters, who were super-experts. Every time they tasted a Guinness from the factory that wasn’t 5 out of 5, they knew right away.\nBut, Guinness had a big problem. They would make a keg of beer, and they would want to know if every single pint that would come out would be a 5 out of 5. So, the beer tasters drank pint after pint out of the keg, until it was gone. Some kegs were all 5 out of 5s. Some weren’t, Guinness needed to fix that. But, the biggest problem was that, after the testing, there was no beer left to sell, the testers drank it all (remember I’m making this part up to illustrate a point, they probably still had beer left to sell).\nGuinness had a sampling and population problem. They wanted to know that the entire population of the beers they made were all 5 out of 5 stars. But, if they sampled the entire population, they would drink all of their beer, and wouldn’t have any left to sell.\nEnter William Sealy Gosset. Gosset figured out the solution to the problem. He asked questions like this:\n\nHow many samples do I need to take to know the whole population is 5 out of 5?\nWhat’s the fewest amount of samples I need to take to know the above, that would mean Guinness could test fewer beers for quality, sell more beers for profit, and make the product testing time shorter.\n\nGosset solved those questions, and he invented something called the Student’s t-test. Gosset was working for Guinness, and could be fired for releasing trade-secrets that he invented (the t-test). But, Gosset published the work anyways, under a pseudonym (Student1908?). He called himself Student, hence Student’s t-test. Now you know the rest of the story.\nIt turns out this was a very nice thing for Gosset to have done. t-tests are used all the time, and they are useful, that’s why they are used. In this chapter we learn how they work.\nYou’ll be surprised to learn that what we’ve already talked about, (the Crump Test, and the Randomization Test), are both very very similar to the t-test. So, in general, you have already been thinking about the things you need to think about to understand t-tests. You’re probably wondering what is this \\(t\\), what does \\(t\\) mean? We will tell you. Before we tell what it means, we first tell you about one more idea.\n\n\nWe’ve talked about getting a sample of data. We know we can find the mean, we know we can find the standard deviation. We know we can look at the data in a histogram. These are all useful things to do for us to learn something about the properties of our data.\nYou might be thinking of the mean and standard deviation as very different things that we would not put together. The mean is about central tendency (where most of the data is), and the standard deviation is about variance (where most of the data isn’t). Yes, they are different things, but we can use them together to create useful new things.\nWhat if I told you my sample mean was 50, and I told you nothing else about my sample. Would you be confident that most of the numbers were near 50? Would you wonder if there was a lot of variability in the sample, and many of the numbers were very different from 50. You should wonder all of those things. The mean alone, just by itself, doesn’t tell you anything about well the mean represents all of the numbers in the sample.\nIt could be a representative number, when the standard deviation is very small, and all the numbers are close to 50. It could be a non-representative number, when the standard deviation is large, and many of the numbers are not near 50. You need to know the standard deviation in order to be confident in how well the mean represents the data.\nHow can we put the mean and the standard deviation together, to give us a new number that tells us about confidence in the mean?\nWe can do this using a ratio:\n\\(\\frac{mean}{\\text{standard deviation}}\\)\nThink about what happens here. We are dividing a number by a number. Look at what happens:\n\\(\\frac{number}{\\text{same number}} = 1\\)\n\\(\\frac{number}{\\text{smaller number}} = \\text{big number}\\)\ncompared to:\n\\(\\frac{number}{\\text{bigger number}} = \\text{smaller number}\\)\nImagine we have a mean of 50, and a truly small standard deviation of 1. What do we get with our formula?\n\\(\\frac{50}{1} = 50\\)\nImagine we have a mean of 50, and a big standard deviation of 100. What do we get with our formula?\n\\(\\frac{50}{100} = 0.5\\)\nNotice, when we have a mean paired with a small standard deviation, our formula gives us a big number, like 50. When we have a mean paired with a large standard deviation, our formula gives us a small number, like 0.5. These numbers can tell us something about confidence in our mean, in a general way. We can be 50 confident in our mean in the first case, and only 0.5 (not at a lot) confident in the second case.\nWhat did we do here? We created a descriptive statistic by dividing the mean by the standard deviation. And, we have a sense of how to interpret this number, when it’s big we’re more confident that the mean represents all of the numbers, when it’s small we are less confident. This is a useful kind of number, a ratio between what we think about our sample (the mean), and the variability in our sample (the standard deviation). Get used to this idea. Almost everything that follows in this textbook is based on this kind of ratio. We will see that our ratio turns into different kinds of “statistics”, and the ratios will look like this in general:\n\\(\\text{name of statistic} = \\frac{\\text{measure of what we know}}{\\text{measure of what we don't know}}\\)\nor, to say it using different words:\n\\(\\text{name of statistic} = \\frac{\\text{measure of effect}}{\\text{measure of error}}\\)\nIn fact, this is the general formula for the t-test. Big surprise!\n\n\n\nNow we are ready to talk about t-test. We will talk about three of them. We start with the one-sample t-test.\nCommonly, the one-sample t-test is used to estimate the chances that your sample came from a particular population. Specifically, you might want to know whether the mean that you found from your sample, could have come from a particular population having a particular mean.\nStraight away, the one-sample t-test becomes a little confusing (and I haven’t even described it yet). Officially, it uses known parameters from the population, like the mean of the population and the standard deviation of the population. However, most times you don’t know those parameters of the population! So, you have to estimate them from your sample. Remember from the chapters on descriptive statistics and sampling, our sample mean is an unbiased estimate of the population mean. And, our sample standard deviation (the one where we divide by n-1) is an unbiased estimate of the population standard deviation. When Gosset developed the t-test, he recognized that he could use these estimates from his samples, to make the t-test. Here is the formula for the one sample t-test, we first use words, and then become more specific:\n\n\n\\(\\text{name of statistic} = \\frac{\\text{measure of effect}}{\\text{measure of error}}\\)\n\\(\\text{t} = \\frac{\\text{measure of effect}}{\\text{measure of error}}\\)\n\\(\\text{t} = \\frac{\\text{Mean difference}}{\\text{standard error}}\\)\n\\(\\text{t} = \\frac{\\bar{X}-u}{S_{\\bar{X}}}\\)\n\\(\\text{t} = \\frac{\\text{Sample Mean  - Population Mean}}{\\text{Sample Standard Error}}\\)\n\\(\\text{Estimated Standard Error} = \\text{Standard Error of Sample} = \\frac{s}{\\sqrt{N}}\\)\nWhere, s is the sample standard deviation.\nSome of you may have gone cross-eyed looking at all of this. Remember, we’ve seen it before when we divided our mean by the standard deviation in the first bit. The t-test is just a measure of a sample mean, divided by the standard error of the sample mean. That is it.\n\n\n\n\\(t\\) gives us a measure of confidence, just like our previous ratio for dividing the mean by a standard deviations. The only difference with \\(t\\), is that we divide by the standard error of mean (remember, this is also a standard deviation, it is the standard deviation of the sampling distribution of the mean)\n\n\n\n\n\n\nNote\n\n\n\nWhat does the t in t-test stand for? Apparently nothing. Gosset originally labelled it z. And, Fisher later called it t, perhaps because t comes after s, which is often used for the sample standard deviation.\n\n\n\\(t\\) is a property of the data that you collect. You compute it with a sample mean, and a sample standard error (there’s one more thing in the one-sample formula, the population mean, which we get to in a moment). This is why we call \\(t\\), a sample-statistic. It’s a statistic we compute from the sample.\nWhat kinds of numbers should we expect to find for these \\(ts\\)? How could we figure that out?\nLet’s start small and work through some examples. Imagine your sample mean is 5. You want to know if it came from a population that also has a mean of 5. In this case, what would \\(t\\) be? It would be zero: we first subtract the sample mean from the population mean, \\(5-5=0\\). Because the numerator is 0, \\(t\\) will be zero. So, \\(t\\) = 0, occurs, when there is no difference.\nLet’s say you take another sample, do you think the mean will be 5 every time, probably not. Let’s say the mean is 6. So, what can \\(t\\) be here? It will be a positive number, because 6-5= +1. But, will \\(t\\) be +1? That depends on the standard error of the sample. If the standard error of the sample is 1, then \\(t\\) could be 1, because 1/1 = 1.\nIf the sample standard error is smaller than 1, what happens to \\(t\\)? It get’s bigger right? For example, 1 divided by 0.5 = 2. If the sample standard error was 0.5, \\(t\\) would be 2. And, what could we do with this information? Well, it be like a measure of confidence. As \\(t\\) get’s bigger we could be more confident in the mean difference we are measuring.\nCan \\(t\\) be smaller than 1? Sure, it can. If the sample standard error is big, say like 2, then \\(t\\) will be smaller than one (in our case), e.g., 1/2 = .5. The direction of the difference between the sample mean and population mean, can also make the \\(t\\) become negative. What if our sample mean was 4. Well, then \\(t\\) will be negative, because the mean difference in the numerator will be negative, and the number in the bottom (denominator) will always be positive (remember why, it’s the standard error, computed from the sample standard deviation, which is always positive because of the squaring that we did.).\nSo, that is some intuitions about what the kinds of values t can take. \\(t\\) can be positive or negative, and big or small.\nLet’s do one more thing to build our intuitions about what \\(t\\) can look like. How about we sample some numbers and then measure the sample mean and the standard error of the mean, and then plot those two things against each each. This will show us how a sample mean typically varies with respect to the standard error of the mean.\nIn Figure 1, I pulled 1,000 samples of \\(N = 10\\) from a normal distribution (mean = 0, sd = 1). Each time I measured the mean and standard error of the sample. That gave two descriptive statistics for each sample, letting us plot each sample as dot in a scatter plot.\n\nsample_mean &lt;- length(1000)\nsample_se &lt;- length(1000)\n\nfor (i in 1:1000) {\n  s &lt;- rnorm(10, 0, 1)\n  sample_mean[i] &lt;- mean(s)\n  sample_se[i] &lt;- sd(s) / sqrt(length(s))\n}\n\nplot(sample_mean, sample_se)\n\n\n\n\n\n\n\nFigure 1: A scatter plot with sample mean on the x-axis, and standard error of the mean on the y-axis\n\n\n\n\n\nWhat we get is a cloud of dots. You might notice the cloud has a circular quality. There’s more dots in the middle, and fewer dots as they radiate out from the middle. The dot cloud shows us the general range of the sample mean, for example most of the dots are in between -1 and 1. Similarly, the range for the sample standard error is roughly between .2 and .5. Remember, each dot represents one sample.\nWe can look at the same data a different way. For example, rather than using a scatter plot, we can divide the mean for each dot by the standard error for each dot. Figure 2 shows the result in a histogram.\n\nhist(sample_mean/sample_se, breaks=30)\n\n\n\n\n\n\n\nFigure 2: A histogram of the sample means divided by the sample standard errors, this is a t-distribution.\n\n\n\n\n\nInteresting, we can see the histogram is shaped like a normal curve. It is centered on 0, which is the most common value. As values become more extreme, they become less common. If you remember, our formula for \\(t\\), was the mean divided by the standard error of the mean. That’s what we did here. This histogram is showing you a \\(t\\)-distribution.\n\n\n\nLet’s briefly calculate a t-value from a small sample. Let’s say we had 10 students do a true/false quiz with 5 questions on it. There’s a 50% chance of getting each answer correct.\nEvery student completes the 5 questions, we grade them, and then we find their performance (mean percent correct). What we want to know is whether the students were guessing. If they were all guessing, then the sample mean should be about 50%, it shouldn’t be different from chance, which is 50%. Let’s look at Table 1.\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\n\nTable 1: Calculating the t-value for a one-sample test.\n\n\n\n\n\n\nstudents\nscores\nmean\nDifference_from_Mean\nSquared_Deviations\n\n\n\n\n1\n50\n61\n-11\n121\n\n\n2\n70\n61\n9\n81\n\n\n3\n60\n61\n-1\n1\n\n\n4\n40\n61\n-21\n441\n\n\n5\n80\n61\n19\n361\n\n\n6\n30\n61\n-31\n961\n\n\n7\n90\n61\n29\n841\n\n\n8\n60\n61\n-1\n1\n\n\n9\n70\n61\n9\n81\n\n\n10\n60\n61\n-1\n1\n\n\nSums\n610\n610\n0\n2890\n\n\nMeans\n61\n61\n0\n289\n\n\n\n\n\nsd\n17.92\n\n\n\n\n\nSEM\n5.67\n\n\n\n\n\nt\n1.94003527336861\n\n\n\n\n\n\n\n\nYou can see the scores column has all of the test scores for each of the 10 students. We did the things we need to do to compute the standard deviation.\nRemember the sample standard deviation is the square root of the sample variance, or:\n\\(\\text{sample standard deviation} = \\sqrt{\\frac{\\sum_{i}^{n}({x_{i}-\\bar{x})^2}}{N-1}}\\)\n\\(\\text{sd} = \\sqrt{\\frac{2890}{10-1}} = 17.92\\)\nThe standard error of the mean, is the standard deviation divided by the square root of N\n\\(\\text{SEM} = \\frac{s}{\\sqrt{N}} = \\frac{17.92}{10} = 5.67\\)\n\\(t\\) is the difference between our sample mean (61), and our population mean (50, assuming chance), divided by the standard error of the mean.\n\\(\\text{t} = \\frac{\\bar{X}-u}{S_{\\bar{X}}} = \\frac{\\bar{X}-u}{SEM} = \\frac{61-50}{5.67} = 1.94\\)\nAnd, that is you how calculate \\(t\\), by hand. It’s a pain. I was annoyed doing it this way. In the lab, you learn how to calculate \\(t\\) using software, so it will just spit out \\(t\\). For example in R, all you have to do is this:\n\nt.test(scores, mu=50)\n\n\n    One Sample t-test\n\ndata:  scores\nt = 1.9412, df = 9, p-value = 0.08415\nalternative hypothesis: true mean is not equal to 50\n95 percent confidence interval:\n 48.18111 73.81889\nsample estimates:\nmean of x \n       61 \n\n\n\n\n\nIf \\(t\\) is just a number that we can compute from our sample (it is), what can we do with it? How can we use \\(t\\) for statistical inference?\nRemember back to the chapter on sampling and distributions, that’s where we discussed the sampling distribution of the sample mean. Remember, we made a lot of samples, then computed the mean for each sample, then we plotted a histogram of the sample means. Later, in that same section, we mentioned that we could generate sampling distributions for any statistic. For each sample, we could compute the mean, the standard deviation, the standard error, and now even \\(t\\), if we wanted to. We could generate 10,000 samples, and draw four histograms, one for each sampling distribution for each statistic.\nThis is exactly what I did, and the results are shown in the four panels of Figure 3 below. I used a sample size of 20, and drew random observations for each sample from a normal distribution, with mean = 0, and standard deviation = 1. Let’s look at the sampling distributions for each of the statistics. \\(t\\) was computed assuming with the population mean assumed to be 0.\n\nall_df &lt;- data.frame()\nfor (i in 1:10000) {\n  sample &lt;- rnorm(20, 0, 1)\n  sample_mean &lt;- mean(sample)\n  sample_sd &lt;- sd(sample)\n  sample_se &lt;- sd(sample) / sqrt(length(sample))\n  sample_t &lt;- as.numeric(t.test(sample, mu = 0)$statistic)\n  t_df &lt;- data.frame(i, sample_mean, sample_sd, sample_se, sample_t)\n  all_df &lt;- rbind(all_df, t_df)\n}\n\nlibrary(ggpubr)\na &lt;- ggplot(all_df, aes(x = sample_mean)) +\n  geom_histogram(color = \"white\") +\n  theme_classic(base_size=20)\nb &lt;- ggplot(all_df, aes(x = sample_sd)) +\n  geom_histogram(color = \"white\") +\n  theme_classic(base_size=20)\nc &lt;- ggplot(all_df, aes(x = sample_se)) +\n  geom_histogram(color = \"white\") +\n  theme_classic(base_size=20)\nd &lt;- ggplot(all_df, aes(x = sample_t)) +\n  geom_histogram(color = \"white\") +\n  theme_classic(base_size=20)\n\nggarrange(a, b, c, d,\n          ncol = 2, nrow = 2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nFigure 3: Sampling distributions for the mean, standard deviation, standard error of the mean, and \\(t\\).\n\n\n\n\n\nWe see four sampling distributions. This is how statistical summaries of these summaries behave. We have used the word chance windows before. These are four chance windows, measuring different aspects of the sample. In this case, all of the samples came from the same normal distribution. Because of sampling error, each sample is not identical. The means are not identical, the standard deviations are not identical, sample standard error of the means are not identical, and the \\(t\\)s of the samples are not identical. They all have some variation, as shown by the histograms. This is how samples of size 20 behave.\nWe can see straight away, that in this case, we are unlikely to get a sample mean of 2. That’s way outside the window. The range for the sampling distribution of the mean is around -.5 to +.5, and is centered on 0 (the population mean, would you believe!).\nWe are unlikely to get sample standard deviations of between .6 and 1.5, that is a different range, specific to the sample standard deviation.\nSame thing with the sample standard error of the mean, the range here is even smaller, mostly between .1, and .3. You would rarely find a sample with a standard error of the mean greater than .3. Virtually never would you find one of say 1 (for this situation).\nNow, look at \\(t\\). It’s range is basically between -3 and +3 here. 3s barely happen at all. You pretty much never see a 5 or -5 in this situation.\nAll of these sampling windows are chance windows, and they can all be used in the same way as we have used similar sampling distributions before (e.g., Crump Test, and Randomization Test) for statistical inference. For all of them we would follow the same process:\n\nGenerate these distributions\nLook at your sample statistics for the data you have (mean, SD, SEM, and \\(t\\))\nFind the likelihood of obtaining that value or greater\nObtain that probability\nSee if you think your sample statistics were probable or improbable.\n\nWe’ll formalize this in a second. I just want you to know that what you will be doing is something that you have already done before. For example, in the Crump test and the Randomization test we focused on the distribution of mean differences. We could do that again here, but instead, we will focus on the distribution of \\(t\\) values. We then apply the same kinds of decision rules to the \\(t\\) distribution, as we did for the other distributions. Below you will see a graph you have already seen, except this time it is a distribution of \\(t\\)s, not mean differences:\nRemember, if we obtained a single \\(t\\) from one sample we collected, we could consult the chance window in Figure 4 below to find out whether the \\(t\\) we obtained from the sample was likely or unlikely to occur by chance.\n\nsample_t &lt;- all_df$sample_t\n\nggplot(all_df, aes(x = sample_t)) +\n  annotate(\n    \"rect\",\n    xmin = min(sample_t),\n    xmax = max(sample_t),\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.5,\n    fill = \"red\"\n  ) +\n  annotate(\n    \"rect\",\n    xmin = min(sample_t),\n    xmax = -1.94,\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.7,\n    fill = \"light grey\"\n  ) +\n  annotate(\n    \"rect\",\n    xmin = 1.94,\n    xmax = max(sample_t),\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.7,\n    fill = \"light grey\"\n  ) +\n  geom_rect(aes(\n    xmin = -Inf,\n    xmax = min(sample_t),\n    ymin = 0,\n    ymax = Inf\n  ),\n  alpha = .5,\n  fill = \"lightgreen\") +\n  geom_rect(aes(\n    xmin = max(sample_t),\n    xmax = Inf,\n    ymin = 0,\n    ymax = Inf\n  ),\n  alpha = .5,\n  fill = \"lightgreen\") +\n  geom_histogram(bins = 50, color = \"white\") +\n  theme_classic() +\n  geom_vline(xintercept = min(sample_t)) +\n  geom_vline(xintercept = max(sample_t)) +\n  geom_vline(xintercept = -1.94) +\n  geom_vline(xintercept = 1.94) +\n  xlim(-8, 8) +\n  geom_label(data = data.frame(x = 0, y = 250, label = \"CHANCE\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = -7, y = 250, label = \"NOT \\n CHANCE\"),\n             aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = 7, y = 250, label = \"NOT \\n CHANCE\"),\n             aes(x = x, y = y, label = label)) +\n  #  geom_label(data = data.frame(x = min(sample_t), y = 600,\n  #                              label = paste0(\"min \\n\",round(min(sample_t)))),\n  #                             aes(x = x, y = y, label = label))+\n  #geom_label(data = data.frame(x = max(sample_t), y = 600,\n  #                            label = paste0(\"max \\n\",round(max(sample_t)))),\n  #                           aes(x = x, y = y, label = label))+\n  geom_label(data = data.frame(x = -4, y = 250,\n                               label = \"?\"),\n             aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = 4, y = 250,\n                               label = \"?\"),\n             aes(x = x, y = y, label = label)) +\n  xlab(\"mean sample_t\")\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\nFigure 4: Applying decision criteria to the \\(t\\)-distribution. Histogram of \\(t\\)s from samples (n=20) drawn from the same normal distribution (u=0, sd=1)\n\n\n\n\n\n\n\n\nFrom our early example involving the TRUE/FALSE quizzes, we are now ready to make some kind of decision about what happened there. We found a mean difference of 11. We found a \\(t\\) = 1.9411765. The probability of this \\(t\\) or larger occurring is \\(p\\) = 0.0841503. We were testing the idea that our sample mean of 61 could have come from a normal distribution with mean = 50. The \\(t\\) test tells us that the \\(t\\) for our sample, or a larger one, would happen with p = 0.0841503. In other words, chance can do it a kind of small amount of time, but not often. In English, this means that all of the students could have been guessing, but it wasn’t that likely that were just guessing.\nThe next \\(t\\)-test is called a paired samples t-test. And, spoiler alert, we will find out that a paired samples t-test is actually a one-sample t-test in disguise (WHAT!), yes it is. If the one-sample \\(t\\)-test didn’t make sense to you, read the next section.\n\n\n\n\nFor me (Crump), many analyses often boil down to a paired samples t-test. It just happens that many things I do reduce down to a test like this.\nI am a cognitive psychologist, I conduct research about how people do things like remember, pay attention, and learn skills. There are lots of Psychologists like me, who do very similar things.\nWe all often conduct the same kinds of experiments. They go like this, and they are called repeated measures designs. They are called repeated measures designs, because we measure how one person does something more than once, we repeat the measure.\nSo, I might measure somebody doing something in condition A, and measure the same person doing something in Condition B, and then I see that same person does different things in the two conditions. I repeatedly measure the same person in both conditions. I am interested in whether the experimental manipulation changes something about how people perform the task in question.\n\n\nWe will introduce the paired-samples t-test with an example using real data, from a real study. (mehr20165?) were interested in whether singing songs to infants helps infants become more sensitive to social cues. For example, infants might need to learn to direct their attention toward people as a part of learning how to interact socially with people. Perhaps singing songs to infants aids this process of directing attention. When an infant hears a familiar song, they might start to pay more attention to the person singing that song, even after they are done singing the song. The person who sang the song might become more socially important to the infant. You will learn more about this study in the lab for this week. This example, prepares you for the lab activities. Here is a brief summary of what they did.\nFirst, parents were trained to sing a song to their infants. After many days of singing this song to the infants, a parent came into the lab with their infant. In the first session, parents sat with their infants on their knees, so the infant could watch two video presentations. There were two videos. Each video involved two unfamiliar new people the infant had never seen before. Each new person in the video (the singers) sang one song to the infant. One singer sang the “familiar” song the infant had learned from their parents. The other singer sang an “unfamiliar” song the infant had not hear before.\nThere were two really important measurement phases: the baseline phase, and the test phase.\nThe baseline phase occurred before the infants saw and heard each singer sing a song. During the baseline phase, the infants watched a video of both singers at the same time. The researchers recorded the proportion of time that the infant looked at each singer. The baseline phase was conducted to determine whether infants had a preference to look at either person (who would later sing them a song).\nThe test phase occurred after infants saw and heard each song, sung by each singer. During the test phase, each infant had an opportunity to watch silent videos of both singers. The researchers measured the proportion of time the infants spent looking at each person. The question of interest, was whether the infants would spend a greater proportion of time looking at the singer who sang the familiar song, compared to the singer who sang the unfamiliar song.\nThere is more than one way to describe the design of this study. We will describe it like this. It was a repeated measures design, with one independent (manipulation) variable called Viewing phase: Baseline versus Test. There was one dependent variable (the measurement), which was proportion looking time (to singer who sung familiar song). This was a repeated measures design because the researchers measured proportion looking time twice (they repeated the measure), once during baseline (before infants heard each singer sing a song), and again during test (after infants head each singer sing a song).\nThe important question was whether infants would change their looking time, and look more at the singer who sang the familiar song during the test phase, than they did during the baseline phase. This is a question about a change within individual infants. In general, the possible outcomes for the study are:\n\nNo change: The difference between looking time toward the singer of the familiar song during baseline and test is zero, no difference.\nPositive change: Infants will look longer toward the singer of the familiar song during the test phase (after they saw and heard the singers), compared to the baseline phase (before they saw and heard the singers). This is a positive difference if we use the formula: Test Phase Looking time - Baseline phase looking time (to familiar song singer).\nNegative change: Infants will look longer toward the singer of the unfamiliar song during the test phase (after they saw and heard the singers), compared to the baseline phase (before they saw and heard the singers). This is a negative difference if we use the same formula: Test Phase Looking time - Baseline phase looking time (to familiar song singer).\n\n\n\n\nLet’s take a look at the data for the first 5 infants in the study. This will help us better understand some properties of the data before we analyze it. We will see that the data is structured in a particular way that we can take advantage of with a paired samples t-test. Note, we look at the first 5 infants to show how the computations work. The results of the paired-samples t-test change when we use all of the data from the study.\nHere is a table of the data:\n\n\n\nAttaching package: 'data.table'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\n\n\n\n\ninfant\nBaseline\nTest\n\n\n\n\n1\n0.44\n0.60\n\n\n2\n0.41\n0.68\n\n\n3\n0.75\n0.72\n\n\n4\n0.44\n0.28\n\n\n5\n0.47\n0.50\n\n\n\n\n\nThe table shows proportion looking times toward the singer of the familiar song during the Baseline and Test phases. Notice there are five different infants, (1 to 5). Each infant is measured twice, once during the Baseline phase, and once during the Test phase. To repeat from before, this is a repeated-measures design, because the infants are measured repeatedly (twice in this case). Or, this kind of design is also called a paired-samples design. Why? because each participant comes with a pair of samples (two samples), one for each level of the design.\nGreat, so what are we really interested in here? We want to know if the mean looking time toward the singer of the familiar song for the Test phase is higher than the Baseline phase. We are comparing the two sample means against each other and looking for a difference. We already know that differences could be obtained by chance alone, simply because we took two sets of samples, and we know that samples can be different. So, we are interested in knowing whether chance was likely or unlikely to have produced any difference we might observe.\nIn other words, we are interested in looking at the difference scores between the baseline and test phase for each infant. The question here is, for each infant, did their proportion looking time to the singer of the familiar song, increase during the test phase as compared to the baseline phase.\n\n\n\nLet’s add the difference scores to the table of data so it is easier to see what we are talking about. The first step in creating difference scores is to decide how you will take the difference, there are two options:\n\nTest phase score - Baseline Phase Score\nBaseline phase score - Test Phase score\n\nLet’s use the first formula. Why? Because it will give us positive differences when the test phase score is higher than the baseline phase score. This makes a positive score meaningful with respect to the study design, we know (because we defined it to be this way), that positive scores will refer to longer proportion looking times (to singer of familiar song) during the test phase compared to the baseline phase.\n\npaired_sample_df &lt;- cbind(paired_sample_df, \n                          differences = (paired_sample_df$Test-\n                                           paired_sample_df$Baseline))\nknitr::kable(paired_sample_df)\n\n\n\n\ninfant\nBaseline\nTest\ndifferences\n\n\n\n\n1\n0.44\n0.60\n0.16\n\n\n2\n0.41\n0.68\n0.27\n\n\n3\n0.75\n0.72\n-0.03\n\n\n4\n0.44\n0.28\n-0.16\n\n\n5\n0.47\n0.50\n0.03\n\n\n\n\n\nThere we have it, the difference scores. The first thing we can do here is look at the difference scores, and ask how many infants showed the effect of interest. Specifically, how many infants showed a positive difference score. We can see that three of five infants showed a positive difference (they looked more at the singer of the familiar song during the test than baseline phase), and two the infants showed the opposite effect (negative difference, they looked more at the singer of the familiar song during baseline than test).\n\n\n\nAs we have been discussing, the effect of interest in this study is the mean difference between the baseline and test phase proportion looking times. We can calculate the mean difference, by finding the mean of the difference scores. Let’s do that, in fact, for fun let’s calculate the mean of the baseline scores, the test scores, and the difference scores.\n\npaired_sample_df &lt;- paired_sample_df %&gt;%\n   rbind(c(\"Sums\",colSums(paired_sample_df[1:5,2:4]))) %&gt;%\n   rbind(c(\"Means\",colMeans(paired_sample_df[1:5,2:4])))\n  \nknitr::kable(paired_sample_df)\n\n\n\n\ninfant\nBaseline\nTest\ndifferences\n\n\n\n\n1\n0.44\n0.6\n0.16\n\n\n2\n0.41\n0.68\n0.27\n\n\n3\n0.75\n0.72\n-0.03\n\n\n4\n0.44\n0.28\n-0.16\n\n\n5\n0.47\n0.5\n0.03\n\n\nSums\n2.51\n2.78\n0.27\n\n\nMeans\n0.502\n0.556\n0.054\n\n\n\n\n\nWe can see there was a positive mean difference of 0.054, between the test and baseline phases.\nCan we rush to judgment and conclude that infants are more socially attracted to individuals who have sung them a familiar song? I would hope not based on this very small sample. First, the difference in proportion looking isn’t very large, and of course we recognize that this difference could have been produced by chance.\nWe will more formally evaluate whether this difference could have been caused by chance with the paired-samples t-test. But, before we do that, let’s again calculate \\(t\\) and discuss what \\(t\\) tells us over and above what our measure of the mean of the difference scores tells us.\n\n\n\nOK, so how do we calculate \\(t\\) for a paired-samples \\(t\\)-test? Surprise, we use the one-sample t-test formula that you already learned about! Specifically, we use the one-sample \\(t\\)-test formula on the difference scores. We have one sample of difference scores (you can see they are in one column), so we can use the one-sample \\(t\\)-test on the difference scores. Specifically, we are interested in comparing whether the mean of our difference scores came from a distribution with mean difference = 0. This is a special distribution we refer to as the null distribution. It is the distribution no differences. Of course, this null distribution can produce differences due to to sampling error, but those differences are not caused by any experimental manipulation, they caused by the random sampling process.\nWe calculate \\(t\\) in a moment. Let’s now consider again why we want to calculate \\(t\\)? Why don’t we just stick with the mean difference we already have?\nRemember, the whole concept behind \\(t\\), is that it gives an indication of how confident we should be in our mean. Remember, \\(t\\) involves a measure of the mean in the numerator, divided by a measure of variation (standard error of the sample mean) in the denominator. The resulting \\(t\\) value is small when the mean difference is small, or when the variation is large. So small \\(t\\)-values tell us that we shouldn’t be that confident in the estimate of our mean difference. Large \\(t\\)-values occur when the mean difference is large and/or when the measure of variation is small. So, large \\(t\\)-values tell us that we can be more confident in the estimate of our mean difference. Let’s find \\(t\\) for the mean difference scores. We use the same formulas as we did last time:\n\n\n\n\n\n\n\n\n\n\n\n\n\ninfant\nBaseline\nTest\ndifferences\ndiff_from_mean\nSquared_differences\n\n\n\n\n1\n0.44\n0.6\n0.16\n0.106\n0.011236\n\n\n2\n0.41\n0.68\n0.27\n0.216\n0.046656\n\n\n3\n0.75\n0.72\n-0.03\n-0.084\n0.00705600000000001\n\n\n4\n0.44\n0.28\n-0.16\n-0.214\n0.045796\n\n\n5\n0.47\n0.5\n0.03\n-0.024\n0.000575999999999999\n\n\nSums\n2.51\n2.78\n0.27\n0\n0.11132\n\n\nMeans\n0.502\n0.556\n0.054\n0\n0.022264\n\n\n\n\n\n\nsd\n0.167\n\n\n\n\n\n\nSEM\n0.075\n\n\n\n\n\n\nt\n0.72\n\n\n\n\n\nIf we did this test using R, we would obtain almost the same numbers (there is a little bit of rounding in the table).\n\nt.test(differences,mu=0)\n\n\n    One Sample t-test\n\ndata:  differences\nt = 0.72381, df = 4, p-value = 0.5092\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -0.1531384  0.2611384\nsample estimates:\nmean of x \n    0.054 \n\n\nHere is a quick write up of our t-test results, t(4) = .72, p = .509.\nWhat does all of that tell us? There’s a few things we haven’t gotten into much yet. For example, the 4 represents degrees of freedom, which we discuss later. The important part, the \\(t\\) value should start to be a little bit more meaningful. We got a kind of small t-value didn’t we. It’s .72. What can we tell from this value? First, it is positive, so we know the mean difference is positive. The sign of the \\(t\\)-value is always the same as the sign of the mean difference (ours was +0.054). We can also see that the p-value was .509. We’ve seen p-values before. This tells us that our \\(t\\) value or larger, occurs about 50.9% of the time… Actually it means more than this. And, to understand it, we need to talk about the concept of two-tailed and one-tailed tests.\n\n\n\nRemember what it is we are doing here. We are evaluating whether our sample data could have come from a particular kind of distribution. The null distribution of no differences. This is the distribution of \\(t\\)-values that would occur for samples of size 5, with a mean difference of 0, and a standard error of the sample mean of .075 (this is the SEM that we calculated from our sample). We can see what this particular null-distribution looks like in Figure 5.\n\nrange &lt;- seq(-3, 3, .1)\nnull_distribution &lt;- dt(range, 4, log = FALSE)\nplot_df &lt;- data.frame(range, null_distribution)\n\nggplot(plot_df, aes(x = range, y = null_distribution)) +\n  geom_line() +\n  xlab(\"t-values\") +\n  ylab(\"Probability\") +\n  theme(axis.text.y = element_blank(), axis.ticks = element_blank()) +\n  scale_x_continuous(breaks = (seq(-3, 3, .5))) +\n  geom_label(data = data.frame(x = -.7, y = .1, label = \"50% \\n (-)\"),\n             aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = .7, y = .1, label = \"50% \\n (+)\"), aes(x = x, y = y, label = label)) +\n  geom_vline(xintercept = 0)+\n  theme_classic(base_size = 20)\n\n\n\n\n\n\n\nFigure 5: A distribution of \\(t\\)-values that can occur by chance alone, when there is no difference between the sample and a population\n\n\n\n\n\nThe \\(t\\)-distribution above shows us the kinds of values \\(t\\) will will take by chance alone, when we measure the mean differences for pairs of 5 samples (like our current). \\(t\\) is most likely to be zero, which is good, because we are looking at the distribution of no-differences, which should most often be 0! But, sometimes, due to sampling error, we can get \\(t\\)s that are bigger than 0, either in the positive or negative direction. Notice the distribution is symmetrical, a \\(t\\) from the null-distribution will be positive half of the time, and negative half of the time, that is what we would expect by chance.\nSo, what kind of information do we want know when we find a particular \\(t\\) value from our sample? We want to know how likely the \\(t\\) value like the one we found occurs just by chance. This is actually a subtly nuanced kind of question. For example, any particular \\(t\\) value doesn’t have a specific probability of occurring. When we talk about probabilities, we are talking about ranges of probabilities. Let’s consider some probabilities. We will use the letter \\(p\\), to talk about the probabilities of particular \\(t\\) values.\n\nWhat is the probability that \\(t\\) is zero or positive or negative? The answer is p=1, or 100%. We will always have a \\(t\\) value that is zero or non-zero…Actually, if we can’t compute the t-value, for example when the standard deviation is undefined, I guess then we would have a non-number. But, assuming we can calculate \\(t\\), then it will always be 0 or positive or negative.\nWhat is the probability of \\(t\\) = 0 or greater than 0? The answer is p=.5, or 50%. 50% of \\(t\\)-values are 0 or greater.\nWhat is the of \\(t\\) = 0 or smaller than 0? The answer is p=.5, or 50%. 50% of \\(t\\)-values are 0 or smaller.\n\nWe can answer all of those questions just by looking at our t-distribution, and dividing it into two equal regions, the left side (containing 50% of the \\(t\\) values), and the right side containing 50% of the \\(t\\)-values).\nWhat if we wanted to take a more fine-grained approach, let’s say we were interested in regions of 10%. What kinds of \\(t\\)s occur 10% of the time. We would apply lines like the following. Notice, the likelihood of bigger numbers (positive or negative) gets smaller, so we have to increase the width of the bars for each of the intervals between the bars to contain 10% of the \\(t\\)-values, it looks like Figure 6.\n\nrange &lt;- seq(-3, 3, .1)\nnull_distribution &lt;- dt(range, 4, log = FALSE)\nplot_df &lt;- data.frame(range, null_distribution)\n\nt_ps &lt;- qt(seq(.1, .9, .1), 4)\n\nggplot(plot_df, aes(x = range, y = null_distribution)) +\n  geom_line() +\n  xlab(\"t-values\") +\n  ylab(\"Probability\") +\n  geom_vline(xintercept = t_ps) +\n  theme_classic(base_size = 15) +\n  theme(axis.text.y = element_blank(), axis.ticks = element_blank()) +\n  scale_x_continuous(breaks = round(t_ps, digits = 1)) +\n  geom_label(data = data.frame(x = -2.5, y = .2, label = \"10%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = -1.3, y = .2, label = \"10%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = 2.5, y = .2, label = \"10%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = 1.3, y = .2, label = \"10%\"), aes(x = x, y = y, label = label))\n\n\n\n\n\n\n\nFigure 6: Splitting the t distribution up into regions each containing 10% of the \\(t\\)-values. The width between the bars narrows as they approach the center of the distribution, where there are more \\(t\\)-values.\n\n\n\n\n\nConsider the probabilities (\\(p\\)) of \\(t\\) for the different ranges.\n\n\\(t\\) &lt;= -1.5 (\\(t\\) is less than or equal to -1.5), \\(p\\) = 10%\n-1.5 &gt;= \\(t\\) &lt;= -0.9 (\\(t\\) is equal to or between -1.5 and -.9), \\(p\\) = 10%\n-.9 &gt;= \\(t\\) &lt;= -0.6 (\\(t\\) is equal to or between -.9 and -.6), \\(p\\) = 10%\n\\(t\\) &gt;= 1.5 (\\(t\\) is greater than or equal to 1.5), \\(p\\) = 10%\n\nNotice, that the \\(p\\)s are always 10%. \\(t\\)s occur in these ranges with 10% probability.\n\n\n\nYou might be wondering where I am getting some of these values from. For example, how do I know that 10% of \\(t\\) values (for this null distribution) have a value of approximately 1.5 or greater than 1.5? The answer is I used R to tell me.\nIn most statistics textbooks the answer would be: there is a table at the back of the book where you can look these things up…This textbook has no such table. We could make one for you. And, we might do that. But, we didn’t do that yet…\nSo, where do these values come from, how can you figure out what they are? The complicated answer is that we are not going to explain the math behind finding these values because, 1) the authors (some of us) admittedly don’t know the math well enough to explain it, and 2) it would sidetrack us to much, 3) you will learn how to get these numbers in the lab with software, 4) you will learn how to get these numbers in lab without the math, just by doing a simulation, and 5) you can do it in R, or excel, or you can use an online calculator.\nThis is all to say that you can find the \\(t\\)s and their associated \\(p\\)s using software. But, the software won’t tell you what these values mean. That’s we are doing here. You will also see that software wants to know a few more things from you, such as the degrees of freedom for the test, and whether the test is one-tailed or two tailed. We haven’t explained any of these things yet. That’s what we are going to do now. Note, we explain degrees of freedom last. First, we start with a one-tailed test.\n\n\n\nA one-tailed test is sometimes also called a directional test. It is called a directional test, because a researcher might have a hypothesis in mind suggesting that the difference they observe in their means is going to have a particular direction, either a positive difference, or a negative difference.\nTypically, a researcher would set an alpha criterion. The alpha criterion describes a line in the sand for the researcher. Often, the alpha criterion is set at \\(p = .05\\). What does this mean? Figure 7 shows the \\(t\\)-distribution and the alpha criterion.\n\nrange &lt;- seq(-3, 3, .1)\nnull_distribution &lt;- dt(range, 4, log = FALSE)\nplot_df &lt;- data.frame(range, null_distribution)\n\nt_ps &lt;- qt(seq(.1, .9, .1), 4)\n\nggplot(plot_df, aes(x = range, y = null_distribution)) +\n  geom_line() +\n  xlab(\"t-values\") +\n  ylab(\"Probability\") +\n  geom_vline(xintercept = qt(.95, 4, lower.tail = TRUE)) +\n  ggtitle(\"Critical t for one-tailed test\") +\n  theme_classic(base_size = 10) +\n  theme(axis.text.y = element_blank(), axis.ticks = element_blank()) +\n  annotate(\n    \"rect\",\n    xmin = qt(.95, 4, lower.tail = TRUE),\n    xmax = 3,\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.5,\n    fill = \"green\"\n  ) +\n  geom_label(data = data.frame(x = 2.5, y = .2, label = \"5%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.95, 4, lower.tail = TRUE),\n    y = .3,\n    label = \"Critical t\"\n  ),\n  aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.95, 4, lower.tail = TRUE),\n    y = .25,\n    label = round(qt(.95, 4, lower.tail = TRUE), digits =\n                    2)\n  ),\n  aes(x = x, y = y, label = label))\n\n\n\n\n\n\n\nFigure 7: The critical value of t for an alpha criterion of 0.05. 5% of all ts are at this value or larger\n\n\n\n\n\nThe figure shows that \\(t\\) values of +2.13 or greater occur 5% of the time. Because the t-distribution is symmetrical, we also know that \\(t\\) values of -2.13 or smaller also occur 5% of the time. Both of these properties are true under the null distribution of no differences. This means, that when there really are no differences, a researcher can expect to find \\(t\\) values of 2.13 or larger 5% of the time.\nLet’s review and connect some of the terms:\n\nalpha criterion: the criterion set by the researcher to make decisions about whether they believe chance did or did not cause the difference. The alpha criterion here is set to \\(p = .05\\).\nCritical \\(t\\). The critical \\(t\\) is the \\(t\\)-value associated with the alpha-criterion. In this case for a one-tailed test, it is the \\(t\\) value where 5% of all \\(t\\)s are this number or greater. In our example, the critical \\(t\\) is 2.13. 5% of all \\(t\\) values (with degrees of freedom = 4) are +2.13, or greater than +2.13.\nObserved \\(t\\). The observed \\(t\\) is the one that you calculated from your sample. In our example about the infants, the observed \\(t\\) was \\(t\\) (4) = 0.72.\np-value. The \\(p\\)-value is the probability of obtaining the observed \\(t\\) value or larger. Now, you could look back at our previous example, and find that the \\(p\\)-value for \\(t\\) (4) = .72, was \\(p = .509\\) . HOWEVER, this p-value was not calculated for a one-directional test…(we talk about what .509 means in the next section).\n\nFigure 8 shows what the \\(p\\)-value for \\(t\\) (4) = .72 using a one-directional test would would look like:\n\nrange &lt;- seq(-3, 3, .1)\nnull_distribution &lt;- dt(range, 4, log = FALSE)\nplot_df &lt;- data.frame(range, null_distribution)\n\nt_ps &lt;- qt(seq(.1, .9, .1), 4)\n\nggplot(plot_df, aes(x = range, y = null_distribution)) +\n  geom_line() +\n  xlab(\"t-values\") +\n  ylab(\"Probability\") +\n  geom_vline(xintercept = .72) +\n  geom_vline(xintercept = qt(.95, 4, lower.tail = TRUE)) +\n  ggtitle(\"t value and p-range for one-directional test\") +\n  theme_classic(base_size = 10) +\n  theme(axis.text.y = element_blank(), axis.ticks = element_blank()) +\n  annotate(\n    \"rect\",\n    xmin = .72,\n    xmax = 3,\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.5,\n    fill = \"grey\"\n  ) +\n  annotate(\n    \"rect\",\n    xmin = qt(.95, 4, lower.tail = TRUE),\n    xmax = 3,\n    ymin = 0,\n    ymax = .25,\n    alpha = 0.5,\n    fill = \"green\"\n  ) +\n  geom_label(data = data.frame(x = 2.5, y = .2, label = \"5%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.95, 4, lower.tail = TRUE),\n    y = .3,\n    label = \"Critical t\"\n  ),\n  aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.95, 4, lower.tail = TRUE),\n    y = .25,\n    label = round(qt(.95, 4, lower.tail = TRUE), digits =\n                    2)\n  ),\n  aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = .72, y = .1,\n                               label = \"Observed t\"),\n             aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = .72, y = .05,\n                               label = \".72, p=\"),\n             aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = 1.5,\n    y = .05,\n    label = round(pt(.72, 4, lower.tail = FALSE), digits =\n                    3)\n  ),\n  aes(x = x, y = y, label = label))\n\n\n\n\n\n\n\nFigure 8: A case where the observed value of t is much less than the critical value for a one-directional t-test.\n\n\n\n\n\nLet’s take this one step at a time. We have located the observed \\(t\\) of .72 on the graph. We shaded the right region all grey. What we see is that the grey region represents .256 or 25.6% of all \\(t\\) values. In other words, 25.6% of \\(t\\) values are .72 or larger than .72. You could expect, by chance alone, to a find a \\(t\\) value of .72 or larger, 25.6% of the time. That’s fairly often. We did find a \\(t\\) value of .72. Now that you know this kind of \\(t\\) value or larger occurs 25.6% of the time, would you be confident that the mean difference was not due to chance? Probably not, given that chance can produce this difference fairly often.\nFollowing the “standard” decision making procedure, we would claim that our \\(t\\) value was not statistically significant, because it was not large enough. If our observed value was larger than the critical \\(t\\) (larger than 2.13), defined by our alpha criterion, then we would claim that our \\(t\\) value was statistically significant. This would be equivalent to saying that we believe it is unlikely that the difference we observed was due to chance. In general, for any observed \\(t\\) value, the associated \\(p\\)-value tells you how likely a \\(t\\) of the observed size or larger would be observed. The \\(p\\)-value always refers to a range of \\(t\\)-values, never to a single \\(t\\)-value. Researchers use the alpha criterion of .05, as a matter of convenience and convention. There are other ways to interpret these values that do not rely on a strict (significant versus not) dichotomy.\n\n\n\nOK, so that was one-tailed tests… What are two tailed tests? The \\(p\\)-value that we originally calculated from our paired-samples \\(t\\)-test was for a 2-tailed test. Often, the default is that the \\(p\\)-value is for a two-tailed test.\nThe two-tailed test, is asking a more general question about whether a difference is likely to have been produced by chance. The question is: what is probability of any difference. It is also called a non-directional test, because here we don’t care about the direction or sign of the difference (positive or negative), we just care if there is any kind of difference.\nThe same basic things as before are involved. We define an alpha criterion (\\(\\alpha = 0.05\\)). And, we say that any observed \\(t\\) value that has a probability of \\(p\\) &lt;.05 (\\(p\\) is less than .05) will be called statistically significant, and ones that are more likely (\\(p\\) &gt;.05, \\(p\\) is greater than .05) will be called null-results, or not statistically significant. The only difference is how we draw the alpha range. Before it was on the right side of the \\(t\\) distribution (we were conducting a one-sided test remember, so we were only interested in one side).\nFigure 9 shows what the most extreme 5% of the \\(t\\)-values are when we ignore their sign (whether they are positive or negative).\n\nrange &lt;- seq(-4, 4, .1)\nnull_distribution &lt;- dt(range, 4, log = FALSE)\nplot_df &lt;- data.frame(range, null_distribution)\n\nt_ps &lt;- qt(seq(.1, .9, .1), 4)\n\nggplot(plot_df, aes(x = range, y = null_distribution)) +\n  geom_line() +\n  xlab(\"t-values\") +\n  ylab(\"Probability\") +\n  geom_vline(xintercept = qt(.975, 4, lower.tail = TRUE)) +\n  geom_vline(xintercept = qt(.025, 4, lower.tail = TRUE)) +\n  ggtitle(\"Critical ts for two-tailed test\") +\n  theme_classic(base_size = 10) +\n  theme(axis.text.y = element_blank(), axis.ticks = element_blank()) +\n  annotate(\n    \"rect\",\n    xmin = qt(.975, 4, lower.tail = TRUE),\n    xmax = 4,\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.5,\n    fill = \"green\"\n  ) +\n  geom_label(data = data.frame(x = 3.5, y = .2, label = \"2.5%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.975, 4, lower.tail = TRUE),\n    y = .3,\n    label = \"Critical t\"\n  ),\n  aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.975, 4, lower.tail = TRUE),\n    y = .25,\n    label = round(qt(.975, 4, lower.tail = TRUE), digits =\n                    2)\n  ),\n  aes(x = x, y = y, label = label)) +\n  annotate(\n    \"rect\",\n    xmin = -4,\n    xmax = qt(.025, 4, lower.tail = TRUE),\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.5,\n    fill = \"green\"\n  ) +\n  geom_label(data = data.frame(x = -3.5, y = .2, label = \"2.5%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.025, 4, lower.tail = TRUE),\n    y = .3,\n    label = \"Critical t\"\n  ),\n  aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.025, 4, lower.tail = TRUE),\n    y = .25,\n    label = round(qt(.025, 4, lower.tail = TRUE), digits =\n                    2)\n  ),\n  aes(x = x, y = y, label = label))\n\n\n\n\n\n\n\nFigure 9: Critical values for a two-tailed test. Each line represents the location where 2.5% of all \\(t\\)s are larger or smaller than critical value. The total for both tails is 5%\n\n\n\n\n\nHere is what we are seeing. A distribution of no differences (the null, which is what we are looking at), will produce \\(t\\)s that are 2.78 or greater 2.5% of the time, and \\(t\\)s that are -2.78 or smaller 2.5% of the time. 2.5% + 2.5% is a total of 5% of the time. We could also say that \\(t\\)s larger than +/- 2.78 occur 5% of the time.\nAs a result, the critical \\(t\\) value is (+/-) 2.78 for a two-tailed test. As you can see, the two-tailed test is blind to the direction or sign of the difference. Because of this, the critical \\(t\\) value is also higher for a two-tailed test, than for the one-tailed test that we did earlier. Hopefully, now you can see why it is called a two-tailed test. There are two tails of the distribution, one on the left and right, both shaded in green.\n\n\n\nNow that you know there are two kinds of tests, one-tailed, and two-tailed, which one should you use? There is some conventional wisdom on this, but also some debate. In the end, it is up to you to be able to justify your choice and why it is appropriate for you data. That is the real answer.\nThe conventional answer is that you use a one-tailed test when you have a theory or hypothesis that is making a directional prediction (the theory predicts that the difference will be positive, or negative). Similarly, use a two-tailed test when you are looking for any difference, and you don’t have a theory that makes a directional prediction (it just makes the prediction that there will be a difference, either positive or negative).\nAlso, people appear to choose one or two-tailed tests based on how risky they are as researchers. If you always ran one-tailed tests, your critical \\(t\\) values for your set alpha criterion would always be smaller than the critical \\(t\\)s for a two-tailed test. Over the long run, you would make more type I errors, because the criterion to detect an effect is a lower bar for one than two tailed tests.\n\nRemember type 1 errors occur when you reject the idea that chance could have caused your difference. You often never know when you make this error. It happens anytime that sampling error was the actual cause of the difference, but a researcher dismisses that possibility and concludes that their manipulation caused the difference.\n\nSimilarly, if you always ran two-tailed tests, even when you had a directional prediction, you would make fewer type I errors over the long run, because the \\(t\\) for a two-tailed test is higher than the \\(t\\) for a one-tailed test. It seems quite common for researchers to use a more conservative two-tailed test, even when they are making a directional prediction based on theory. In practice, researchers tend to adopt a standard for reporting that is common in their field. Whether or not the practice is justifiable can sometimes be an open question. The important task for any researcher, or student learning statistics, is to be able to justify their choice of test.\n\n\n\nBefore we finish up with paired-samples \\(t\\)-tests, we should talk about degrees of freedom. Our sense is that students don’t really understand degrees of freedom very well. If you are reading this textbook, you are probably still wondering what is degrees of freedom, seeing as we haven’t really talked about it all.\nFor the \\(t\\)-test, there is a formula for degrees of freedom. For the one-sample and paired sample \\(t\\)-tests, the formula is:\n\\(\\text{Degrees of Freedom} = \\text{df} = n-1\\). Where n is the number of samples in the test.\nIn our paired \\(t\\)-test example, there were 5 infants. Therefore, degrees of freedom = 5-1 = 4.\nOK, that’s a formula. Who cares about degrees of freedom, what does the number mean? And why do we report it when we report a \\(t\\)-test… you’ve probably noticed the number in parentheses e.g., \\(t\\)(4)=.72, the 4 is the \\(df\\), or degrees of freedom.\nDegrees of freedom is both a concept, and a correction. The concept is that if you estimate a property of the numbers, and you use this estimate, you will be forcing some constraints on your numbers.\nConsider the numbers: 1, 2, 3. The mean of these numbers is 2. Now, let’s say I told you that the mean of three numbers is 2. Then, how many of these three numbers have freedom? Funny question right. What we mean is, how many of the three numbers could be any number, or have the freedom to be any number.\nThe first two numbers could be any number. But, once those two numbers are set, the final number (the third number), MUST be a particular number that makes the mean 2. The first two numbers have freedom. The third number has no freedom.\nTo illustrate. Let’s freely pick two numbers: 51 and -3. I used my personal freedom to pick those two numbers. Now, if our three numbers are 51, -3, and x, and the mean of these three numbers is 2. There is only one solution, x has to be -42, otherwise the mean won’t be 2. This is one way to think about degrees of freedom. The degrees of freedom for these three numbers is n-1 = 3-1= 2, because 2 of the numbers can be free, but the last number has no freedom, it becomes fixed after the first two are decided.\nNow, statisticians often apply degrees of freedom to their calculations, especially when a second calculation relies on an estimated value. For example, when we calculate the standard deviation of a sample, we first calculate the mean of the sample right! By estimating the mean, we are fixing an aspect of our sample, and so, our sample now has n-1 degrees of freedom when we calculate the standard deviation (remember for the sample standard deviation, we divide by n-1…there’s that n-1 again.)\n\n\nThere are at least two ways to think the degrees of freedom for a \\(t\\)-test. For example, if you want to use math to compute aspects of the \\(t\\) distribution, then you need the degrees of freedom to plug in to the formula… If you want to see the formulas I’m talking about, scroll down on the \\(t\\)-test wikipedia page and look for the probability density or cumulative distribution functions…We think that is quite scary for most people, and one reason why degrees of freedom are not well-understood.\nIf we wanted to simulate the \\(t\\) distribution we could more easily see what influence degrees of freedom has on the shape of the distribution. Remember, \\(t\\) is a sample statistic, it is something we measure from the sample. So, we could simulate the process of measuring \\(t\\) from many different samples, then plot the histogram of \\(t\\) to show us the simulated \\(t\\) distribution.\n\nts &lt;- c(rt(10000, 4), rt(10000, 100))\ndfs &lt;- as.factor(rep(c(4, 100), each = 10000))\n\nt_df &lt;- data.frame(dfs, ts)\nt_df &lt;- t_df[abs(t_df$ts) &lt; 5, ]\n\nggplot(t_df, aes(x = ts, group = dfs, color = dfs)) +\n  geom_histogram() +\n  theme_classic() +\n  facet_wrap( ~ dfs) +\n  theme_classic(base_size=15)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nFigure 10: The width of the t distribution shrinks as sample size and degrees of freedom (from 4 to 100) increases.\n\n\n\n\n\nIn Figure 10 notice that the red distribution for \\(df = 4\\), is a little bit shorter, and a little bit wider than the bluey-green distribution for \\(df = 100\\). As degrees of freedom increase the \\(t\\) distribution gets taller (in the middle), and narrower in the range. It get’s more peaky. Can you guess the reason for this? Remember, we are estimating a sample statistic, and degrees of freedom is really just a number that refers to the number of subjects (well minus one). And, we already know that as we increase \\(n\\), our sample statistics become better estimates (less variance) of the distributional parameters they are estimating. So, \\(t\\) becomes a better estimate of it’s “true” value as sample size increase, resulting in a more narrow distribution of \\(t\\)s.\nThere is a slightly different \\(t\\) distribution for every degrees of freedom, and the critical regions associated with 5% of the extreme values are thus slightly different every time. This is why we report the degrees of freedom for each t-test, they define the distribution of \\(t\\) values for the sample-size in question. Why do we use n-1 and not n? Well, we calculate \\(t\\) using the sample standard deviation to estimate the standard error or the mean, that estimate uses n-1 in the denominator, so our \\(t\\) distribution is built assuming n-1. That’s enough for degrees of freedom…\n\n\n\n\n\nYou must be wondering if we will ever be finished talking about paired samples t-tests… why are we doing round 2, oh no! Don’t worry, we’re just going to 1) remind you about what we were doing with the infant study, and 2) do a paired samples t-test on the entire data set and discuss.\nRemember, we were wondering if the infants would look longer toward the singer who sang the familiar song during the test phase compared to the baseline phase. We showed you data from 5 infants, and walked through the computations for the \\(t\\)-test. As a reminder, it looked like this:\n\n\n\n\n\n\n\n\n\n\n\n\n\ninfant\nBaseline\nTest\ndifferences\ndiff_from_mean\nSquared_differences\n\n\n\n\n1\n0.44\n0.6\n0.16\n0.106\n0.011236\n\n\n2\n0.41\n0.68\n0.27\n0.216\n0.046656\n\n\n3\n0.75\n0.72\n-0.03\n-0.084\n0.00705600000000001\n\n\n4\n0.44\n0.28\n-0.16\n-0.214\n0.045796\n\n\n5\n0.47\n0.5\n0.03\n-0.024\n0.000575999999999999\n\n\nSums\n2.51\n2.78\n0.27\n0\n0.11132\n\n\nMeans\n0.502\n0.556\n0.054\n0\n0.022264\n\n\n\n\n\n\nsd\n0.167\n\n\n\n\n\n\nSEM\n0.075\n\n\n\n\n\n\nt\n0.72\n\n\n\n\n\n\n    One Sample t-test\n\ndata:  round(differences, digits = 2)\nt = 0.72381, df = 4, p-value = 0.5092\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -0.1531384  0.2611384\nsample estimates:\nmean of x \n    0.054 \n\n\nLet’s write down the finding one more time: The mean difference was 0.054, \\(t\\)(4) = .72, \\(p\\) =.509. We can also now confirm, that the \\(p\\)-value was from a two-tailed test. So, what does this all really mean.\nWe can say that a \\(t\\) value with an absolute of .72 or larger occurs 50.9% of the time. More precisely, the distribution of no differences (the null), will produce a \\(t\\) value this large or larger 50.9% of the time. In other words, chance alone good have easily produced the \\(t\\) value from our sample, and the mean difference we observed or .054, could easily have been a result of chance.\nLet’s quickly put all of the data in the \\(t\\)-test, and re-run the test using all of the infant subjects.\n\npaired_sample_df &lt;-  data.frame(infant=1:32, \n                               Baseline = round(experiment_one$Baseline_Proportion_Gaze_to_Singer[1:32],digits=2), \n                               Test = round(experiment_one$Test_Proportion_Gaze_to_Singer[1:32], digits=2))\n\ndifferences &lt;-  paired_sample_df$Test-paired_sample_df$Baseline\nt.test(differences,mu=0)\n\n\n    One Sample t-test\n\ndata:  differences\nt = 2.4388, df = 31, p-value = 0.02066\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 0.01192088 0.13370412\nsample estimates:\nmean of x \n0.0728125 \n\n\nNow we get a very different answer. We would summarize the results saying the mean difference was .073, t(31) = 2.44, p = 0.020. How many total infants were their? Well the degrees of freedom was 31, so there must have been 32 infants in the study. Now we see a much smaller \\(p\\)-value. This was also a two-tailed test, so we that observing a \\(t\\) value of 2.4 or greater (absolute value) only occurs 2% of the time. In other words, the distribution of no differences will produce the observed t-value very rarely. So, it is unlikely that the observed mean difference of .073 was due to chance (it could have been due to chance, but that is very unlikely). As a result, we can be somewhat confident in concluding that something about seeing and hearing a unfamiliar person sing a familiar song, causes an infant to draw their attention toward the singer, and this potentially benefits social learning on the part of the infant.\n\n\n\nIf you’ve been following the Star Wars references, we are on last movie (of the original trilogy)… the independent t-test. This is were basically the same story plays out as before, only slightly different.\nRemember there are different \\(t\\)-tests for different kinds of research designs. When your design is a between-subjects design, you use an independent samples t-test. Between-subjects design involve different people or subjects in each experimental condition. If there are two conditions, and 10 people in each, then there are 20 total people. And, there are no paired scores, because every single person is measured once, not twice, no repeated measures. Because there are no repeated measures we can’t look at the difference scores between conditions one and two. The scores are not paired in any meaningful way, to it doesn’t make sense to subtract them. So what do we do?\nThe logic of the independent samples t-test is the very same as the other \\(t\\)-tests. We calculated the means for each group, then we find the difference. That goes into the numerator of the t formula. Then we get an estimate of the variation for the denominator. We divide the mean difference by the estimate of the variation, and we get \\(t\\). It’s the same as before.\nThe only wrinkle here is what goes into the denominator? How should we calculate the estimate of the variance? It would be nice if we could do something very straightforward like this, say for an experiment with two groups A and B:\n\\(t = \\frac{\\bar{A}-\\bar{B}}{(\\frac{SEM_A+SEM_B}{2})}\\)\nIn plain language, this is just:\n\nFind the mean difference for the top part\nCompute the SEM (standard error of the mean) for each group, and average them together to make a single estimate, pooling over both samples.\n\nThis would be nice, but unfortunately, it turns out that finding the average of two standard errors of the mean is not the best way to do it. This would create a biased estimator of the variation for the hypothesized distribution of no differences. We won’t go into the math here, but instead of the above formula, we an use a different one that gives as an unbiased estimate of the pooled standard error of the sample mean. Our new and improved \\(t\\) formula would look like this:\n\\(t = \\frac{\\bar{X_A}-\\bar{X_B}}{s_p * \\sqrt{\\frac{1}{n_A} + \\frac{1}{n_B}}}\\)\nand, \\(s_p\\), which is the pooled sample standard deviation is defined as, note the $s$es in the formula are variances:\n\\(s_p = \\sqrt{\\frac{(n_A-1)s_A^2 + (n_B-1)s^2_B}{n_A +n_B -2}}\\)\nBelieve you me, that is so much more formula than I wanted to type out. Shall we do one independent \\(t\\)-test example by hand, just to see the computations? Let’s do it…but in a slightly different way than you expect. I show the steps using R. I made some fake scores for groups A and B. Then, I followed all of the steps from the formula, but made R do each of the calculations. This shows you the needed steps by following the code. At the end, I print the \\(t\\)-test values I computed “by hand”, and then the \\(t\\)-test value that the R software outputs using the \\(t\\)-test function. You should be able to get the same values for \\(t\\), if you were brave enough to compute \\(t\\) by hand.\n\n## By \"hand\" using R r code\na &lt;- c(1,2,3,4,5)\nb &lt;- c(3,5,4,7,9)\n\nmean_difference &lt;- mean(a)-mean(b) # compute mean difference\n\nvariance_a &lt;- var(a) # compute variance for A\nvariance_b &lt;- var(b) # compute variance for B\n\n# Compute top part and bottom part of sp formula\n\nsp_numerator &lt;- (4*variance_a + 4* variance_b) \nsp_denominator &lt;- 5+5-2\nsp &lt;- sqrt(sp_numerator/sp_denominator) # compute sp\n\n\n# compute t following formulat\n\nt &lt;- mean_difference / ( sp * sqrt( (1/5) +(1/5) ) )\n\nt # print results\n\n[1] -2.017991\n\n# using the R function t.test\nt.test(a,b, paired=FALSE, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  a and b\nt = -2.018, df = 8, p-value = 0.0783\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -5.5710785  0.3710785\nsample estimates:\nmean of x mean of y \n      3.0       5.6 \n\n\n\n\n\nAn “advanced” topic for \\(t\\)-tests is the idea of using R to conduct simulations for \\(t\\)-tests.\nIf you recall, \\(t\\) is a property of a sample. We calculate \\(t\\) from our sample. The \\(t\\) distribution is the hypothetical behavior of our sample. That is, if we had taken thousands upon thousands of samples, and calculated \\(t\\) for each one, and then looked at the distribution of those \\(t\\)’s, we would have the sampling distribution of \\(t\\)!\nIt can be very useful to get in the habit of using R to simulate data under certain conditions, to see how your sample data, and things like \\(t\\) behave. Why is this useful? It mainly prepares you with some intuitions about how sampling error (random chance) can influence your results, given specific parameters of your design, such as sample-size, the size of the mean difference you expect to find in your data, and the amount of variation you might find. These methods can be used formally to conduct power-analyses. Or more informally for data sense.\n\n\nHere are the steps you might follow to simulate data for a one sample \\(t\\)-test.\n\nMake some assumptions about what your sample (that you might be planning to collect) might look like. For example, you might be planning to collect 30 subjects worth of data. The scores of those data points might come from a normal distribution (mean = 50, sd = 10).\nsample simulated numbers from the distribution, then conduct a \\(t\\)-test on the simulated numbers. Save the statistics you want (such as \\(t\\)s and \\(p\\)s), and then see how things behave.\n\nLet’s do this a couple different times. First, let’s simulate samples with N = 30, taken from a normal (mean= 50, sd = 25). We’ll do a simulation with 1000 simulations. For each simulation, we will compare the sample mean with a population mean of 50. There should be no difference on average here. Figure 11 is the null distribution that we are simulating.\n\n# steps to create fake data from a distribution\n# and conduct t-tests on the simulated data\nsave_ps &lt;- length(1000)\nsave_ts &lt;- length(1000)\nfor (i in 1:1000) {\n  my_sample &lt;- rnorm(n = 30, mean = 50, sd = 25)\n  t_test &lt;- t.test (my_sample, mu = 50)\n  save_ps[i] &lt;- t_test$p.value\n  save_ts[i] &lt;- t_test$statistic\n}\n\n\n#plot histograms of t and p values for 1000 simulations\nhist(save_ts)\n\n\n\n\n\n\n\nFigure 11: The distribution of \\(t\\)-values under the null. These are the \\(t\\) values that are produced by chance alone.\n\n\n\n\n\n\nhist(save_ps)\n\n\n\n\n\n\n\nFigure 12: The distribution of \\(p\\)-values that are observed is flat under the null.\n\n\n\n\n\nNeat. We see both a \\(t\\) distribution, that looks like \\(t\\) distribution as it should. And we see the \\(p\\) distribution. This shows us how often we get \\(t\\) values of particular sizes. You may find it interesting that the \\(p\\)-distribution is flat under the null, which we are simulating here. This means that you have the same chances of a getting a \\(t\\) with a p-value between 0 and 0.05, as you would for getting a \\(t\\) with a p-value between .90 and .95. Those ranges are both ranges of 5%, so there are an equal amount of \\(t\\) values in them by definition.\nHere’s another way to do the same simulation in R, using the replicate function, instead a for loop:\n\nsimulated_ts &lt;- replicate(1000,\n                          t.test(rnorm(30, 50, 25), mu = 50)$statistic)\nhist(simulated_ts)\n\n\n\n\n\n\n\nFigure 13: Simulating \\(t\\)s in R.\n\n\n\n\n\n\nsimulated_ps &lt;- replicate(1000,\n                          t.test(rnorm(30, 50, 25), mu = 50)$p.value)\nhist(simulated_ps)\n\n\n\n\n\n\n\nFigure 14: Simulating \\(p\\)s in R.\n\n\n\n\n\n\n\n\nThe code below is set up to sample 10 scores for condition A and B from the same normal distribution. The simulation is conducted 1000 times, and the \\(t\\)s and \\(p\\)s are saved and plotted for each.\n\nsave_ps &lt;- length(1000)\nsave_ts &lt;- length(1000)\nfor ( i in 1:1000 ){\n  condition_A &lt;- rnorm(10,10,5)\n  condition_B &lt;- rnorm(10,10,5)\n  differences &lt;- condition_A - condition_B\n  t_test &lt;- t.test(differences, mu=0)\n  save_ps[i] &lt;- t_test$p.value\n  save_ts[i] &lt;- t_test$statistic\n}\n\n\nhist(save_ts)\n\n\n\n\n\n\n\nFigure 15: 1000 simulated ts from the null distribution\n\n\n\n\n\n\nhist(save_ps)\n\n\n\n\n\n\n\nFigure 16: 1000 simulated ps from the null distribution\n\n\n\n\n\nAccording to the simulation. When there are no differences between the conditions, and the samples are being pulled from the very same distribution, you get these two distributions for \\(t\\) and \\(p\\). These again show how the null distribution of no differences behaves.\nFor any of these simulations, if you rejected the null-hypothesis (that your difference was only due to chance), you would be making a type I error. If you set your alpha criteria to \\(\\alpha = .05\\), we can ask how many type I errors were made in these 1000 simulations. The answer is:\n\nlength(save_ps[save_ps&lt;.05])\n\n[1] 53\n\nlength(save_ps[save_ps&lt;.05])/1000\n\n[1] 0.053\n\n\nWe happened to make 53. The expectation over the long run is 5% type I error rates (if your alpha is .05).\nWhat happens if there actually is a difference in the simulated data, let’s set one condition to have a larger mean than the other:\n\nsave_ps &lt;- length(1000)\nsave_ts &lt;- length(1000)\nfor ( i in 1:1000 ){\n  condition_A &lt;- rnorm(10,10,5)\n  condition_B &lt;- rnorm(10,13,5)\n  differences &lt;- condition_A - condition_B\n  t_test &lt;- t.test(differences, mu=0)\n  save_ps[i] &lt;- t_test$p.value\n  save_ts[i] &lt;- t_test$statistic\n}\n\n\nhist(save_ts)\n\n\n\n\n\n\n\nFigure 17: 1000 ts when there is a true difference\n\n\n\n\n\n\nhist(save_ps)\n\n\n\n\n\n\n\nFigure 18: 1000 ps when there is a true difference\n\n\n\n\n\nNow you can see that the \\(p\\)-value distribution is skewed to the left. This is because when there is a true effect, you will get p-values that are less than .05 more often. Or, rather, you get larger \\(t\\) values than you normally would if there were no differences.\nIn this case, we wouldn’t be making a type I error if we rejected the null when p was smaller than .05. How many times would we do that out of our 1000 experiments?\n\nlength(save_ps[save_ps&lt;.05])\n\n[1] 205\n\nlength(save_ps[save_ps&lt;.05])/1000\n\n[1] 0.205\n\n\nWe happened to get 205 simulations where p was less than .05, that’s only 0.205 experiments. If you were the researcher, would you want to run an experiment that would be successful only 0.205 of the time? I wouldn’t. I would run a better experiment.\nHow would you run a better simulated experiment? Well, you could increase \\(n\\), the number of subjects in the experiment. Let’s increase \\(n\\) from 10 to 100, and see what happens to the number of “significant” simulated experiments.\n\nsave_ps &lt;- length(1000)\nsave_ts &lt;- length(1000)\nfor ( i in 1:1000 ){\n  condition_A &lt;- rnorm(100,10,5)\n  condition_B &lt;- rnorm(100,13,5)\n  differences &lt;- condition_A - condition_B\n  t_test &lt;- t.test(differences, mu=0)\n  save_ps[i] &lt;- t_test$p.value\n  save_ts[i] &lt;- t_test$statistic\n}\n\n\nhist(save_ts)\n\n\n\n\n\n\n\nFigure 19: 1000 ts for n =100, when there is a true effect\n\n\n\n\n\n\nhist(save_ps)\n\n\nlength(save_ps[save_ps&lt;.05])\n\n[1] 988\n\nlength(save_ps[save_ps&lt;.05])/1000\n\n[1] 0.988\n\n\n\n\n\n\n\n\nFigure 20: 1000 ps for n =100, when there is a true effect\n\n\n\n\n\nCool, now almost all of the experiments show a \\(p\\)-value of less than .05 (using a two-tailed test, that’s the default in R). See, you could use this simulation process to determine how many subjects you need to reliably find your effect.\n\n\n\nJust change the t.test function like so… this is for the null, assuming no difference between groups.\n\nsave_ps &lt;- length(1000)\nsave_ts &lt;- length(1000)\nfor ( i in 1:1000 ){\n  group_A &lt;- rnorm(10,10,5)\n  group_B &lt;- rnorm(10,10,5)\n  t_test &lt;- t.test(group_A, group_B, paired=FALSE, var.equal=TRUE)\n  save_ps[i] &lt;- t_test$p.value\n  save_ts[i] &lt;- t_test$statistic\n}\n\n\nhist(save_ts)\n\n\n\n\n\n\n\nFigure 21: 1000 ts for n =100, when there is a true effect\n\n\n\n\n\n\nhist(save_ps)\n\n\nlength(save_ps[save_ps&lt;.05])\n\n[1] 43\n\nlength(save_ps[save_ps&lt;.05])/1000\n\n[1] 0.043\n\n\n\n\n\n\n\n\nFigure 22: 1000 ps for n =100, when there is a true effect",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "06-ttests"
    ]
  },
  {
    "objectID": "week01/06-ttests.html#check-your-confidence-in-your-mean",
    "href": "week01/06-ttests.html#check-your-confidence-in-your-mean",
    "title": "06-ttests",
    "section": "",
    "text": "We’ve talked about getting a sample of data. We know we can find the mean, we know we can find the standard deviation. We know we can look at the data in a histogram. These are all useful things to do for us to learn something about the properties of our data.\nYou might be thinking of the mean and standard deviation as very different things that we would not put together. The mean is about central tendency (where most of the data is), and the standard deviation is about variance (where most of the data isn’t). Yes, they are different things, but we can use them together to create useful new things.\nWhat if I told you my sample mean was 50, and I told you nothing else about my sample. Would you be confident that most of the numbers were near 50? Would you wonder if there was a lot of variability in the sample, and many of the numbers were very different from 50. You should wonder all of those things. The mean alone, just by itself, doesn’t tell you anything about well the mean represents all of the numbers in the sample.\nIt could be a representative number, when the standard deviation is very small, and all the numbers are close to 50. It could be a non-representative number, when the standard deviation is large, and many of the numbers are not near 50. You need to know the standard deviation in order to be confident in how well the mean represents the data.\nHow can we put the mean and the standard deviation together, to give us a new number that tells us about confidence in the mean?\nWe can do this using a ratio:\n\\(\\frac{mean}{\\text{standard deviation}}\\)\nThink about what happens here. We are dividing a number by a number. Look at what happens:\n\\(\\frac{number}{\\text{same number}} = 1\\)\n\\(\\frac{number}{\\text{smaller number}} = \\text{big number}\\)\ncompared to:\n\\(\\frac{number}{\\text{bigger number}} = \\text{smaller number}\\)\nImagine we have a mean of 50, and a truly small standard deviation of 1. What do we get with our formula?\n\\(\\frac{50}{1} = 50\\)\nImagine we have a mean of 50, and a big standard deviation of 100. What do we get with our formula?\n\\(\\frac{50}{100} = 0.5\\)\nNotice, when we have a mean paired with a small standard deviation, our formula gives us a big number, like 50. When we have a mean paired with a large standard deviation, our formula gives us a small number, like 0.5. These numbers can tell us something about confidence in our mean, in a general way. We can be 50 confident in our mean in the first case, and only 0.5 (not at a lot) confident in the second case.\nWhat did we do here? We created a descriptive statistic by dividing the mean by the standard deviation. And, we have a sense of how to interpret this number, when it’s big we’re more confident that the mean represents all of the numbers, when it’s small we are less confident. This is a useful kind of number, a ratio between what we think about our sample (the mean), and the variability in our sample (the standard deviation). Get used to this idea. Almost everything that follows in this textbook is based on this kind of ratio. We will see that our ratio turns into different kinds of “statistics”, and the ratios will look like this in general:\n\\(\\text{name of statistic} = \\frac{\\text{measure of what we know}}{\\text{measure of what we don't know}}\\)\nor, to say it using different words:\n\\(\\text{name of statistic} = \\frac{\\text{measure of effect}}{\\text{measure of error}}\\)\nIn fact, this is the general formula for the t-test. Big surprise!",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "06-ttests"
    ]
  },
  {
    "objectID": "week01/06-ttests.html#one-sample-t-test-a-new-t-test",
    "href": "week01/06-ttests.html#one-sample-t-test-a-new-t-test",
    "title": "06-ttests",
    "section": "",
    "text": "Now we are ready to talk about t-test. We will talk about three of them. We start with the one-sample t-test.\nCommonly, the one-sample t-test is used to estimate the chances that your sample came from a particular population. Specifically, you might want to know whether the mean that you found from your sample, could have come from a particular population having a particular mean.\nStraight away, the one-sample t-test becomes a little confusing (and I haven’t even described it yet). Officially, it uses known parameters from the population, like the mean of the population and the standard deviation of the population. However, most times you don’t know those parameters of the population! So, you have to estimate them from your sample. Remember from the chapters on descriptive statistics and sampling, our sample mean is an unbiased estimate of the population mean. And, our sample standard deviation (the one where we divide by n-1) is an unbiased estimate of the population standard deviation. When Gosset developed the t-test, he recognized that he could use these estimates from his samples, to make the t-test. Here is the formula for the one sample t-test, we first use words, and then become more specific:\n\n\n\\(\\text{name of statistic} = \\frac{\\text{measure of effect}}{\\text{measure of error}}\\)\n\\(\\text{t} = \\frac{\\text{measure of effect}}{\\text{measure of error}}\\)\n\\(\\text{t} = \\frac{\\text{Mean difference}}{\\text{standard error}}\\)\n\\(\\text{t} = \\frac{\\bar{X}-u}{S_{\\bar{X}}}\\)\n\\(\\text{t} = \\frac{\\text{Sample Mean  - Population Mean}}{\\text{Sample Standard Error}}\\)\n\\(\\text{Estimated Standard Error} = \\text{Standard Error of Sample} = \\frac{s}{\\sqrt{N}}\\)\nWhere, s is the sample standard deviation.\nSome of you may have gone cross-eyed looking at all of this. Remember, we’ve seen it before when we divided our mean by the standard deviation in the first bit. The t-test is just a measure of a sample mean, divided by the standard error of the sample mean. That is it.\n\n\n\n\\(t\\) gives us a measure of confidence, just like our previous ratio for dividing the mean by a standard deviations. The only difference with \\(t\\), is that we divide by the standard error of mean (remember, this is also a standard deviation, it is the standard deviation of the sampling distribution of the mean)\n\n\n\n\n\n\nNote\n\n\n\nWhat does the t in t-test stand for? Apparently nothing. Gosset originally labelled it z. And, Fisher later called it t, perhaps because t comes after s, which is often used for the sample standard deviation.\n\n\n\\(t\\) is a property of the data that you collect. You compute it with a sample mean, and a sample standard error (there’s one more thing in the one-sample formula, the population mean, which we get to in a moment). This is why we call \\(t\\), a sample-statistic. It’s a statistic we compute from the sample.\nWhat kinds of numbers should we expect to find for these \\(ts\\)? How could we figure that out?\nLet’s start small and work through some examples. Imagine your sample mean is 5. You want to know if it came from a population that also has a mean of 5. In this case, what would \\(t\\) be? It would be zero: we first subtract the sample mean from the population mean, \\(5-5=0\\). Because the numerator is 0, \\(t\\) will be zero. So, \\(t\\) = 0, occurs, when there is no difference.\nLet’s say you take another sample, do you think the mean will be 5 every time, probably not. Let’s say the mean is 6. So, what can \\(t\\) be here? It will be a positive number, because 6-5= +1. But, will \\(t\\) be +1? That depends on the standard error of the sample. If the standard error of the sample is 1, then \\(t\\) could be 1, because 1/1 = 1.\nIf the sample standard error is smaller than 1, what happens to \\(t\\)? It get’s bigger right? For example, 1 divided by 0.5 = 2. If the sample standard error was 0.5, \\(t\\) would be 2. And, what could we do with this information? Well, it be like a measure of confidence. As \\(t\\) get’s bigger we could be more confident in the mean difference we are measuring.\nCan \\(t\\) be smaller than 1? Sure, it can. If the sample standard error is big, say like 2, then \\(t\\) will be smaller than one (in our case), e.g., 1/2 = .5. The direction of the difference between the sample mean and population mean, can also make the \\(t\\) become negative. What if our sample mean was 4. Well, then \\(t\\) will be negative, because the mean difference in the numerator will be negative, and the number in the bottom (denominator) will always be positive (remember why, it’s the standard error, computed from the sample standard deviation, which is always positive because of the squaring that we did.).\nSo, that is some intuitions about what the kinds of values t can take. \\(t\\) can be positive or negative, and big or small.\nLet’s do one more thing to build our intuitions about what \\(t\\) can look like. How about we sample some numbers and then measure the sample mean and the standard error of the mean, and then plot those two things against each each. This will show us how a sample mean typically varies with respect to the standard error of the mean.\nIn Figure 1, I pulled 1,000 samples of \\(N = 10\\) from a normal distribution (mean = 0, sd = 1). Each time I measured the mean and standard error of the sample. That gave two descriptive statistics for each sample, letting us plot each sample as dot in a scatter plot.\n\nsample_mean &lt;- length(1000)\nsample_se &lt;- length(1000)\n\nfor (i in 1:1000) {\n  s &lt;- rnorm(10, 0, 1)\n  sample_mean[i] &lt;- mean(s)\n  sample_se[i] &lt;- sd(s) / sqrt(length(s))\n}\n\nplot(sample_mean, sample_se)\n\n\n\n\n\n\n\nFigure 1: A scatter plot with sample mean on the x-axis, and standard error of the mean on the y-axis\n\n\n\n\n\nWhat we get is a cloud of dots. You might notice the cloud has a circular quality. There’s more dots in the middle, and fewer dots as they radiate out from the middle. The dot cloud shows us the general range of the sample mean, for example most of the dots are in between -1 and 1. Similarly, the range for the sample standard error is roughly between .2 and .5. Remember, each dot represents one sample.\nWe can look at the same data a different way. For example, rather than using a scatter plot, we can divide the mean for each dot by the standard error for each dot. Figure 2 shows the result in a histogram.\n\nhist(sample_mean/sample_se, breaks=30)\n\n\n\n\n\n\n\nFigure 2: A histogram of the sample means divided by the sample standard errors, this is a t-distribution.\n\n\n\n\n\nInteresting, we can see the histogram is shaped like a normal curve. It is centered on 0, which is the most common value. As values become more extreme, they become less common. If you remember, our formula for \\(t\\), was the mean divided by the standard error of the mean. That’s what we did here. This histogram is showing you a \\(t\\)-distribution.\n\n\n\nLet’s briefly calculate a t-value from a small sample. Let’s say we had 10 students do a true/false quiz with 5 questions on it. There’s a 50% chance of getting each answer correct.\nEvery student completes the 5 questions, we grade them, and then we find their performance (mean percent correct). What we want to know is whether the students were guessing. If they were all guessing, then the sample mean should be about 50%, it shouldn’t be different from chance, which is 50%. Let’s look at Table 1.\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\n\nTable 1: Calculating the t-value for a one-sample test.\n\n\n\n\n\n\nstudents\nscores\nmean\nDifference_from_Mean\nSquared_Deviations\n\n\n\n\n1\n50\n61\n-11\n121\n\n\n2\n70\n61\n9\n81\n\n\n3\n60\n61\n-1\n1\n\n\n4\n40\n61\n-21\n441\n\n\n5\n80\n61\n19\n361\n\n\n6\n30\n61\n-31\n961\n\n\n7\n90\n61\n29\n841\n\n\n8\n60\n61\n-1\n1\n\n\n9\n70\n61\n9\n81\n\n\n10\n60\n61\n-1\n1\n\n\nSums\n610\n610\n0\n2890\n\n\nMeans\n61\n61\n0\n289\n\n\n\n\n\nsd\n17.92\n\n\n\n\n\nSEM\n5.67\n\n\n\n\n\nt\n1.94003527336861\n\n\n\n\n\n\n\n\nYou can see the scores column has all of the test scores for each of the 10 students. We did the things we need to do to compute the standard deviation.\nRemember the sample standard deviation is the square root of the sample variance, or:\n\\(\\text{sample standard deviation} = \\sqrt{\\frac{\\sum_{i}^{n}({x_{i}-\\bar{x})^2}}{N-1}}\\)\n\\(\\text{sd} = \\sqrt{\\frac{2890}{10-1}} = 17.92\\)\nThe standard error of the mean, is the standard deviation divided by the square root of N\n\\(\\text{SEM} = \\frac{s}{\\sqrt{N}} = \\frac{17.92}{10} = 5.67\\)\n\\(t\\) is the difference between our sample mean (61), and our population mean (50, assuming chance), divided by the standard error of the mean.\n\\(\\text{t} = \\frac{\\bar{X}-u}{S_{\\bar{X}}} = \\frac{\\bar{X}-u}{SEM} = \\frac{61-50}{5.67} = 1.94\\)\nAnd, that is you how calculate \\(t\\), by hand. It’s a pain. I was annoyed doing it this way. In the lab, you learn how to calculate \\(t\\) using software, so it will just spit out \\(t\\). For example in R, all you have to do is this:\n\nt.test(scores, mu=50)\n\n\n    One Sample t-test\n\ndata:  scores\nt = 1.9412, df = 9, p-value = 0.08415\nalternative hypothesis: true mean is not equal to 50\n95 percent confidence interval:\n 48.18111 73.81889\nsample estimates:\nmean of x \n       61 \n\n\n\n\n\nIf \\(t\\) is just a number that we can compute from our sample (it is), what can we do with it? How can we use \\(t\\) for statistical inference?\nRemember back to the chapter on sampling and distributions, that’s where we discussed the sampling distribution of the sample mean. Remember, we made a lot of samples, then computed the mean for each sample, then we plotted a histogram of the sample means. Later, in that same section, we mentioned that we could generate sampling distributions for any statistic. For each sample, we could compute the mean, the standard deviation, the standard error, and now even \\(t\\), if we wanted to. We could generate 10,000 samples, and draw four histograms, one for each sampling distribution for each statistic.\nThis is exactly what I did, and the results are shown in the four panels of Figure 3 below. I used a sample size of 20, and drew random observations for each sample from a normal distribution, with mean = 0, and standard deviation = 1. Let’s look at the sampling distributions for each of the statistics. \\(t\\) was computed assuming with the population mean assumed to be 0.\n\nall_df &lt;- data.frame()\nfor (i in 1:10000) {\n  sample &lt;- rnorm(20, 0, 1)\n  sample_mean &lt;- mean(sample)\n  sample_sd &lt;- sd(sample)\n  sample_se &lt;- sd(sample) / sqrt(length(sample))\n  sample_t &lt;- as.numeric(t.test(sample, mu = 0)$statistic)\n  t_df &lt;- data.frame(i, sample_mean, sample_sd, sample_se, sample_t)\n  all_df &lt;- rbind(all_df, t_df)\n}\n\nlibrary(ggpubr)\na &lt;- ggplot(all_df, aes(x = sample_mean)) +\n  geom_histogram(color = \"white\") +\n  theme_classic(base_size=20)\nb &lt;- ggplot(all_df, aes(x = sample_sd)) +\n  geom_histogram(color = \"white\") +\n  theme_classic(base_size=20)\nc &lt;- ggplot(all_df, aes(x = sample_se)) +\n  geom_histogram(color = \"white\") +\n  theme_classic(base_size=20)\nd &lt;- ggplot(all_df, aes(x = sample_t)) +\n  geom_histogram(color = \"white\") +\n  theme_classic(base_size=20)\n\nggarrange(a, b, c, d,\n          ncol = 2, nrow = 2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nFigure 3: Sampling distributions for the mean, standard deviation, standard error of the mean, and \\(t\\).\n\n\n\n\n\nWe see four sampling distributions. This is how statistical summaries of these summaries behave. We have used the word chance windows before. These are four chance windows, measuring different aspects of the sample. In this case, all of the samples came from the same normal distribution. Because of sampling error, each sample is not identical. The means are not identical, the standard deviations are not identical, sample standard error of the means are not identical, and the \\(t\\)s of the samples are not identical. They all have some variation, as shown by the histograms. This is how samples of size 20 behave.\nWe can see straight away, that in this case, we are unlikely to get a sample mean of 2. That’s way outside the window. The range for the sampling distribution of the mean is around -.5 to +.5, and is centered on 0 (the population mean, would you believe!).\nWe are unlikely to get sample standard deviations of between .6 and 1.5, that is a different range, specific to the sample standard deviation.\nSame thing with the sample standard error of the mean, the range here is even smaller, mostly between .1, and .3. You would rarely find a sample with a standard error of the mean greater than .3. Virtually never would you find one of say 1 (for this situation).\nNow, look at \\(t\\). It’s range is basically between -3 and +3 here. 3s barely happen at all. You pretty much never see a 5 or -5 in this situation.\nAll of these sampling windows are chance windows, and they can all be used in the same way as we have used similar sampling distributions before (e.g., Crump Test, and Randomization Test) for statistical inference. For all of them we would follow the same process:\n\nGenerate these distributions\nLook at your sample statistics for the data you have (mean, SD, SEM, and \\(t\\))\nFind the likelihood of obtaining that value or greater\nObtain that probability\nSee if you think your sample statistics were probable or improbable.\n\nWe’ll formalize this in a second. I just want you to know that what you will be doing is something that you have already done before. For example, in the Crump test and the Randomization test we focused on the distribution of mean differences. We could do that again here, but instead, we will focus on the distribution of \\(t\\) values. We then apply the same kinds of decision rules to the \\(t\\) distribution, as we did for the other distributions. Below you will see a graph you have already seen, except this time it is a distribution of \\(t\\)s, not mean differences:\nRemember, if we obtained a single \\(t\\) from one sample we collected, we could consult the chance window in Figure 4 below to find out whether the \\(t\\) we obtained from the sample was likely or unlikely to occur by chance.\n\nsample_t &lt;- all_df$sample_t\n\nggplot(all_df, aes(x = sample_t)) +\n  annotate(\n    \"rect\",\n    xmin = min(sample_t),\n    xmax = max(sample_t),\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.5,\n    fill = \"red\"\n  ) +\n  annotate(\n    \"rect\",\n    xmin = min(sample_t),\n    xmax = -1.94,\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.7,\n    fill = \"light grey\"\n  ) +\n  annotate(\n    \"rect\",\n    xmin = 1.94,\n    xmax = max(sample_t),\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.7,\n    fill = \"light grey\"\n  ) +\n  geom_rect(aes(\n    xmin = -Inf,\n    xmax = min(sample_t),\n    ymin = 0,\n    ymax = Inf\n  ),\n  alpha = .5,\n  fill = \"lightgreen\") +\n  geom_rect(aes(\n    xmin = max(sample_t),\n    xmax = Inf,\n    ymin = 0,\n    ymax = Inf\n  ),\n  alpha = .5,\n  fill = \"lightgreen\") +\n  geom_histogram(bins = 50, color = \"white\") +\n  theme_classic() +\n  geom_vline(xintercept = min(sample_t)) +\n  geom_vline(xintercept = max(sample_t)) +\n  geom_vline(xintercept = -1.94) +\n  geom_vline(xintercept = 1.94) +\n  xlim(-8, 8) +\n  geom_label(data = data.frame(x = 0, y = 250, label = \"CHANCE\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = -7, y = 250, label = \"NOT \\n CHANCE\"),\n             aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = 7, y = 250, label = \"NOT \\n CHANCE\"),\n             aes(x = x, y = y, label = label)) +\n  #  geom_label(data = data.frame(x = min(sample_t), y = 600,\n  #                              label = paste0(\"min \\n\",round(min(sample_t)))),\n  #                             aes(x = x, y = y, label = label))+\n  #geom_label(data = data.frame(x = max(sample_t), y = 600,\n  #                            label = paste0(\"max \\n\",round(max(sample_t)))),\n  #                           aes(x = x, y = y, label = label))+\n  geom_label(data = data.frame(x = -4, y = 250,\n                               label = \"?\"),\n             aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = 4, y = 250,\n                               label = \"?\"),\n             aes(x = x, y = y, label = label)) +\n  xlab(\"mean sample_t\")\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\nFigure 4: Applying decision criteria to the \\(t\\)-distribution. Histogram of \\(t\\)s from samples (n=20) drawn from the same normal distribution (u=0, sd=1)\n\n\n\n\n\n\n\n\nFrom our early example involving the TRUE/FALSE quizzes, we are now ready to make some kind of decision about what happened there. We found a mean difference of 11. We found a \\(t\\) = 1.9411765. The probability of this \\(t\\) or larger occurring is \\(p\\) = 0.0841503. We were testing the idea that our sample mean of 61 could have come from a normal distribution with mean = 50. The \\(t\\) test tells us that the \\(t\\) for our sample, or a larger one, would happen with p = 0.0841503. In other words, chance can do it a kind of small amount of time, but not often. In English, this means that all of the students could have been guessing, but it wasn’t that likely that were just guessing.\nThe next \\(t\\)-test is called a paired samples t-test. And, spoiler alert, we will find out that a paired samples t-test is actually a one-sample t-test in disguise (WHAT!), yes it is. If the one-sample \\(t\\)-test didn’t make sense to you, read the next section.",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "06-ttests"
    ]
  },
  {
    "objectID": "week01/06-ttests.html#paired-samples-t-test",
    "href": "week01/06-ttests.html#paired-samples-t-test",
    "title": "06-ttests",
    "section": "",
    "text": "For me (Crump), many analyses often boil down to a paired samples t-test. It just happens that many things I do reduce down to a test like this.\nI am a cognitive psychologist, I conduct research about how people do things like remember, pay attention, and learn skills. There are lots of Psychologists like me, who do very similar things.\nWe all often conduct the same kinds of experiments. They go like this, and they are called repeated measures designs. They are called repeated measures designs, because we measure how one person does something more than once, we repeat the measure.\nSo, I might measure somebody doing something in condition A, and measure the same person doing something in Condition B, and then I see that same person does different things in the two conditions. I repeatedly measure the same person in both conditions. I am interested in whether the experimental manipulation changes something about how people perform the task in question.\n\n\nWe will introduce the paired-samples t-test with an example using real data, from a real study. (mehr20165?) were interested in whether singing songs to infants helps infants become more sensitive to social cues. For example, infants might need to learn to direct their attention toward people as a part of learning how to interact socially with people. Perhaps singing songs to infants aids this process of directing attention. When an infant hears a familiar song, they might start to pay more attention to the person singing that song, even after they are done singing the song. The person who sang the song might become more socially important to the infant. You will learn more about this study in the lab for this week. This example, prepares you for the lab activities. Here is a brief summary of what they did.\nFirst, parents were trained to sing a song to their infants. After many days of singing this song to the infants, a parent came into the lab with their infant. In the first session, parents sat with their infants on their knees, so the infant could watch two video presentations. There were two videos. Each video involved two unfamiliar new people the infant had never seen before. Each new person in the video (the singers) sang one song to the infant. One singer sang the “familiar” song the infant had learned from their parents. The other singer sang an “unfamiliar” song the infant had not hear before.\nThere were two really important measurement phases: the baseline phase, and the test phase.\nThe baseline phase occurred before the infants saw and heard each singer sing a song. During the baseline phase, the infants watched a video of both singers at the same time. The researchers recorded the proportion of time that the infant looked at each singer. The baseline phase was conducted to determine whether infants had a preference to look at either person (who would later sing them a song).\nThe test phase occurred after infants saw and heard each song, sung by each singer. During the test phase, each infant had an opportunity to watch silent videos of both singers. The researchers measured the proportion of time the infants spent looking at each person. The question of interest, was whether the infants would spend a greater proportion of time looking at the singer who sang the familiar song, compared to the singer who sang the unfamiliar song.\nThere is more than one way to describe the design of this study. We will describe it like this. It was a repeated measures design, with one independent (manipulation) variable called Viewing phase: Baseline versus Test. There was one dependent variable (the measurement), which was proportion looking time (to singer who sung familiar song). This was a repeated measures design because the researchers measured proportion looking time twice (they repeated the measure), once during baseline (before infants heard each singer sing a song), and again during test (after infants head each singer sing a song).\nThe important question was whether infants would change their looking time, and look more at the singer who sang the familiar song during the test phase, than they did during the baseline phase. This is a question about a change within individual infants. In general, the possible outcomes for the study are:\n\nNo change: The difference between looking time toward the singer of the familiar song during baseline and test is zero, no difference.\nPositive change: Infants will look longer toward the singer of the familiar song during the test phase (after they saw and heard the singers), compared to the baseline phase (before they saw and heard the singers). This is a positive difference if we use the formula: Test Phase Looking time - Baseline phase looking time (to familiar song singer).\nNegative change: Infants will look longer toward the singer of the unfamiliar song during the test phase (after they saw and heard the singers), compared to the baseline phase (before they saw and heard the singers). This is a negative difference if we use the same formula: Test Phase Looking time - Baseline phase looking time (to familiar song singer).\n\n\n\n\nLet’s take a look at the data for the first 5 infants in the study. This will help us better understand some properties of the data before we analyze it. We will see that the data is structured in a particular way that we can take advantage of with a paired samples t-test. Note, we look at the first 5 infants to show how the computations work. The results of the paired-samples t-test change when we use all of the data from the study.\nHere is a table of the data:\n\n\n\nAttaching package: 'data.table'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\n\n\n\n\ninfant\nBaseline\nTest\n\n\n\n\n1\n0.44\n0.60\n\n\n2\n0.41\n0.68\n\n\n3\n0.75\n0.72\n\n\n4\n0.44\n0.28\n\n\n5\n0.47\n0.50\n\n\n\n\n\nThe table shows proportion looking times toward the singer of the familiar song during the Baseline and Test phases. Notice there are five different infants, (1 to 5). Each infant is measured twice, once during the Baseline phase, and once during the Test phase. To repeat from before, this is a repeated-measures design, because the infants are measured repeatedly (twice in this case). Or, this kind of design is also called a paired-samples design. Why? because each participant comes with a pair of samples (two samples), one for each level of the design.\nGreat, so what are we really interested in here? We want to know if the mean looking time toward the singer of the familiar song for the Test phase is higher than the Baseline phase. We are comparing the two sample means against each other and looking for a difference. We already know that differences could be obtained by chance alone, simply because we took two sets of samples, and we know that samples can be different. So, we are interested in knowing whether chance was likely or unlikely to have produced any difference we might observe.\nIn other words, we are interested in looking at the difference scores between the baseline and test phase for each infant. The question here is, for each infant, did their proportion looking time to the singer of the familiar song, increase during the test phase as compared to the baseline phase.\n\n\n\nLet’s add the difference scores to the table of data so it is easier to see what we are talking about. The first step in creating difference scores is to decide how you will take the difference, there are two options:\n\nTest phase score - Baseline Phase Score\nBaseline phase score - Test Phase score\n\nLet’s use the first formula. Why? Because it will give us positive differences when the test phase score is higher than the baseline phase score. This makes a positive score meaningful with respect to the study design, we know (because we defined it to be this way), that positive scores will refer to longer proportion looking times (to singer of familiar song) during the test phase compared to the baseline phase.\n\npaired_sample_df &lt;- cbind(paired_sample_df, \n                          differences = (paired_sample_df$Test-\n                                           paired_sample_df$Baseline))\nknitr::kable(paired_sample_df)\n\n\n\n\ninfant\nBaseline\nTest\ndifferences\n\n\n\n\n1\n0.44\n0.60\n0.16\n\n\n2\n0.41\n0.68\n0.27\n\n\n3\n0.75\n0.72\n-0.03\n\n\n4\n0.44\n0.28\n-0.16\n\n\n5\n0.47\n0.50\n0.03\n\n\n\n\n\nThere we have it, the difference scores. The first thing we can do here is look at the difference scores, and ask how many infants showed the effect of interest. Specifically, how many infants showed a positive difference score. We can see that three of five infants showed a positive difference (they looked more at the singer of the familiar song during the test than baseline phase), and two the infants showed the opposite effect (negative difference, they looked more at the singer of the familiar song during baseline than test).\n\n\n\nAs we have been discussing, the effect of interest in this study is the mean difference between the baseline and test phase proportion looking times. We can calculate the mean difference, by finding the mean of the difference scores. Let’s do that, in fact, for fun let’s calculate the mean of the baseline scores, the test scores, and the difference scores.\n\npaired_sample_df &lt;- paired_sample_df %&gt;%\n   rbind(c(\"Sums\",colSums(paired_sample_df[1:5,2:4]))) %&gt;%\n   rbind(c(\"Means\",colMeans(paired_sample_df[1:5,2:4])))\n  \nknitr::kable(paired_sample_df)\n\n\n\n\ninfant\nBaseline\nTest\ndifferences\n\n\n\n\n1\n0.44\n0.6\n0.16\n\n\n2\n0.41\n0.68\n0.27\n\n\n3\n0.75\n0.72\n-0.03\n\n\n4\n0.44\n0.28\n-0.16\n\n\n5\n0.47\n0.5\n0.03\n\n\nSums\n2.51\n2.78\n0.27\n\n\nMeans\n0.502\n0.556\n0.054\n\n\n\n\n\nWe can see there was a positive mean difference of 0.054, between the test and baseline phases.\nCan we rush to judgment and conclude that infants are more socially attracted to individuals who have sung them a familiar song? I would hope not based on this very small sample. First, the difference in proportion looking isn’t very large, and of course we recognize that this difference could have been produced by chance.\nWe will more formally evaluate whether this difference could have been caused by chance with the paired-samples t-test. But, before we do that, let’s again calculate \\(t\\) and discuss what \\(t\\) tells us over and above what our measure of the mean of the difference scores tells us.\n\n\n\nOK, so how do we calculate \\(t\\) for a paired-samples \\(t\\)-test? Surprise, we use the one-sample t-test formula that you already learned about! Specifically, we use the one-sample \\(t\\)-test formula on the difference scores. We have one sample of difference scores (you can see they are in one column), so we can use the one-sample \\(t\\)-test on the difference scores. Specifically, we are interested in comparing whether the mean of our difference scores came from a distribution with mean difference = 0. This is a special distribution we refer to as the null distribution. It is the distribution no differences. Of course, this null distribution can produce differences due to to sampling error, but those differences are not caused by any experimental manipulation, they caused by the random sampling process.\nWe calculate \\(t\\) in a moment. Let’s now consider again why we want to calculate \\(t\\)? Why don’t we just stick with the mean difference we already have?\nRemember, the whole concept behind \\(t\\), is that it gives an indication of how confident we should be in our mean. Remember, \\(t\\) involves a measure of the mean in the numerator, divided by a measure of variation (standard error of the sample mean) in the denominator. The resulting \\(t\\) value is small when the mean difference is small, or when the variation is large. So small \\(t\\)-values tell us that we shouldn’t be that confident in the estimate of our mean difference. Large \\(t\\)-values occur when the mean difference is large and/or when the measure of variation is small. So, large \\(t\\)-values tell us that we can be more confident in the estimate of our mean difference. Let’s find \\(t\\) for the mean difference scores. We use the same formulas as we did last time:\n\n\n\n\n\n\n\n\n\n\n\n\n\ninfant\nBaseline\nTest\ndifferences\ndiff_from_mean\nSquared_differences\n\n\n\n\n1\n0.44\n0.6\n0.16\n0.106\n0.011236\n\n\n2\n0.41\n0.68\n0.27\n0.216\n0.046656\n\n\n3\n0.75\n0.72\n-0.03\n-0.084\n0.00705600000000001\n\n\n4\n0.44\n0.28\n-0.16\n-0.214\n0.045796\n\n\n5\n0.47\n0.5\n0.03\n-0.024\n0.000575999999999999\n\n\nSums\n2.51\n2.78\n0.27\n0\n0.11132\n\n\nMeans\n0.502\n0.556\n0.054\n0\n0.022264\n\n\n\n\n\n\nsd\n0.167\n\n\n\n\n\n\nSEM\n0.075\n\n\n\n\n\n\nt\n0.72\n\n\n\n\n\nIf we did this test using R, we would obtain almost the same numbers (there is a little bit of rounding in the table).\n\nt.test(differences,mu=0)\n\n\n    One Sample t-test\n\ndata:  differences\nt = 0.72381, df = 4, p-value = 0.5092\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -0.1531384  0.2611384\nsample estimates:\nmean of x \n    0.054 \n\n\nHere is a quick write up of our t-test results, t(4) = .72, p = .509.\nWhat does all of that tell us? There’s a few things we haven’t gotten into much yet. For example, the 4 represents degrees of freedom, which we discuss later. The important part, the \\(t\\) value should start to be a little bit more meaningful. We got a kind of small t-value didn’t we. It’s .72. What can we tell from this value? First, it is positive, so we know the mean difference is positive. The sign of the \\(t\\)-value is always the same as the sign of the mean difference (ours was +0.054). We can also see that the p-value was .509. We’ve seen p-values before. This tells us that our \\(t\\) value or larger, occurs about 50.9% of the time… Actually it means more than this. And, to understand it, we need to talk about the concept of two-tailed and one-tailed tests.\n\n\n\nRemember what it is we are doing here. We are evaluating whether our sample data could have come from a particular kind of distribution. The null distribution of no differences. This is the distribution of \\(t\\)-values that would occur for samples of size 5, with a mean difference of 0, and a standard error of the sample mean of .075 (this is the SEM that we calculated from our sample). We can see what this particular null-distribution looks like in Figure 5.\n\nrange &lt;- seq(-3, 3, .1)\nnull_distribution &lt;- dt(range, 4, log = FALSE)\nplot_df &lt;- data.frame(range, null_distribution)\n\nggplot(plot_df, aes(x = range, y = null_distribution)) +\n  geom_line() +\n  xlab(\"t-values\") +\n  ylab(\"Probability\") +\n  theme(axis.text.y = element_blank(), axis.ticks = element_blank()) +\n  scale_x_continuous(breaks = (seq(-3, 3, .5))) +\n  geom_label(data = data.frame(x = -.7, y = .1, label = \"50% \\n (-)\"),\n             aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = .7, y = .1, label = \"50% \\n (+)\"), aes(x = x, y = y, label = label)) +\n  geom_vline(xintercept = 0)+\n  theme_classic(base_size = 20)\n\n\n\n\n\n\n\nFigure 5: A distribution of \\(t\\)-values that can occur by chance alone, when there is no difference between the sample and a population\n\n\n\n\n\nThe \\(t\\)-distribution above shows us the kinds of values \\(t\\) will will take by chance alone, when we measure the mean differences for pairs of 5 samples (like our current). \\(t\\) is most likely to be zero, which is good, because we are looking at the distribution of no-differences, which should most often be 0! But, sometimes, due to sampling error, we can get \\(t\\)s that are bigger than 0, either in the positive or negative direction. Notice the distribution is symmetrical, a \\(t\\) from the null-distribution will be positive half of the time, and negative half of the time, that is what we would expect by chance.\nSo, what kind of information do we want know when we find a particular \\(t\\) value from our sample? We want to know how likely the \\(t\\) value like the one we found occurs just by chance. This is actually a subtly nuanced kind of question. For example, any particular \\(t\\) value doesn’t have a specific probability of occurring. When we talk about probabilities, we are talking about ranges of probabilities. Let’s consider some probabilities. We will use the letter \\(p\\), to talk about the probabilities of particular \\(t\\) values.\n\nWhat is the probability that \\(t\\) is zero or positive or negative? The answer is p=1, or 100%. We will always have a \\(t\\) value that is zero or non-zero…Actually, if we can’t compute the t-value, for example when the standard deviation is undefined, I guess then we would have a non-number. But, assuming we can calculate \\(t\\), then it will always be 0 or positive or negative.\nWhat is the probability of \\(t\\) = 0 or greater than 0? The answer is p=.5, or 50%. 50% of \\(t\\)-values are 0 or greater.\nWhat is the of \\(t\\) = 0 or smaller than 0? The answer is p=.5, or 50%. 50% of \\(t\\)-values are 0 or smaller.\n\nWe can answer all of those questions just by looking at our t-distribution, and dividing it into two equal regions, the left side (containing 50% of the \\(t\\) values), and the right side containing 50% of the \\(t\\)-values).\nWhat if we wanted to take a more fine-grained approach, let’s say we were interested in regions of 10%. What kinds of \\(t\\)s occur 10% of the time. We would apply lines like the following. Notice, the likelihood of bigger numbers (positive or negative) gets smaller, so we have to increase the width of the bars for each of the intervals between the bars to contain 10% of the \\(t\\)-values, it looks like Figure 6.\n\nrange &lt;- seq(-3, 3, .1)\nnull_distribution &lt;- dt(range, 4, log = FALSE)\nplot_df &lt;- data.frame(range, null_distribution)\n\nt_ps &lt;- qt(seq(.1, .9, .1), 4)\n\nggplot(plot_df, aes(x = range, y = null_distribution)) +\n  geom_line() +\n  xlab(\"t-values\") +\n  ylab(\"Probability\") +\n  geom_vline(xintercept = t_ps) +\n  theme_classic(base_size = 15) +\n  theme(axis.text.y = element_blank(), axis.ticks = element_blank()) +\n  scale_x_continuous(breaks = round(t_ps, digits = 1)) +\n  geom_label(data = data.frame(x = -2.5, y = .2, label = \"10%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = -1.3, y = .2, label = \"10%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = 2.5, y = .2, label = \"10%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = 1.3, y = .2, label = \"10%\"), aes(x = x, y = y, label = label))\n\n\n\n\n\n\n\nFigure 6: Splitting the t distribution up into regions each containing 10% of the \\(t\\)-values. The width between the bars narrows as they approach the center of the distribution, where there are more \\(t\\)-values.\n\n\n\n\n\nConsider the probabilities (\\(p\\)) of \\(t\\) for the different ranges.\n\n\\(t\\) &lt;= -1.5 (\\(t\\) is less than or equal to -1.5), \\(p\\) = 10%\n-1.5 &gt;= \\(t\\) &lt;= -0.9 (\\(t\\) is equal to or between -1.5 and -.9), \\(p\\) = 10%\n-.9 &gt;= \\(t\\) &lt;= -0.6 (\\(t\\) is equal to or between -.9 and -.6), \\(p\\) = 10%\n\\(t\\) &gt;= 1.5 (\\(t\\) is greater than or equal to 1.5), \\(p\\) = 10%\n\nNotice, that the \\(p\\)s are always 10%. \\(t\\)s occur in these ranges with 10% probability.\n\n\n\nYou might be wondering where I am getting some of these values from. For example, how do I know that 10% of \\(t\\) values (for this null distribution) have a value of approximately 1.5 or greater than 1.5? The answer is I used R to tell me.\nIn most statistics textbooks the answer would be: there is a table at the back of the book where you can look these things up…This textbook has no such table. We could make one for you. And, we might do that. But, we didn’t do that yet…\nSo, where do these values come from, how can you figure out what they are? The complicated answer is that we are not going to explain the math behind finding these values because, 1) the authors (some of us) admittedly don’t know the math well enough to explain it, and 2) it would sidetrack us to much, 3) you will learn how to get these numbers in the lab with software, 4) you will learn how to get these numbers in lab without the math, just by doing a simulation, and 5) you can do it in R, or excel, or you can use an online calculator.\nThis is all to say that you can find the \\(t\\)s and their associated \\(p\\)s using software. But, the software won’t tell you what these values mean. That’s we are doing here. You will also see that software wants to know a few more things from you, such as the degrees of freedom for the test, and whether the test is one-tailed or two tailed. We haven’t explained any of these things yet. That’s what we are going to do now. Note, we explain degrees of freedom last. First, we start with a one-tailed test.\n\n\n\nA one-tailed test is sometimes also called a directional test. It is called a directional test, because a researcher might have a hypothesis in mind suggesting that the difference they observe in their means is going to have a particular direction, either a positive difference, or a negative difference.\nTypically, a researcher would set an alpha criterion. The alpha criterion describes a line in the sand for the researcher. Often, the alpha criterion is set at \\(p = .05\\). What does this mean? Figure 7 shows the \\(t\\)-distribution and the alpha criterion.\n\nrange &lt;- seq(-3, 3, .1)\nnull_distribution &lt;- dt(range, 4, log = FALSE)\nplot_df &lt;- data.frame(range, null_distribution)\n\nt_ps &lt;- qt(seq(.1, .9, .1), 4)\n\nggplot(plot_df, aes(x = range, y = null_distribution)) +\n  geom_line() +\n  xlab(\"t-values\") +\n  ylab(\"Probability\") +\n  geom_vline(xintercept = qt(.95, 4, lower.tail = TRUE)) +\n  ggtitle(\"Critical t for one-tailed test\") +\n  theme_classic(base_size = 10) +\n  theme(axis.text.y = element_blank(), axis.ticks = element_blank()) +\n  annotate(\n    \"rect\",\n    xmin = qt(.95, 4, lower.tail = TRUE),\n    xmax = 3,\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.5,\n    fill = \"green\"\n  ) +\n  geom_label(data = data.frame(x = 2.5, y = .2, label = \"5%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.95, 4, lower.tail = TRUE),\n    y = .3,\n    label = \"Critical t\"\n  ),\n  aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.95, 4, lower.tail = TRUE),\n    y = .25,\n    label = round(qt(.95, 4, lower.tail = TRUE), digits =\n                    2)\n  ),\n  aes(x = x, y = y, label = label))\n\n\n\n\n\n\n\nFigure 7: The critical value of t for an alpha criterion of 0.05. 5% of all ts are at this value or larger\n\n\n\n\n\nThe figure shows that \\(t\\) values of +2.13 or greater occur 5% of the time. Because the t-distribution is symmetrical, we also know that \\(t\\) values of -2.13 or smaller also occur 5% of the time. Both of these properties are true under the null distribution of no differences. This means, that when there really are no differences, a researcher can expect to find \\(t\\) values of 2.13 or larger 5% of the time.\nLet’s review and connect some of the terms:\n\nalpha criterion: the criterion set by the researcher to make decisions about whether they believe chance did or did not cause the difference. The alpha criterion here is set to \\(p = .05\\).\nCritical \\(t\\). The critical \\(t\\) is the \\(t\\)-value associated with the alpha-criterion. In this case for a one-tailed test, it is the \\(t\\) value where 5% of all \\(t\\)s are this number or greater. In our example, the critical \\(t\\) is 2.13. 5% of all \\(t\\) values (with degrees of freedom = 4) are +2.13, or greater than +2.13.\nObserved \\(t\\). The observed \\(t\\) is the one that you calculated from your sample. In our example about the infants, the observed \\(t\\) was \\(t\\) (4) = 0.72.\np-value. The \\(p\\)-value is the probability of obtaining the observed \\(t\\) value or larger. Now, you could look back at our previous example, and find that the \\(p\\)-value for \\(t\\) (4) = .72, was \\(p = .509\\) . HOWEVER, this p-value was not calculated for a one-directional test…(we talk about what .509 means in the next section).\n\nFigure 8 shows what the \\(p\\)-value for \\(t\\) (4) = .72 using a one-directional test would would look like:\n\nrange &lt;- seq(-3, 3, .1)\nnull_distribution &lt;- dt(range, 4, log = FALSE)\nplot_df &lt;- data.frame(range, null_distribution)\n\nt_ps &lt;- qt(seq(.1, .9, .1), 4)\n\nggplot(plot_df, aes(x = range, y = null_distribution)) +\n  geom_line() +\n  xlab(\"t-values\") +\n  ylab(\"Probability\") +\n  geom_vline(xintercept = .72) +\n  geom_vline(xintercept = qt(.95, 4, lower.tail = TRUE)) +\n  ggtitle(\"t value and p-range for one-directional test\") +\n  theme_classic(base_size = 10) +\n  theme(axis.text.y = element_blank(), axis.ticks = element_blank()) +\n  annotate(\n    \"rect\",\n    xmin = .72,\n    xmax = 3,\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.5,\n    fill = \"grey\"\n  ) +\n  annotate(\n    \"rect\",\n    xmin = qt(.95, 4, lower.tail = TRUE),\n    xmax = 3,\n    ymin = 0,\n    ymax = .25,\n    alpha = 0.5,\n    fill = \"green\"\n  ) +\n  geom_label(data = data.frame(x = 2.5, y = .2, label = \"5%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.95, 4, lower.tail = TRUE),\n    y = .3,\n    label = \"Critical t\"\n  ),\n  aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.95, 4, lower.tail = TRUE),\n    y = .25,\n    label = round(qt(.95, 4, lower.tail = TRUE), digits =\n                    2)\n  ),\n  aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = .72, y = .1,\n                               label = \"Observed t\"),\n             aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = .72, y = .05,\n                               label = \".72, p=\"),\n             aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = 1.5,\n    y = .05,\n    label = round(pt(.72, 4, lower.tail = FALSE), digits =\n                    3)\n  ),\n  aes(x = x, y = y, label = label))\n\n\n\n\n\n\n\nFigure 8: A case where the observed value of t is much less than the critical value for a one-directional t-test.\n\n\n\n\n\nLet’s take this one step at a time. We have located the observed \\(t\\) of .72 on the graph. We shaded the right region all grey. What we see is that the grey region represents .256 or 25.6% of all \\(t\\) values. In other words, 25.6% of \\(t\\) values are .72 or larger than .72. You could expect, by chance alone, to a find a \\(t\\) value of .72 or larger, 25.6% of the time. That’s fairly often. We did find a \\(t\\) value of .72. Now that you know this kind of \\(t\\) value or larger occurs 25.6% of the time, would you be confident that the mean difference was not due to chance? Probably not, given that chance can produce this difference fairly often.\nFollowing the “standard” decision making procedure, we would claim that our \\(t\\) value was not statistically significant, because it was not large enough. If our observed value was larger than the critical \\(t\\) (larger than 2.13), defined by our alpha criterion, then we would claim that our \\(t\\) value was statistically significant. This would be equivalent to saying that we believe it is unlikely that the difference we observed was due to chance. In general, for any observed \\(t\\) value, the associated \\(p\\)-value tells you how likely a \\(t\\) of the observed size or larger would be observed. The \\(p\\)-value always refers to a range of \\(t\\)-values, never to a single \\(t\\)-value. Researchers use the alpha criterion of .05, as a matter of convenience and convention. There are other ways to interpret these values that do not rely on a strict (significant versus not) dichotomy.\n\n\n\nOK, so that was one-tailed tests… What are two tailed tests? The \\(p\\)-value that we originally calculated from our paired-samples \\(t\\)-test was for a 2-tailed test. Often, the default is that the \\(p\\)-value is for a two-tailed test.\nThe two-tailed test, is asking a more general question about whether a difference is likely to have been produced by chance. The question is: what is probability of any difference. It is also called a non-directional test, because here we don’t care about the direction or sign of the difference (positive or negative), we just care if there is any kind of difference.\nThe same basic things as before are involved. We define an alpha criterion (\\(\\alpha = 0.05\\)). And, we say that any observed \\(t\\) value that has a probability of \\(p\\) &lt;.05 (\\(p\\) is less than .05) will be called statistically significant, and ones that are more likely (\\(p\\) &gt;.05, \\(p\\) is greater than .05) will be called null-results, or not statistically significant. The only difference is how we draw the alpha range. Before it was on the right side of the \\(t\\) distribution (we were conducting a one-sided test remember, so we were only interested in one side).\nFigure 9 shows what the most extreme 5% of the \\(t\\)-values are when we ignore their sign (whether they are positive or negative).\n\nrange &lt;- seq(-4, 4, .1)\nnull_distribution &lt;- dt(range, 4, log = FALSE)\nplot_df &lt;- data.frame(range, null_distribution)\n\nt_ps &lt;- qt(seq(.1, .9, .1), 4)\n\nggplot(plot_df, aes(x = range, y = null_distribution)) +\n  geom_line() +\n  xlab(\"t-values\") +\n  ylab(\"Probability\") +\n  geom_vline(xintercept = qt(.975, 4, lower.tail = TRUE)) +\n  geom_vline(xintercept = qt(.025, 4, lower.tail = TRUE)) +\n  ggtitle(\"Critical ts for two-tailed test\") +\n  theme_classic(base_size = 10) +\n  theme(axis.text.y = element_blank(), axis.ticks = element_blank()) +\n  annotate(\n    \"rect\",\n    xmin = qt(.975, 4, lower.tail = TRUE),\n    xmax = 4,\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.5,\n    fill = \"green\"\n  ) +\n  geom_label(data = data.frame(x = 3.5, y = .2, label = \"2.5%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.975, 4, lower.tail = TRUE),\n    y = .3,\n    label = \"Critical t\"\n  ),\n  aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.975, 4, lower.tail = TRUE),\n    y = .25,\n    label = round(qt(.975, 4, lower.tail = TRUE), digits =\n                    2)\n  ),\n  aes(x = x, y = y, label = label)) +\n  annotate(\n    \"rect\",\n    xmin = -4,\n    xmax = qt(.025, 4, lower.tail = TRUE),\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.5,\n    fill = \"green\"\n  ) +\n  geom_label(data = data.frame(x = -3.5, y = .2, label = \"2.5%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.025, 4, lower.tail = TRUE),\n    y = .3,\n    label = \"Critical t\"\n  ),\n  aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.025, 4, lower.tail = TRUE),\n    y = .25,\n    label = round(qt(.025, 4, lower.tail = TRUE), digits =\n                    2)\n  ),\n  aes(x = x, y = y, label = label))\n\n\n\n\n\n\n\nFigure 9: Critical values for a two-tailed test. Each line represents the location where 2.5% of all \\(t\\)s are larger or smaller than critical value. The total for both tails is 5%\n\n\n\n\n\nHere is what we are seeing. A distribution of no differences (the null, which is what we are looking at), will produce \\(t\\)s that are 2.78 or greater 2.5% of the time, and \\(t\\)s that are -2.78 or smaller 2.5% of the time. 2.5% + 2.5% is a total of 5% of the time. We could also say that \\(t\\)s larger than +/- 2.78 occur 5% of the time.\nAs a result, the critical \\(t\\) value is (+/-) 2.78 for a two-tailed test. As you can see, the two-tailed test is blind to the direction or sign of the difference. Because of this, the critical \\(t\\) value is also higher for a two-tailed test, than for the one-tailed test that we did earlier. Hopefully, now you can see why it is called a two-tailed test. There are two tails of the distribution, one on the left and right, both shaded in green.\n\n\n\nNow that you know there are two kinds of tests, one-tailed, and two-tailed, which one should you use? There is some conventional wisdom on this, but also some debate. In the end, it is up to you to be able to justify your choice and why it is appropriate for you data. That is the real answer.\nThe conventional answer is that you use a one-tailed test when you have a theory or hypothesis that is making a directional prediction (the theory predicts that the difference will be positive, or negative). Similarly, use a two-tailed test when you are looking for any difference, and you don’t have a theory that makes a directional prediction (it just makes the prediction that there will be a difference, either positive or negative).\nAlso, people appear to choose one or two-tailed tests based on how risky they are as researchers. If you always ran one-tailed tests, your critical \\(t\\) values for your set alpha criterion would always be smaller than the critical \\(t\\)s for a two-tailed test. Over the long run, you would make more type I errors, because the criterion to detect an effect is a lower bar for one than two tailed tests.\n\nRemember type 1 errors occur when you reject the idea that chance could have caused your difference. You often never know when you make this error. It happens anytime that sampling error was the actual cause of the difference, but a researcher dismisses that possibility and concludes that their manipulation caused the difference.\n\nSimilarly, if you always ran two-tailed tests, even when you had a directional prediction, you would make fewer type I errors over the long run, because the \\(t\\) for a two-tailed test is higher than the \\(t\\) for a one-tailed test. It seems quite common for researchers to use a more conservative two-tailed test, even when they are making a directional prediction based on theory. In practice, researchers tend to adopt a standard for reporting that is common in their field. Whether or not the practice is justifiable can sometimes be an open question. The important task for any researcher, or student learning statistics, is to be able to justify their choice of test.\n\n\n\nBefore we finish up with paired-samples \\(t\\)-tests, we should talk about degrees of freedom. Our sense is that students don’t really understand degrees of freedom very well. If you are reading this textbook, you are probably still wondering what is degrees of freedom, seeing as we haven’t really talked about it all.\nFor the \\(t\\)-test, there is a formula for degrees of freedom. For the one-sample and paired sample \\(t\\)-tests, the formula is:\n\\(\\text{Degrees of Freedom} = \\text{df} = n-1\\). Where n is the number of samples in the test.\nIn our paired \\(t\\)-test example, there were 5 infants. Therefore, degrees of freedom = 5-1 = 4.\nOK, that’s a formula. Who cares about degrees of freedom, what does the number mean? And why do we report it when we report a \\(t\\)-test… you’ve probably noticed the number in parentheses e.g., \\(t\\)(4)=.72, the 4 is the \\(df\\), or degrees of freedom.\nDegrees of freedom is both a concept, and a correction. The concept is that if you estimate a property of the numbers, and you use this estimate, you will be forcing some constraints on your numbers.\nConsider the numbers: 1, 2, 3. The mean of these numbers is 2. Now, let’s say I told you that the mean of three numbers is 2. Then, how many of these three numbers have freedom? Funny question right. What we mean is, how many of the three numbers could be any number, or have the freedom to be any number.\nThe first two numbers could be any number. But, once those two numbers are set, the final number (the third number), MUST be a particular number that makes the mean 2. The first two numbers have freedom. The third number has no freedom.\nTo illustrate. Let’s freely pick two numbers: 51 and -3. I used my personal freedom to pick those two numbers. Now, if our three numbers are 51, -3, and x, and the mean of these three numbers is 2. There is only one solution, x has to be -42, otherwise the mean won’t be 2. This is one way to think about degrees of freedom. The degrees of freedom for these three numbers is n-1 = 3-1= 2, because 2 of the numbers can be free, but the last number has no freedom, it becomes fixed after the first two are decided.\nNow, statisticians often apply degrees of freedom to their calculations, especially when a second calculation relies on an estimated value. For example, when we calculate the standard deviation of a sample, we first calculate the mean of the sample right! By estimating the mean, we are fixing an aspect of our sample, and so, our sample now has n-1 degrees of freedom when we calculate the standard deviation (remember for the sample standard deviation, we divide by n-1…there’s that n-1 again.)\n\n\nThere are at least two ways to think the degrees of freedom for a \\(t\\)-test. For example, if you want to use math to compute aspects of the \\(t\\) distribution, then you need the degrees of freedom to plug in to the formula… If you want to see the formulas I’m talking about, scroll down on the \\(t\\)-test wikipedia page and look for the probability density or cumulative distribution functions…We think that is quite scary for most people, and one reason why degrees of freedom are not well-understood.\nIf we wanted to simulate the \\(t\\) distribution we could more easily see what influence degrees of freedom has on the shape of the distribution. Remember, \\(t\\) is a sample statistic, it is something we measure from the sample. So, we could simulate the process of measuring \\(t\\) from many different samples, then plot the histogram of \\(t\\) to show us the simulated \\(t\\) distribution.\n\nts &lt;- c(rt(10000, 4), rt(10000, 100))\ndfs &lt;- as.factor(rep(c(4, 100), each = 10000))\n\nt_df &lt;- data.frame(dfs, ts)\nt_df &lt;- t_df[abs(t_df$ts) &lt; 5, ]\n\nggplot(t_df, aes(x = ts, group = dfs, color = dfs)) +\n  geom_histogram() +\n  theme_classic() +\n  facet_wrap( ~ dfs) +\n  theme_classic(base_size=15)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nFigure 10: The width of the t distribution shrinks as sample size and degrees of freedom (from 4 to 100) increases.\n\n\n\n\n\nIn Figure 10 notice that the red distribution for \\(df = 4\\), is a little bit shorter, and a little bit wider than the bluey-green distribution for \\(df = 100\\). As degrees of freedom increase the \\(t\\) distribution gets taller (in the middle), and narrower in the range. It get’s more peaky. Can you guess the reason for this? Remember, we are estimating a sample statistic, and degrees of freedom is really just a number that refers to the number of subjects (well minus one). And, we already know that as we increase \\(n\\), our sample statistics become better estimates (less variance) of the distributional parameters they are estimating. So, \\(t\\) becomes a better estimate of it’s “true” value as sample size increase, resulting in a more narrow distribution of \\(t\\)s.\nThere is a slightly different \\(t\\) distribution for every degrees of freedom, and the critical regions associated with 5% of the extreme values are thus slightly different every time. This is why we report the degrees of freedom for each t-test, they define the distribution of \\(t\\) values for the sample-size in question. Why do we use n-1 and not n? Well, we calculate \\(t\\) using the sample standard deviation to estimate the standard error or the mean, that estimate uses n-1 in the denominator, so our \\(t\\) distribution is built assuming n-1. That’s enough for degrees of freedom…",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "06-ttests"
    ]
  },
  {
    "objectID": "week01/06-ttests.html#the-paired-samples-t-test-strikes-back",
    "href": "week01/06-ttests.html#the-paired-samples-t-test-strikes-back",
    "title": "06-ttests",
    "section": "",
    "text": "You must be wondering if we will ever be finished talking about paired samples t-tests… why are we doing round 2, oh no! Don’t worry, we’re just going to 1) remind you about what we were doing with the infant study, and 2) do a paired samples t-test on the entire data set and discuss.\nRemember, we were wondering if the infants would look longer toward the singer who sang the familiar song during the test phase compared to the baseline phase. We showed you data from 5 infants, and walked through the computations for the \\(t\\)-test. As a reminder, it looked like this:\n\n\n\n\n\n\n\n\n\n\n\n\n\ninfant\nBaseline\nTest\ndifferences\ndiff_from_mean\nSquared_differences\n\n\n\n\n1\n0.44\n0.6\n0.16\n0.106\n0.011236\n\n\n2\n0.41\n0.68\n0.27\n0.216\n0.046656\n\n\n3\n0.75\n0.72\n-0.03\n-0.084\n0.00705600000000001\n\n\n4\n0.44\n0.28\n-0.16\n-0.214\n0.045796\n\n\n5\n0.47\n0.5\n0.03\n-0.024\n0.000575999999999999\n\n\nSums\n2.51\n2.78\n0.27\n0\n0.11132\n\n\nMeans\n0.502\n0.556\n0.054\n0\n0.022264\n\n\n\n\n\n\nsd\n0.167\n\n\n\n\n\n\nSEM\n0.075\n\n\n\n\n\n\nt\n0.72\n\n\n\n\n\n\n    One Sample t-test\n\ndata:  round(differences, digits = 2)\nt = 0.72381, df = 4, p-value = 0.5092\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -0.1531384  0.2611384\nsample estimates:\nmean of x \n    0.054 \n\n\nLet’s write down the finding one more time: The mean difference was 0.054, \\(t\\)(4) = .72, \\(p\\) =.509. We can also now confirm, that the \\(p\\)-value was from a two-tailed test. So, what does this all really mean.\nWe can say that a \\(t\\) value with an absolute of .72 or larger occurs 50.9% of the time. More precisely, the distribution of no differences (the null), will produce a \\(t\\) value this large or larger 50.9% of the time. In other words, chance alone good have easily produced the \\(t\\) value from our sample, and the mean difference we observed or .054, could easily have been a result of chance.\nLet’s quickly put all of the data in the \\(t\\)-test, and re-run the test using all of the infant subjects.\n\npaired_sample_df &lt;-  data.frame(infant=1:32, \n                               Baseline = round(experiment_one$Baseline_Proportion_Gaze_to_Singer[1:32],digits=2), \n                               Test = round(experiment_one$Test_Proportion_Gaze_to_Singer[1:32], digits=2))\n\ndifferences &lt;-  paired_sample_df$Test-paired_sample_df$Baseline\nt.test(differences,mu=0)\n\n\n    One Sample t-test\n\ndata:  differences\nt = 2.4388, df = 31, p-value = 0.02066\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 0.01192088 0.13370412\nsample estimates:\nmean of x \n0.0728125 \n\n\nNow we get a very different answer. We would summarize the results saying the mean difference was .073, t(31) = 2.44, p = 0.020. How many total infants were their? Well the degrees of freedom was 31, so there must have been 32 infants in the study. Now we see a much smaller \\(p\\)-value. This was also a two-tailed test, so we that observing a \\(t\\) value of 2.4 or greater (absolute value) only occurs 2% of the time. In other words, the distribution of no differences will produce the observed t-value very rarely. So, it is unlikely that the observed mean difference of .073 was due to chance (it could have been due to chance, but that is very unlikely). As a result, we can be somewhat confident in concluding that something about seeing and hearing a unfamiliar person sing a familiar song, causes an infant to draw their attention toward the singer, and this potentially benefits social learning on the part of the infant.",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "06-ttests"
    ]
  },
  {
    "objectID": "week01/06-ttests.html#independent-samples-t-test-the-return-of-the-t-test",
    "href": "week01/06-ttests.html#independent-samples-t-test-the-return-of-the-t-test",
    "title": "06-ttests",
    "section": "",
    "text": "If you’ve been following the Star Wars references, we are on last movie (of the original trilogy)… the independent t-test. This is were basically the same story plays out as before, only slightly different.\nRemember there are different \\(t\\)-tests for different kinds of research designs. When your design is a between-subjects design, you use an independent samples t-test. Between-subjects design involve different people or subjects in each experimental condition. If there are two conditions, and 10 people in each, then there are 20 total people. And, there are no paired scores, because every single person is measured once, not twice, no repeated measures. Because there are no repeated measures we can’t look at the difference scores between conditions one and two. The scores are not paired in any meaningful way, to it doesn’t make sense to subtract them. So what do we do?\nThe logic of the independent samples t-test is the very same as the other \\(t\\)-tests. We calculated the means for each group, then we find the difference. That goes into the numerator of the t formula. Then we get an estimate of the variation for the denominator. We divide the mean difference by the estimate of the variation, and we get \\(t\\). It’s the same as before.\nThe only wrinkle here is what goes into the denominator? How should we calculate the estimate of the variance? It would be nice if we could do something very straightforward like this, say for an experiment with two groups A and B:\n\\(t = \\frac{\\bar{A}-\\bar{B}}{(\\frac{SEM_A+SEM_B}{2})}\\)\nIn plain language, this is just:\n\nFind the mean difference for the top part\nCompute the SEM (standard error of the mean) for each group, and average them together to make a single estimate, pooling over both samples.\n\nThis would be nice, but unfortunately, it turns out that finding the average of two standard errors of the mean is not the best way to do it. This would create a biased estimator of the variation for the hypothesized distribution of no differences. We won’t go into the math here, but instead of the above formula, we an use a different one that gives as an unbiased estimate of the pooled standard error of the sample mean. Our new and improved \\(t\\) formula would look like this:\n\\(t = \\frac{\\bar{X_A}-\\bar{X_B}}{s_p * \\sqrt{\\frac{1}{n_A} + \\frac{1}{n_B}}}\\)\nand, \\(s_p\\), which is the pooled sample standard deviation is defined as, note the $s$es in the formula are variances:\n\\(s_p = \\sqrt{\\frac{(n_A-1)s_A^2 + (n_B-1)s^2_B}{n_A +n_B -2}}\\)\nBelieve you me, that is so much more formula than I wanted to type out. Shall we do one independent \\(t\\)-test example by hand, just to see the computations? Let’s do it…but in a slightly different way than you expect. I show the steps using R. I made some fake scores for groups A and B. Then, I followed all of the steps from the formula, but made R do each of the calculations. This shows you the needed steps by following the code. At the end, I print the \\(t\\)-test values I computed “by hand”, and then the \\(t\\)-test value that the R software outputs using the \\(t\\)-test function. You should be able to get the same values for \\(t\\), if you were brave enough to compute \\(t\\) by hand.\n\n## By \"hand\" using R r code\na &lt;- c(1,2,3,4,5)\nb &lt;- c(3,5,4,7,9)\n\nmean_difference &lt;- mean(a)-mean(b) # compute mean difference\n\nvariance_a &lt;- var(a) # compute variance for A\nvariance_b &lt;- var(b) # compute variance for B\n\n# Compute top part and bottom part of sp formula\n\nsp_numerator &lt;- (4*variance_a + 4* variance_b) \nsp_denominator &lt;- 5+5-2\nsp &lt;- sqrt(sp_numerator/sp_denominator) # compute sp\n\n\n# compute t following formulat\n\nt &lt;- mean_difference / ( sp * sqrt( (1/5) +(1/5) ) )\n\nt # print results\n\n[1] -2.017991\n\n# using the R function t.test\nt.test(a,b, paired=FALSE, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  a and b\nt = -2.018, df = 8, p-value = 0.0783\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -5.5710785  0.3710785\nsample estimates:\nmean of x mean of y \n      3.0       5.6",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "06-ttests"
    ]
  },
  {
    "objectID": "week01/06-ttests.html#simulating-data-for-t-tests",
    "href": "week01/06-ttests.html#simulating-data-for-t-tests",
    "title": "06-ttests",
    "section": "",
    "text": "An “advanced” topic for \\(t\\)-tests is the idea of using R to conduct simulations for \\(t\\)-tests.\nIf you recall, \\(t\\) is a property of a sample. We calculate \\(t\\) from our sample. The \\(t\\) distribution is the hypothetical behavior of our sample. That is, if we had taken thousands upon thousands of samples, and calculated \\(t\\) for each one, and then looked at the distribution of those \\(t\\)’s, we would have the sampling distribution of \\(t\\)!\nIt can be very useful to get in the habit of using R to simulate data under certain conditions, to see how your sample data, and things like \\(t\\) behave. Why is this useful? It mainly prepares you with some intuitions about how sampling error (random chance) can influence your results, given specific parameters of your design, such as sample-size, the size of the mean difference you expect to find in your data, and the amount of variation you might find. These methods can be used formally to conduct power-analyses. Or more informally for data sense.\n\n\nHere are the steps you might follow to simulate data for a one sample \\(t\\)-test.\n\nMake some assumptions about what your sample (that you might be planning to collect) might look like. For example, you might be planning to collect 30 subjects worth of data. The scores of those data points might come from a normal distribution (mean = 50, sd = 10).\nsample simulated numbers from the distribution, then conduct a \\(t\\)-test on the simulated numbers. Save the statistics you want (such as \\(t\\)s and \\(p\\)s), and then see how things behave.\n\nLet’s do this a couple different times. First, let’s simulate samples with N = 30, taken from a normal (mean= 50, sd = 25). We’ll do a simulation with 1000 simulations. For each simulation, we will compare the sample mean with a population mean of 50. There should be no difference on average here. Figure 11 is the null distribution that we are simulating.\n\n# steps to create fake data from a distribution\n# and conduct t-tests on the simulated data\nsave_ps &lt;- length(1000)\nsave_ts &lt;- length(1000)\nfor (i in 1:1000) {\n  my_sample &lt;- rnorm(n = 30, mean = 50, sd = 25)\n  t_test &lt;- t.test (my_sample, mu = 50)\n  save_ps[i] &lt;- t_test$p.value\n  save_ts[i] &lt;- t_test$statistic\n}\n\n\n#plot histograms of t and p values for 1000 simulations\nhist(save_ts)\n\n\n\n\n\n\n\nFigure 11: The distribution of \\(t\\)-values under the null. These are the \\(t\\) values that are produced by chance alone.\n\n\n\n\n\n\nhist(save_ps)\n\n\n\n\n\n\n\nFigure 12: The distribution of \\(p\\)-values that are observed is flat under the null.\n\n\n\n\n\nNeat. We see both a \\(t\\) distribution, that looks like \\(t\\) distribution as it should. And we see the \\(p\\) distribution. This shows us how often we get \\(t\\) values of particular sizes. You may find it interesting that the \\(p\\)-distribution is flat under the null, which we are simulating here. This means that you have the same chances of a getting a \\(t\\) with a p-value between 0 and 0.05, as you would for getting a \\(t\\) with a p-value between .90 and .95. Those ranges are both ranges of 5%, so there are an equal amount of \\(t\\) values in them by definition.\nHere’s another way to do the same simulation in R, using the replicate function, instead a for loop:\n\nsimulated_ts &lt;- replicate(1000,\n                          t.test(rnorm(30, 50, 25), mu = 50)$statistic)\nhist(simulated_ts)\n\n\n\n\n\n\n\nFigure 13: Simulating \\(t\\)s in R.\n\n\n\n\n\n\nsimulated_ps &lt;- replicate(1000,\n                          t.test(rnorm(30, 50, 25), mu = 50)$p.value)\nhist(simulated_ps)\n\n\n\n\n\n\n\nFigure 14: Simulating \\(p\\)s in R.\n\n\n\n\n\n\n\n\nThe code below is set up to sample 10 scores for condition A and B from the same normal distribution. The simulation is conducted 1000 times, and the \\(t\\)s and \\(p\\)s are saved and plotted for each.\n\nsave_ps &lt;- length(1000)\nsave_ts &lt;- length(1000)\nfor ( i in 1:1000 ){\n  condition_A &lt;- rnorm(10,10,5)\n  condition_B &lt;- rnorm(10,10,5)\n  differences &lt;- condition_A - condition_B\n  t_test &lt;- t.test(differences, mu=0)\n  save_ps[i] &lt;- t_test$p.value\n  save_ts[i] &lt;- t_test$statistic\n}\n\n\nhist(save_ts)\n\n\n\n\n\n\n\nFigure 15: 1000 simulated ts from the null distribution\n\n\n\n\n\n\nhist(save_ps)\n\n\n\n\n\n\n\nFigure 16: 1000 simulated ps from the null distribution\n\n\n\n\n\nAccording to the simulation. When there are no differences between the conditions, and the samples are being pulled from the very same distribution, you get these two distributions for \\(t\\) and \\(p\\). These again show how the null distribution of no differences behaves.\nFor any of these simulations, if you rejected the null-hypothesis (that your difference was only due to chance), you would be making a type I error. If you set your alpha criteria to \\(\\alpha = .05\\), we can ask how many type I errors were made in these 1000 simulations. The answer is:\n\nlength(save_ps[save_ps&lt;.05])\n\n[1] 53\n\nlength(save_ps[save_ps&lt;.05])/1000\n\n[1] 0.053\n\n\nWe happened to make 53. The expectation over the long run is 5% type I error rates (if your alpha is .05).\nWhat happens if there actually is a difference in the simulated data, let’s set one condition to have a larger mean than the other:\n\nsave_ps &lt;- length(1000)\nsave_ts &lt;- length(1000)\nfor ( i in 1:1000 ){\n  condition_A &lt;- rnorm(10,10,5)\n  condition_B &lt;- rnorm(10,13,5)\n  differences &lt;- condition_A - condition_B\n  t_test &lt;- t.test(differences, mu=0)\n  save_ps[i] &lt;- t_test$p.value\n  save_ts[i] &lt;- t_test$statistic\n}\n\n\nhist(save_ts)\n\n\n\n\n\n\n\nFigure 17: 1000 ts when there is a true difference\n\n\n\n\n\n\nhist(save_ps)\n\n\n\n\n\n\n\nFigure 18: 1000 ps when there is a true difference\n\n\n\n\n\nNow you can see that the \\(p\\)-value distribution is skewed to the left. This is because when there is a true effect, you will get p-values that are less than .05 more often. Or, rather, you get larger \\(t\\) values than you normally would if there were no differences.\nIn this case, we wouldn’t be making a type I error if we rejected the null when p was smaller than .05. How many times would we do that out of our 1000 experiments?\n\nlength(save_ps[save_ps&lt;.05])\n\n[1] 205\n\nlength(save_ps[save_ps&lt;.05])/1000\n\n[1] 0.205\n\n\nWe happened to get 205 simulations where p was less than .05, that’s only 0.205 experiments. If you were the researcher, would you want to run an experiment that would be successful only 0.205 of the time? I wouldn’t. I would run a better experiment.\nHow would you run a better simulated experiment? Well, you could increase \\(n\\), the number of subjects in the experiment. Let’s increase \\(n\\) from 10 to 100, and see what happens to the number of “significant” simulated experiments.\n\nsave_ps &lt;- length(1000)\nsave_ts &lt;- length(1000)\nfor ( i in 1:1000 ){\n  condition_A &lt;- rnorm(100,10,5)\n  condition_B &lt;- rnorm(100,13,5)\n  differences &lt;- condition_A - condition_B\n  t_test &lt;- t.test(differences, mu=0)\n  save_ps[i] &lt;- t_test$p.value\n  save_ts[i] &lt;- t_test$statistic\n}\n\n\nhist(save_ts)\n\n\n\n\n\n\n\nFigure 19: 1000 ts for n =100, when there is a true effect\n\n\n\n\n\n\nhist(save_ps)\n\n\nlength(save_ps[save_ps&lt;.05])\n\n[1] 988\n\nlength(save_ps[save_ps&lt;.05])/1000\n\n[1] 0.988\n\n\n\n\n\n\n\n\nFigure 20: 1000 ps for n =100, when there is a true effect\n\n\n\n\n\nCool, now almost all of the experiments show a \\(p\\)-value of less than .05 (using a two-tailed test, that’s the default in R). See, you could use this simulation process to determine how many subjects you need to reliably find your effect.\n\n\n\nJust change the t.test function like so… this is for the null, assuming no difference between groups.\n\nsave_ps &lt;- length(1000)\nsave_ts &lt;- length(1000)\nfor ( i in 1:1000 ){\n  group_A &lt;- rnorm(10,10,5)\n  group_B &lt;- rnorm(10,10,5)\n  t_test &lt;- t.test(group_A, group_B, paired=FALSE, var.equal=TRUE)\n  save_ps[i] &lt;- t_test$p.value\n  save_ts[i] &lt;- t_test$statistic\n}\n\n\nhist(save_ts)\n\n\n\n\n\n\n\nFigure 21: 1000 ts for n =100, when there is a true effect\n\n\n\n\n\n\nhist(save_ps)\n\n\nlength(save_ps[save_ps&lt;.05])\n\n[1] 43\n\nlength(save_ps[save_ps&lt;.05])/1000\n\n[1] 0.043\n\n\n\n\n\n\n\n\nFigure 22: 1000 ps for n =100, when there is a true effect",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "06-ttests"
    ]
  },
  {
    "objectID": "week01/chapter.html",
    "href": "week01/chapter.html",
    "title": "T-Tests",
    "section": "",
    "text": "::: Content below origially written by Matthew Crump under a CC-BY-NC-SA Licence. Original Content Chapter 6 of https://www.crumplab.com/statistics/06-ttests.html :::\nBack in the day, William Sealy Gosset got a job working for Guinness Breweries. They make the famous Irish stout called Guinness. What happens next went something like this (total fabrication, but mostly on point).\nGuinness wanted all of their beers to be the best beers. No mistakes, no bad beers. They wanted to improve their quality control so that when Guinness was poured anywhere in the world, it would always comes out fantastic: 5 stars out of 5 every time, the best.\nGuinness had some beer tasters, who were super-experts. Every time they tasted a Guinness from the factory that wasn’t 5 out of 5, they knew right away.\nBut, Guinness had a big problem. They would make a keg of beer, and they would want to know if every single pint that would come out would be a 5 out of 5. So, the beer tasters drank pint after pint out of the keg, until it was gone. Some kegs were all 5 out of 5s. Some weren’t, Guinness needed to fix that. But, the biggest problem was that, after the testing, there was no beer left to sell, the testers drank it all (remember I’m making this part up to illustrate a point, they probably still had beer left to sell).\nGuinness had a sampling and population problem. They wanted to know that the entire population of the beers they made were all 5 out of 5 stars. But, if they sampled the entire population, they would drink all of their beer, and wouldn’t have any left to sell.\nEnter William Sealy Gosset. Gosset figured out the solution to the problem. He asked questions like this:\n\nHow many samples do I need to take to know the whole population is 5 out of 5?\nWhat’s the fewest amount of samples I need to take to know the above, that would mean Guinness could test fewer beers for quality, sell more beers for profit, and make the product testing time shorter.\n\nGosset solved those questions, and he invented something called the Student’s t-test. Gosset was working for Guinness, and could be fired for releasing trade-secrets that he invented (the t-test). But, Gosset published the work anyways, under a pseudonym (Student1908?). He called himself Student, hence Student’s t-test. Now you know the rest of the story.\nIt turns out this was a very nice thing for Gosset to have done. t-tests are used all the time, and they are useful, that’s why they are used. In this chapter we learn how they work.\nYou’ll be surprised to learn that what we’ve already talked about, (the Crump Test, and the Randomization Test), are both very very similar to the t-test. So, in general, you have already been thinking about the things you need to think about to understand t-tests. You’re probably wondering what is this \\(t\\), what does \\(t\\) mean? We will tell you. Before we tell what it means, we first tell you about one more idea.\n\n\nWe’ve talked about getting a sample of data. We know we can find the mean, we know we can find the standard deviation. We know we can look at the data in a histogram. These are all useful things to do for us to learn something about the properties of our data.\nYou might be thinking of the mean and standard deviation as very different things that we would not put together. The mean is about central tendency (where most of the data is), and the standard deviation is about variance (where most of the data isn’t). Yes, they are different things, but we can use them together to create useful new things.\nWhat if I told you my sample mean was 50, and I told you nothing else about my sample. Would you be confident that most of the numbers were near 50? Would you wonder if there was a lot of variability in the sample, and many of the numbers were very different from 50. You should wonder all of those things. The mean alone, just by itself, doesn’t tell you anything about well the mean represents all of the numbers in the sample.\nIt could be a representative number, when the standard deviation is very small, and all the numbers are close to 50. It could be a non-representative number, when the standard deviation is large, and many of the numbers are not near 50. You need to know the standard deviation in order to be confident in how well the mean represents the data.\nHow can we put the mean and the standard deviation together, to give us a new number that tells us about confidence in the mean?\nWe can do this using a ratio:\n\\(\\frac{mean}{\\text{standard deviation}}\\)\nThink about what happens here. We are dividing a number by a number. Look at what happens:\n\\(\\frac{number}{\\text{same number}} = 1\\)\n\\(\\frac{number}{\\text{smaller number}} = \\text{big number}\\)\ncompared to:\n\\(\\frac{number}{\\text{bigger number}} = \\text{smaller number}\\)\nImagine we have a mean of 50, and a truly small standard deviation of 1. What do we get with our formula?\n\\(\\frac{50}{1} = 50\\)\nImagine we have a mean of 50, and a big standard deviation of 100. What do we get with our formula?\n\\(\\frac{50}{100} = 0.5\\)\nNotice, when we have a mean paired with a small standard deviation, our formula gives us a big number, like 50. When we have a mean paired with a large standard deviation, our formula gives us a small number, like 0.5. These numbers can tell us something about confidence in our mean, in a general way. We can be 50 confident in our mean in the first case, and only 0.5 (not at a lot) confident in the second case.\nWhat did we do here? We created a descriptive statistic by dividing the mean by the standard deviation. And, we have a sense of how to interpret this number, when it’s big we’re more confident that the mean represents all of the numbers, when it’s small we are less confident. This is a useful kind of number, a ratio between what we think about our sample (the mean), and the variability in our sample (the standard deviation). Get used to this idea. Almost everything that follows in this textbook is based on this kind of ratio. We will see that our ratio turns into different kinds of “statistics”, and the ratios will look like this in general:\n\\(\\text{name of statistic} = \\frac{\\text{measure of what we know}}{\\text{measure of what we don't know}}\\)\nor, to say it using different words:\n\\(\\text{name of statistic} = \\frac{\\text{measure of effect}}{\\text{measure of error}}\\)\nIn fact, this is the general formula for the t-test. Big surprise!\n\n\n\nNow we are ready to talk about t-test. We will talk about three of them. We start with the one-sample t-test.\nCommonly, the one-sample t-test is used to estimate the chances that your sample came from a particular population. Specifically, you might want to know whether the mean that you found from your sample, could have come from a particular population having a particular mean.\nStraight away, the one-sample t-test becomes a little confusing (and I haven’t even described it yet). Officially, it uses known parameters from the population, like the mean of the population and the standard deviation of the population. However, most times you don’t know those parameters of the population! So, you have to estimate them from your sample. Remember from the chapters on descriptive statistics and sampling, our sample mean is an unbiased estimate of the population mean. And, our sample standard deviation (the one where we divide by n-1) is an unbiased estimate of the population standard deviation. When Gosset developed the t-test, he recognized that he could use these estimates from his samples, to make the t-test. Here is the formula for the one sample t-test, we first use words, and then become more specific:\n\n\n\\(\\text{name of statistic} = \\frac{\\text{measure of effect}}{\\text{measure of error}}\\)\n\\(\\text{t} = \\frac{\\text{measure of effect}}{\\text{measure of error}}\\)\n\\(\\text{t} = \\frac{\\text{Mean difference}}{\\text{standard error}}\\)\n\\(\\text{t} = \\frac{\\bar{X}-u}{S_{\\bar{X}}}\\)\n\\(\\text{t} = \\frac{\\text{Sample Mean  - Population Mean}}{\\text{Sample Standard Error}}\\)\n\\(\\text{Estimated Standard Error} = \\text{Standard Error of Sample} = \\frac{s}{\\sqrt{N}}\\)\nWhere, s is the sample standard deviation.\nSome of you may have gone cross-eyed looking at all of this. Remember, we’ve seen it before when we divided our mean by the standard deviation in the first bit. The t-test is just a measure of a sample mean, divided by the standard error of the sample mean. That is it.\n\n\n\n\\(t\\) gives us a measure of confidence, just like our previous ratio for dividing the mean by a standard deviations. The only difference with \\(t\\), is that we divide by the standard error of mean (remember, this is also a standard deviation, it is the standard deviation of the sampling distribution of the mean)\n\n\n\n\n\n\nNote\n\n\n\nWhat does the t in t-test stand for? Apparently nothing. Gosset originally labelled it z. And, Fisher later called it t, perhaps because t comes after s, which is often used for the sample standard deviation.\n\n\n\\(t\\) is a property of the data that you collect. You compute it with a sample mean, and a sample standard error (there’s one more thing in the one-sample formula, the population mean, which we get to in a moment). This is why we call \\(t\\), a sample-statistic. It’s a statistic we compute from the sample.\nWhat kinds of numbers should we expect to find for these \\(ts\\)? How could we figure that out?\nLet’s start small and work through some examples. Imagine your sample mean is 5. You want to know if it came from a population that also has a mean of 5. In this case, what would \\(t\\) be? It would be zero: we first subtract the sample mean from the population mean, \\(5-5=0\\). Because the numerator is 0, \\(t\\) will be zero. So, \\(t\\) = 0, occurs, when there is no difference.\nLet’s say you take another sample, do you think the mean will be 5 every time, probably not. Let’s say the mean is 6. So, what can \\(t\\) be here? It will be a positive number, because 6-5= +1. But, will \\(t\\) be +1? That depends on the standard error of the sample. If the standard error of the sample is 1, then \\(t\\) could be 1, because 1/1 = 1.\nIf the sample standard error is smaller than 1, what happens to \\(t\\)? It get’s bigger right? For example, 1 divided by 0.5 = 2. If the sample standard error was 0.5, \\(t\\) would be 2. And, what could we do with this information? Well, it be like a measure of confidence. As \\(t\\) get’s bigger we could be more confident in the mean difference we are measuring.\nCan \\(t\\) be smaller than 1? Sure, it can. If the sample standard error is big, say like 2, then \\(t\\) will be smaller than one (in our case), e.g., 1/2 = .5. The direction of the difference between the sample mean and population mean, can also make the \\(t\\) become negative. What if our sample mean was 4. Well, then \\(t\\) will be negative, because the mean difference in the numerator will be negative, and the number in the bottom (denominator) will always be positive (remember why, it’s the standard error, computed from the sample standard deviation, which is always positive because of the squaring that we did.).\nSo, that is some intuitions about what the kinds of values t can take. \\(t\\) can be positive or negative, and big or small.\nLet’s do one more thing to build our intuitions about what \\(t\\) can look like. How about we sample some numbers and then measure the sample mean and the standard error of the mean, and then plot those two things against each each. This will show us how a sample mean typically varies with respect to the standard error of the mean.\nIn Figure 1, I pulled 1,000 samples of \\(N = 10\\) from a normal distribution (mean = 0, sd = 1). Each time I measured the mean and standard error of the sample. That gave two descriptive statistics for each sample, letting us plot each sample as dot in a scatter plot.\n\n\nCode\nlibrary(ggplot2)\n\n\n\n\nCode\nsample_mean &lt;- length(1000)\nsample_se &lt;- length(1000)\n\nfor (i in 1:1000) {\n  s &lt;- rnorm(10, 0, 1)\n  sample_mean[i] &lt;- mean(s)\n  sample_se[i] &lt;- sd(s) / sqrt(length(s))\n}\n\nplot(sample_mean, sample_se)\n\n\n\n\n\n\n\n\nFigure 1: A scatter plot with sample mean on the x-axis, and standard error of the mean on the y-axis\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nTake penguins, and then,\nadd new columns for the bill ratio and bill area.\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n1penguins |&gt;\n2  mutate(\n    bill_ratio = bill_depth_mm / bill_length_mm,\n    bill_area  = bill_depth_mm * bill_length_mm\n  )\n\n\n\n1\n\nTake penguins, and then,\n\n2\n\nadd new columns for the bill ratio and bill area.\n\n\n\n\n# A tibble: 344 × 10\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 4 more variables: sex &lt;fct&gt;, year &lt;int&gt;, bill_ratio &lt;dbl&gt;, bill_area &lt;dbl&gt;\n\n\n\n\nResultInteractive\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(palmerpenguins)\npenguins |&gt;                                      # &lt;1&gt;\n  mutate(                                        # &lt;2&gt;\n    bill_ratio = bill_depth_mm / bill_length_mm, # &lt;2&gt;\n    bill_area  = bill_depth_mm * bill_length_mm  # &lt;2&gt;\n  )         \n\n\n# A tibble: 344 × 10\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 4 more variables: sex &lt;fct&gt;, year &lt;int&gt;, bill_ratio &lt;dbl&gt;, bill_area &lt;dbl&gt;\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nWhat we get is a cloud of dots. You might notice the cloud has a circular quality. There’s more dots in the middle, and fewer dots as they radiate out from the middle. The dot cloud shows us the general range of the sample mean, for example most of the dots are in between -1 and 1. Similarly, the range for the sample standard error is roughly between .2 and .5. Remember, each dot represents one sample.\nWe can look at the same data a different way. For example, rather than using a scatter plot, we can divide the mean for each dot by the standard error for each dot. Figure 2 shows the result in a histogram.\n\n\nCode\nhist(sample_mean/sample_se, breaks=30)\n\n\n\n\n\n\n\n\nFigure 2: A histogram of the sample means divided by the sample standard errors, this is a t-distribution.\n\n\n\n\n\nInteresting, we can see the histogram is shaped like a normal curve. It is centered on 0, which is the most common value. As values become more extreme, they become less common. If you remember, our formula for \\(t\\), was the mean divided by the standard error of the mean. That’s what we did here. This histogram is showing you a \\(t\\)-distribution.\n\n\n\nLet’s briefly calculate a t-value from a small sample. Let’s say we had 10 students do a true/false quiz with 5 questions on it. There’s a 50% chance of getting each answer correct.\nEvery student completes the 5 questions, we grade them, and then we find their performance (mean percent correct). What we want to know is whether the students were guessing. If they were all guessing, then the sample mean should be about 50%, it shouldn’t be different from chance, which is 50%. Let’s look at Table 1.\n\n\n\n\nTable 1: Calculating the t-value for a one-sample test.\n\n\n\n\n\n\nstudents\nscores\nmean\nDifference_from_Mean\nSquared_Deviations\n\n\n\n\n1\n50\n61\n-11\n121\n\n\n2\n70\n61\n9\n81\n\n\n3\n60\n61\n-1\n1\n\n\n4\n40\n61\n-21\n441\n\n\n5\n80\n61\n19\n361\n\n\n6\n30\n61\n-31\n961\n\n\n7\n90\n61\n29\n841\n\n\n8\n60\n61\n-1\n1\n\n\n9\n70\n61\n9\n81\n\n\n10\n60\n61\n-1\n1\n\n\nSums\n610\n610\n0\n2890\n\n\nMeans\n61\n61\n0\n289\n\n\n\n\n\nsd\n17.92\n\n\n\n\n\nSEM\n5.67\n\n\n\n\n\nt\n1.94003527336861\n\n\n\n\n\n\n\n\nYou can see the scores column has all of the test scores for each of the 10 students. We did the things we need to do to compute the standard deviation.\nRemember the sample standard deviation is the square root of the sample variance, or:\n\\(\\text{sample standard deviation} = \\sqrt{\\frac{\\sum_{i}^{n}({x_{i}-\\bar{x})^2}}{N-1}}\\)\n\\(\\text{sd} = \\sqrt{\\frac{2890}{10-1}} = 17.92\\)\nThe standard error of the mean, is the standard deviation divided by the square root of N\n\\(\\text{SEM} = \\frac{s}{\\sqrt{N}} = \\frac{17.92}{10} = 5.67\\)\n\\(t\\) is the difference between our sample mean (61), and our population mean (50, assuming chance), divided by the standard error of the mean.\n\\(\\text{t} = \\frac{\\bar{X}-u}{S_{\\bar{X}}} = \\frac{\\bar{X}-u}{SEM} = \\frac{61-50}{5.67} = 1.94\\)\nAnd, that is you how calculate \\(t\\), by hand. It’s a pain. I was annoyed doing it this way. In the lab, you learn how to calculate \\(t\\) using software, so it will just spit out \\(t\\). For example in R, all you have to do is this:\n\n\nCode\nt.test(scores, mu=50)\n\n\n\n    One Sample t-test\n\ndata:  scores\nt = 1.9412, df = 9, p-value = 0.08415\nalternative hypothesis: true mean is not equal to 50\n95 percent confidence interval:\n 48.18111 73.81889\nsample estimates:\nmean of x \n       61 \n\n\n\n\n\nIf \\(t\\) is just a number that we can compute from our sample (it is), what can we do with it? How can we use \\(t\\) for statistical inference?\nRemember back to the chapter on sampling and distributions, that’s where we discussed the sampling distribution of the sample mean. Remember, we made a lot of samples, then computed the mean for each sample, then we plotted a histogram of the sample means. Later, in that same section, we mentioned that we could generate sampling distributions for any statistic. For each sample, we could compute the mean, the standard deviation, the standard error, and now even \\(t\\), if we wanted to. We could generate 10,000 samples, and draw four histograms, one for each sampling distribution for each statistic.\nThis is exactly what I did, and the results are shown in the four panels of Figure 3 below. I used a sample size of 20, and drew random observations for each sample from a normal distribution, with mean = 0, and standard deviation = 1. Let’s look at the sampling distributions for each of the statistics. \\(t\\) was computed assuming with the population mean assumed to be 0.\n\n\nCode\nall_df &lt;- data.frame()\nfor (i in 1:10000) {\n  sample &lt;- rnorm(20, 0, 1)\n  sample_mean &lt;- mean(sample)\n  sample_sd &lt;- sd(sample)\n  sample_se &lt;- sd(sample) / sqrt(length(sample))\n  sample_t &lt;- as.numeric(t.test(sample, mu = 0)$statistic)\n  t_df &lt;- data.frame(i, sample_mean, sample_sd, sample_se, sample_t)\n  all_df &lt;- rbind(all_df, t_df)\n}\n\nlibrary(ggpubr)\na &lt;- ggplot(all_df, aes(x = sample_mean)) +\n  geom_histogram(color = \"white\") +\n  theme_classic(base_size=20)\nb &lt;- ggplot(all_df, aes(x = sample_sd)) +\n  geom_histogram(color = \"white\") +\n  theme_classic(base_size=20)\nc &lt;- ggplot(all_df, aes(x = sample_se)) +\n  geom_histogram(color = \"white\") +\n  theme_classic(base_size=20)\nd &lt;- ggplot(all_df, aes(x = sample_t)) +\n  geom_histogram(color = \"white\") +\n  theme_classic(base_size=20)\n\nggarrange(a, b, c, d,\n          ncol = 2, nrow = 2)\n\n\n\n\n\n\n\n\nFigure 3: Sampling distributions for the mean, standard deviation, standard error of the mean, and \\(t\\).\n\n\n\n\n\nWe see four sampling distributions. This is how statistical summaries of these summaries behave. We have used the word chance windows before. These are four chance windows, measuring different aspects of the sample. In this case, all of the samples came from the same normal distribution. Because of sampling error, each sample is not identical. The means are not identical, the standard deviations are not identical, sample standard error of the means are not identical, and the \\(t\\)s of the samples are not identical. They all have some variation, as shown by the histograms. This is how samples of size 20 behave.\nWe can see straight away, that in this case, we are unlikely to get a sample mean of 2. That’s way outside the window. The range for the sampling distribution of the mean is around -.5 to +.5, and is centered on 0 (the population mean, would you believe!).\nWe are unlikely to get sample standard deviations of between .6 and 1.5, that is a different range, specific to the sample standard deviation.\nSame thing with the sample standard error of the mean, the range here is even smaller, mostly between .1, and .3. You would rarely find a sample with a standard error of the mean greater than .3. Virtually never would you find one of say 1 (for this situation).\nNow, look at \\(t\\). It’s range is basically between -3 and +3 here. 3s barely happen at all. You pretty much never see a 5 or -5 in this situation.\nAll of these sampling windows are chance windows, and they can all be used in the same way as we have used similar sampling distributions before (e.g., Crump Test, and Randomization Test) for statistical inference. For all of them we would follow the same process:\n\nGenerate these distributions\nLook at your sample statistics for the data you have (mean, SD, SEM, and \\(t\\))\nFind the likelihood of obtaining that value or greater\nObtain that probability\nSee if you think your sample statistics were probable or improbable.\n\nWe’ll formalize this in a second. I just want you to know that what you will be doing is something that you have already done before. For example, in the Crump test and the Randomization test we focused on the distribution of mean differences. We could do that again here, but instead, we will focus on the distribution of \\(t\\) values. We then apply the same kinds of decision rules to the \\(t\\) distribution, as we did for the other distributions. Below you will see a graph you have already seen, except this time it is a distribution of \\(t\\)s, not mean differences:\nRemember, if we obtained a single \\(t\\) from one sample we collected, we could consult the chance window in Figure 4 below to find out whether the \\(t\\) we obtained from the sample was likely or unlikely to occur by chance.\n\n\nCode\nsample_t &lt;- all_df$sample_t\n\nggplot(all_df, aes(x = sample_t)) +\n  annotate(\n    \"rect\",\n    xmin = min(sample_t),\n    xmax = max(sample_t),\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.5,\n    fill = \"red\"\n  ) +\n  annotate(\n    \"rect\",\n    xmin = min(sample_t),\n    xmax = -1.94,\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.7,\n    fill = \"light grey\"\n  ) +\n  annotate(\n    \"rect\",\n    xmin = 1.94,\n    xmax = max(sample_t),\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.7,\n    fill = \"light grey\"\n  ) +\n  geom_rect(aes(\n    xmin = -Inf,\n    xmax = min(sample_t),\n    ymin = 0,\n    ymax = Inf\n  ),\n  alpha = .5,\n  fill = \"lightgreen\") +\n  geom_rect(aes(\n    xmin = max(sample_t),\n    xmax = Inf,\n    ymin = 0,\n    ymax = Inf\n  ),\n  alpha = .5,\n  fill = \"lightgreen\") +\n  geom_histogram(bins = 50, color = \"white\") +\n  theme_classic() +\n  geom_vline(xintercept = min(sample_t)) +\n  geom_vline(xintercept = max(sample_t)) +\n  geom_vline(xintercept = -1.94) +\n  geom_vline(xintercept = 1.94) +\n  xlim(-8, 8) +\n  geom_label(data = data.frame(x = 0, y = 250, label = \"CHANCE\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = -7, y = 250, label = \"NOT \\n CHANCE\"),\n             aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = 7, y = 250, label = \"NOT \\n CHANCE\"),\n             aes(x = x, y = y, label = label)) +\n  #  geom_label(data = data.frame(x = min(sample_t), y = 600,\n  #                              label = paste0(\"min \\n\",round(min(sample_t)))),\n  #                             aes(x = x, y = y, label = label))+\n  #geom_label(data = data.frame(x = max(sample_t), y = 600,\n  #                            label = paste0(\"max \\n\",round(max(sample_t)))),\n  #                           aes(x = x, y = y, label = label))+\n  geom_label(data = data.frame(x = -4, y = 250,\n                               label = \"?\"),\n             aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = 4, y = 250,\n                               label = \"?\"),\n             aes(x = x, y = y, label = label)) +\n  xlab(\"mean sample_t\")\n\n\n\n\n\n\n\n\nFigure 4: Applying decision criteria to the \\(t\\)-distribution. Histogram of \\(t\\)s from samples (n=20) drawn from the same normal distribution (u=0, sd=1)\n\n\n\n\n\n\n\n\nFrom our early example involving the TRUE/FALSE quizzes, we are now ready to make some kind of decision about what happened there. We found a mean difference of 11. We found a \\(t\\) = 1.9411765. The probability of this \\(t\\) or larger occurring is \\(p\\) = 0.0841503. We were testing the idea that our sample mean of 61 could have come from a normal distribution with mean = 50. The \\(t\\) test tells us that the \\(t\\) for our sample, or a larger one, would happen with p = 0.0841503. In other words, chance can do it a kind of small amount of time, but not often. In English, this means that all of the students could have been guessing, but it wasn’t that likely that were just guessing.\nThe next \\(t\\)-test is called a paired samples t-test. And, spoiler alert, we will find out that a paired samples t-test is actually a one-sample t-test in disguise (WHAT!), yes it is. If the one-sample \\(t\\)-test didn’t make sense to you, read the next section.\n\n\n\n\nFor me (Crump), many analyses often boil down to a paired samples t-test. It just happens that many things I do reduce down to a test like this.\nI am a cognitive psychologist, I conduct research about how people do things like remember, pay attention, and learn skills. There are lots of Psychologists like me, who do very similar things.\nWe all often conduct the same kinds of experiments. They go like this, and they are called repeated measures designs. They are called repeated measures designs, because we measure how one person does something more than once, we repeat the measure.\nSo, I might measure somebody doing something in condition A, and measure the same person doing something in Condition B, and then I see that same person does different things in the two conditions. I repeatedly measure the same person in both conditions. I am interested in whether the experimental manipulation changes something about how people perform the task in question.\n\n\nWe will introduce the paired-samples t-test with an example using real data, from a real study. (mehr20165?) were interested in whether singing songs to infants helps infants become more sensitive to social cues. For example, infants might need to learn to direct their attention toward people as a part of learning how to interact socially with people. Perhaps singing songs to infants aids this process of directing attention. When an infant hears a familiar song, they might start to pay more attention to the person singing that song, even after they are done singing the song. The person who sang the song might become more socially important to the infant. You will learn more about this study in the lab for this week. This example, prepares you for the lab activities. Here is a brief summary of what they did.\nFirst, parents were trained to sing a song to their infants. After many days of singing this song to the infants, a parent came into the lab with their infant. In the first session, parents sat with their infants on their knees, so the infant could watch two video presentations. There were two videos. Each video involved two unfamiliar new people the infant had never seen before. Each new person in the video (the singers) sang one song to the infant. One singer sang the “familiar” song the infant had learned from their parents. The other singer sang an “unfamiliar” song the infant had not hear before.\nThere were two really important measurement phases: the baseline phase, and the test phase.\nThe baseline phase occurred before the infants saw and heard each singer sing a song. During the baseline phase, the infants watched a video of both singers at the same time. The researchers recorded the proportion of time that the infant looked at each singer. The baseline phase was conducted to determine whether infants had a preference to look at either person (who would later sing them a song).\nThe test phase occurred after infants saw and heard each song, sung by each singer. During the test phase, each infant had an opportunity to watch silent videos of both singers. The researchers measured the proportion of time the infants spent looking at each person. The question of interest, was whether the infants would spend a greater proportion of time looking at the singer who sang the familiar song, compared to the singer who sang the unfamiliar song.\nThere is more than one way to describe the design of this study. We will describe it like this. It was a repeated measures design, with one independent (manipulation) variable called Viewing phase: Baseline versus Test. There was one dependent variable (the measurement), which was proportion looking time (to singer who sung familiar song). This was a repeated measures design because the researchers measured proportion looking time twice (they repeated the measure), once during baseline (before infants heard each singer sing a song), and again during test (after infants head each singer sing a song).\nThe important question was whether infants would change their looking time, and look more at the singer who sang the familiar song during the test phase, than they did during the baseline phase. This is a question about a change within individual infants. In general, the possible outcomes for the study are:\n\nNo change: The difference between looking time toward the singer of the familiar song during baseline and test is zero, no difference.\nPositive change: Infants will look longer toward the singer of the familiar song during the test phase (after they saw and heard the singers), compared to the baseline phase (before they saw and heard the singers). This is a positive difference if we use the formula: Test Phase Looking time - Baseline phase looking time (to familiar song singer).\nNegative change: Infants will look longer toward the singer of the unfamiliar song during the test phase (after they saw and heard the singers), compared to the baseline phase (before they saw and heard the singers). This is a negative difference if we use the same formula: Test Phase Looking time - Baseline phase looking time (to familiar song singer).\n\n\n\n\nLet’s take a look at the data for the first 5 infants in the study. This will help us better understand some properties of the data before we analyze it. We will see that the data is structured in a particular way that we can take advantage of with a paired samples t-test. Note, we look at the first 5 infants to show how the computations work. The results of the paired-samples t-test change when we use all of the data from the study.\nHere is a table of the data:\n\n\n\n\n\ninfant\nBaseline\nTest\n\n\n\n\n1\n0.44\n0.60\n\n\n2\n0.41\n0.68\n\n\n3\n0.75\n0.72\n\n\n4\n0.44\n0.28\n\n\n5\n0.47\n0.50\n\n\n\n\n\nThe table shows proportion looking times toward the singer of the familiar song during the Baseline and Test phases. Notice there are five different infants, (1 to 5). Each infant is measured twice, once during the Baseline phase, and once during the Test phase. To repeat from before, this is a repeated-measures design, because the infants are measured repeatedly (twice in this case). Or, this kind of design is also called a paired-samples design. Why? because each participant comes with a pair of samples (two samples), one for each level of the design.\nGreat, so what are we really interested in here? We want to know if the mean looking time toward the singer of the familiar song for the Test phase is higher than the Baseline phase. We are comparing the two sample means against each other and looking for a difference. We already know that differences could be obtained by chance alone, simply because we took two sets of samples, and we know that samples can be different. So, we are interested in knowing whether chance was likely or unlikely to have produced any difference we might observe.\nIn other words, we are interested in looking at the difference scores between the baseline and test phase for each infant. The question here is, for each infant, did their proportion looking time to the singer of the familiar song, increase during the test phase as compared to the baseline phase.\n\n\n\nLet’s add the difference scores to the table of data so it is easier to see what we are talking about. The first step in creating difference scores is to decide how you will take the difference, there are two options:\n\nTest phase score - Baseline Phase Score\nBaseline phase score - Test Phase score\n\nLet’s use the first formula. Why? Because it will give us positive differences when the test phase score is higher than the baseline phase score. This makes a positive score meaningful with respect to the study design, we know (because we defined it to be this way), that positive scores will refer to longer proportion looking times (to singer of familiar song) during the test phase compared to the baseline phase.\n\n\nCode\npaired_sample_df &lt;- cbind(paired_sample_df, \n                          differences = (paired_sample_df$Test-\n                                           paired_sample_df$Baseline))\nknitr::kable(paired_sample_df)\n\n\n\n\n\ninfant\nBaseline\nTest\ndifferences\n\n\n\n\n1\n0.44\n0.60\n0.16\n\n\n2\n0.41\n0.68\n0.27\n\n\n3\n0.75\n0.72\n-0.03\n\n\n4\n0.44\n0.28\n-0.16\n\n\n5\n0.47\n0.50\n0.03\n\n\n\n\n\nThere we have it, the difference scores. The first thing we can do here is look at the difference scores, and ask how many infants showed the effect of interest. Specifically, how many infants showed a positive difference score. We can see that three of five infants showed a positive difference (they looked more at the singer of the familiar song during the test than baseline phase), and two the infants showed the opposite effect (negative difference, they looked more at the singer of the familiar song during baseline than test).\n\n\n\nAs we have been discussing, the effect of interest in this study is the mean difference between the baseline and test phase proportion looking times. We can calculate the mean difference, by finding the mean of the difference scores. Let’s do that, in fact, for fun let’s calculate the mean of the baseline scores, the test scores, and the difference scores.\n\n\nCode\npaired_sample_df &lt;- paired_sample_df %&gt;%\n   rbind(c(\"Sums\",colSums(paired_sample_df[1:5,2:4]))) %&gt;%\n   rbind(c(\"Means\",colMeans(paired_sample_df[1:5,2:4])))\n  \nknitr::kable(paired_sample_df)\n\n\n\n\n\ninfant\nBaseline\nTest\ndifferences\n\n\n\n\n1\n0.44\n0.6\n0.16\n\n\n2\n0.41\n0.68\n0.27\n\n\n3\n0.75\n0.72\n-0.03\n\n\n4\n0.44\n0.28\n-0.16\n\n\n5\n0.47\n0.5\n0.03\n\n\nSums\n2.51\n2.78\n0.27\n\n\nMeans\n0.502\n0.556\n0.054\n\n\n\n\n\nWe can see there was a positive mean difference of 0.054, between the test and baseline phases.\nCan we rush to judgment and conclude that infants are more socially attracted to individuals who have sung them a familiar song? I would hope not based on this very small sample. First, the difference in proportion looking isn’t very large, and of course we recognize that this difference could have been produced by chance.\nWe will more formally evaluate whether this difference could have been caused by chance with the paired-samples t-test. But, before we do that, let’s again calculate \\(t\\) and discuss what \\(t\\) tells us over and above what our measure of the mean of the difference scores tells us.\n\n\n\nOK, so how do we calculate \\(t\\) for a paired-samples \\(t\\)-test? Surprise, we use the one-sample t-test formula that you already learned about! Specifically, we use the one-sample \\(t\\)-test formula on the difference scores. We have one sample of difference scores (you can see they are in one column), so we can use the one-sample \\(t\\)-test on the difference scores. Specifically, we are interested in comparing whether the mean of our difference scores came from a distribution with mean difference = 0. This is a special distribution we refer to as the null distribution. It is the distribution no differences. Of course, this null distribution can produce differences due to to sampling error, but those differences are not caused by any experimental manipulation, they caused by the random sampling process.\nWe calculate \\(t\\) in a moment. Let’s now consider again why we want to calculate \\(t\\)? Why don’t we just stick with the mean difference we already have?\nRemember, the whole concept behind \\(t\\), is that it gives an indication of how confident we should be in our mean. Remember, \\(t\\) involves a measure of the mean in the numerator, divided by a measure of variation (standard error of the sample mean) in the denominator. The resulting \\(t\\) value is small when the mean difference is small, or when the variation is large. So small \\(t\\)-values tell us that we shouldn’t be that confident in the estimate of our mean difference. Large \\(t\\)-values occur when the mean difference is large and/or when the measure of variation is small. So, large \\(t\\)-values tell us that we can be more confident in the estimate of our mean difference. Let’s find \\(t\\) for the mean difference scores. We use the same formulas as we did last time:\n\n\n\n\n\n\n\n\n\n\n\n\n\ninfant\nBaseline\nTest\ndifferences\ndiff_from_mean\nSquared_differences\n\n\n\n\n1\n0.44\n0.6\n0.16\n0.106\n0.011236\n\n\n2\n0.41\n0.68\n0.27\n0.216\n0.046656\n\n\n3\n0.75\n0.72\n-0.03\n-0.084\n0.00705600000000001\n\n\n4\n0.44\n0.28\n-0.16\n-0.214\n0.045796\n\n\n5\n0.47\n0.5\n0.03\n-0.024\n0.000575999999999999\n\n\nSums\n2.51\n2.78\n0.27\n0\n0.11132\n\n\nMeans\n0.502\n0.556\n0.054\n0\n0.022264\n\n\n\n\n\n\nsd\n0.167\n\n\n\n\n\n\nSEM\n0.075\n\n\n\n\n\n\nt\n0.72\n\n\n\n\n\nIf we did this test using R, we would obtain almost the same numbers (there is a little bit of rounding in the table).\n\n\nCode\nt.test(differences,mu=0)\n\n\n\n    One Sample t-test\n\ndata:  differences\nt = 0.72381, df = 4, p-value = 0.5092\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -0.1531384  0.2611384\nsample estimates:\nmean of x \n    0.054 \n\n\nHere is a quick write up of our t-test results, t(4) = .72, p = .509.\nWhat does all of that tell us? There’s a few things we haven’t gotten into much yet. For example, the 4 represents degrees of freedom, which we discuss later. The important part, the \\(t\\) value should start to be a little bit more meaningful. We got a kind of small t-value didn’t we. It’s .72. What can we tell from this value? First, it is positive, so we know the mean difference is positive. The sign of the \\(t\\)-value is always the same as the sign of the mean difference (ours was +0.054). We can also see that the p-value was .509. We’ve seen p-values before. This tells us that our \\(t\\) value or larger, occurs about 50.9% of the time… Actually it means more than this. And, to understand it, we need to talk about the concept of two-tailed and one-tailed tests.\n\n\n\nRemember what it is we are doing here. We are evaluating whether our sample data could have come from a particular kind of distribution. The null distribution of no differences. This is the distribution of \\(t\\)-values that would occur for samples of size 5, with a mean difference of 0, and a standard error of the sample mean of .075 (this is the SEM that we calculated from our sample). We can see what this particular null-distribution looks like in Figure 5.\n\n\nCode\nrange &lt;- seq(-3, 3, .1)\nnull_distribution &lt;- dt(range, 4, log = FALSE)\nplot_df &lt;- data.frame(range, null_distribution)\n\nggplot(plot_df, aes(x = range, y = null_distribution)) +\n  geom_line() +\n  xlab(\"t-values\") +\n  ylab(\"Probability\") +\n  theme(axis.text.y = element_blank(), axis.ticks = element_blank()) +\n  scale_x_continuous(breaks = (seq(-3, 3, .5))) +\n  geom_label(data = data.frame(x = -.7, y = .1, label = \"50% \\n (-)\"),\n             aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = .7, y = .1, label = \"50% \\n (+)\"), aes(x = x, y = y, label = label)) +\n  geom_vline(xintercept = 0)+\n  theme_classic(base_size = 20)\n\n\n\n\n\n\n\n\nFigure 5: A distribution of \\(t\\)-values that can occur by chance alone, when there is no difference between the sample and a population\n\n\n\n\n\nThe \\(t\\)-distribution above shows us the kinds of values \\(t\\) will will take by chance alone, when we measure the mean differences for pairs of 5 samples (like our current). \\(t\\) is most likely to be zero, which is good, because we are looking at the distribution of no-differences, which should most often be 0! But, sometimes, due to sampling error, we can get \\(t\\)s that are bigger than 0, either in the positive or negative direction. Notice the distribution is symmetrical, a \\(t\\) from the null-distribution will be positive half of the time, and negative half of the time, that is what we would expect by chance.\nSo, what kind of information do we want know when we find a particular \\(t\\) value from our sample? We want to know how likely the \\(t\\) value like the one we found occurs just by chance. This is actually a subtly nuanced kind of question. For example, any particular \\(t\\) value doesn’t have a specific probability of occurring. When we talk about probabilities, we are talking about ranges of probabilities. Let’s consider some probabilities. We will use the letter \\(p\\), to talk about the probabilities of particular \\(t\\) values.\n\nWhat is the probability that \\(t\\) is zero or positive or negative? The answer is p=1, or 100%. We will always have a \\(t\\) value that is zero or non-zero…Actually, if we can’t compute the t-value, for example when the standard deviation is undefined, I guess then we would have a non-number. But, assuming we can calculate \\(t\\), then it will always be 0 or positive or negative.\nWhat is the probability of \\(t\\) = 0 or greater than 0? The answer is p=.5, or 50%. 50% of \\(t\\)-values are 0 or greater.\nWhat is the of \\(t\\) = 0 or smaller than 0? The answer is p=.5, or 50%. 50% of \\(t\\)-values are 0 or smaller.\n\nWe can answer all of those questions just by looking at our t-distribution, and dividing it into two equal regions, the left side (containing 50% of the \\(t\\) values), and the right side containing 50% of the \\(t\\)-values).\nWhat if we wanted to take a more fine-grained approach, let’s say we were interested in regions of 10%. What kinds of \\(t\\)s occur 10% of the time. We would apply lines like the following. Notice, the likelihood of bigger numbers (positive or negative) gets smaller, so we have to increase the width of the bars for each of the intervals between the bars to contain 10% of the \\(t\\)-values, it looks like Figure 6.\n\n\nCode\nrange &lt;- seq(-3, 3, .1)\nnull_distribution &lt;- dt(range, 4, log = FALSE)\nplot_df &lt;- data.frame(range, null_distribution)\n\nt_ps &lt;- qt(seq(.1, .9, .1), 4)\n\nggplot(plot_df, aes(x = range, y = null_distribution)) +\n  geom_line() +\n  xlab(\"t-values\") +\n  ylab(\"Probability\") +\n  geom_vline(xintercept = t_ps) +\n  theme_classic(base_size = 15) +\n  theme(axis.text.y = element_blank(), axis.ticks = element_blank()) +\n  scale_x_continuous(breaks = round(t_ps, digits = 1)) +\n  geom_label(data = data.frame(x = -2.5, y = .2, label = \"10%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = -1.3, y = .2, label = \"10%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = 2.5, y = .2, label = \"10%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = 1.3, y = .2, label = \"10%\"), aes(x = x, y = y, label = label))\n\n\n\n\n\n\n\n\nFigure 6: Splitting the t distribution up into regions each containing 10% of the \\(t\\)-values. The width between the bars narrows as they approach the center of the distribution, where there are more \\(t\\)-values.\n\n\n\n\n\nConsider the probabilities (\\(p\\)) of \\(t\\) for the different ranges.\n\n\\(t\\) &lt;= -1.5 (\\(t\\) is less than or equal to -1.5), \\(p\\) = 10%\n-1.5 &gt;= \\(t\\) &lt;= -0.9 (\\(t\\) is equal to or between -1.5 and -.9), \\(p\\) = 10%\n-.9 &gt;= \\(t\\) &lt;= -0.6 (\\(t\\) is equal to or between -.9 and -.6), \\(p\\) = 10%\n\\(t\\) &gt;= 1.5 (\\(t\\) is greater than or equal to 1.5), \\(p\\) = 10%\n\nNotice, that the \\(p\\)s are always 10%. \\(t\\)s occur in these ranges with 10% probability.\n\n\n\nYou might be wondering where I am getting some of these values from. For example, how do I know that 10% of \\(t\\) values (for this null distribution) have a value of approximately 1.5 or greater than 1.5? The answer is I used R to tell me.\nIn most statistics textbooks the answer would be: there is a table at the back of the book where you can look these things up…This textbook has no such table. We could make one for you. And, we might do that. But, we didn’t do that yet…\nSo, where do these values come from, how can you figure out what they are? The complicated answer is that we are not going to explain the math behind finding these values because, 1) the authors (some of us) admittedly don’t know the math well enough to explain it, and 2) it would sidetrack us to much, 3) you will learn how to get these numbers in the lab with software, 4) you will learn how to get these numbers in lab without the math, just by doing a simulation, and 5) you can do it in R, or excel, or you can use an online calculator.\nThis is all to say that you can find the \\(t\\)s and their associated \\(p\\)s using software. But, the software won’t tell you what these values mean. That’s we are doing here. You will also see that software wants to know a few more things from you, such as the degrees of freedom for the test, and whether the test is one-tailed or two tailed. We haven’t explained any of these things yet. That’s what we are going to do now. Note, we explain degrees of freedom last. First, we start with a one-tailed test.\n\n\n\nA one-tailed test is sometimes also called a directional test. It is called a directional test, because a researcher might have a hypothesis in mind suggesting that the difference they observe in their means is going to have a particular direction, either a positive difference, or a negative difference.\nTypically, a researcher would set an alpha criterion. The alpha criterion describes a line in the sand for the researcher. Often, the alpha criterion is set at \\(p = .05\\). What does this mean? Figure 7 shows the \\(t\\)-distribution and the alpha criterion.\n\n\nCode\nrange &lt;- seq(-3, 3, .1)\nnull_distribution &lt;- dt(range, 4, log = FALSE)\nplot_df &lt;- data.frame(range, null_distribution)\n\nt_ps &lt;- qt(seq(.1, .9, .1), 4)\n\nggplot(plot_df, aes(x = range, y = null_distribution)) +\n  geom_line() +\n  xlab(\"t-values\") +\n  ylab(\"Probability\") +\n  geom_vline(xintercept = qt(.95, 4, lower.tail = TRUE)) +\n  ggtitle(\"Critical t for one-tailed test\") +\n  theme_classic(base_size = 10) +\n  theme(axis.text.y = element_blank(), axis.ticks = element_blank()) +\n  annotate(\n    \"rect\",\n    xmin = qt(.95, 4, lower.tail = TRUE),\n    xmax = 3,\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.5,\n    fill = \"green\"\n  ) +\n  geom_label(data = data.frame(x = 2.5, y = .2, label = \"5%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.95, 4, lower.tail = TRUE),\n    y = .3,\n    label = \"Critical t\"\n  ),\n  aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.95, 4, lower.tail = TRUE),\n    y = .25,\n    label = round(qt(.95, 4, lower.tail = TRUE), digits =\n                    2)\n  ),\n  aes(x = x, y = y, label = label))\n\n\n\n\n\n\n\n\nFigure 7: The critical value of t for an alpha criterion of 0.05. 5% of all ts are at this value or larger\n\n\n\n\n\nThe figure shows that \\(t\\) values of +2.13 or greater occur 5% of the time. Because the t-distribution is symmetrical, we also know that \\(t\\) values of -2.13 or smaller also occur 5% of the time. Both of these properties are true under the null distribution of no differences. This means, that when there really are no differences, a researcher can expect to find \\(t\\) values of 2.13 or larger 5% of the time.\nLet’s review and connect some of the terms:\n\nalpha criterion: the criterion set by the researcher to make decisions about whether they believe chance did or did not cause the difference. The alpha criterion here is set to \\(p = .05\\).\nCritical \\(t\\). The critical \\(t\\) is the \\(t\\)-value associated with the alpha-criterion. In this case for a one-tailed test, it is the \\(t\\) value where 5% of all \\(t\\)s are this number or greater. In our example, the critical \\(t\\) is 2.13. 5% of all \\(t\\) values (with degrees of freedom = 4) are +2.13, or greater than +2.13.\nObserved \\(t\\). The observed \\(t\\) is the one that you calculated from your sample. In our example about the infants, the observed \\(t\\) was \\(t\\) (4) = 0.72.\np-value. The \\(p\\)-value is the probability of obtaining the observed \\(t\\) value or larger. Now, you could look back at our previous example, and find that the \\(p\\)-value for \\(t\\) (4) = .72, was \\(p = .509\\) . HOWEVER, this p-value was not calculated for a one-directional test…(we talk about what .509 means in the next section).\n\nFigure 8 shows what the \\(p\\)-value for \\(t\\) (4) = .72 using a one-directional test would would look like:\n\n\nCode\nrange &lt;- seq(-3, 3, .1)\nnull_distribution &lt;- dt(range, 4, log = FALSE)\nplot_df &lt;- data.frame(range, null_distribution)\n\nt_ps &lt;- qt(seq(.1, .9, .1), 4)\n\nggplot(plot_df, aes(x = range, y = null_distribution)) +\n  geom_line() +\n  xlab(\"t-values\") +\n  ylab(\"Probability\") +\n  geom_vline(xintercept = .72) +\n  geom_vline(xintercept = qt(.95, 4, lower.tail = TRUE)) +\n  ggtitle(\"t value and p-range for one-directional test\") +\n  theme_classic(base_size = 10) +\n  theme(axis.text.y = element_blank(), axis.ticks = element_blank()) +\n  annotate(\n    \"rect\",\n    xmin = .72,\n    xmax = 3,\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.5,\n    fill = \"grey\"\n  ) +\n  annotate(\n    \"rect\",\n    xmin = qt(.95, 4, lower.tail = TRUE),\n    xmax = 3,\n    ymin = 0,\n    ymax = .25,\n    alpha = 0.5,\n    fill = \"green\"\n  ) +\n  geom_label(data = data.frame(x = 2.5, y = .2, label = \"5%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.95, 4, lower.tail = TRUE),\n    y = .3,\n    label = \"Critical t\"\n  ),\n  aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.95, 4, lower.tail = TRUE),\n    y = .25,\n    label = round(qt(.95, 4, lower.tail = TRUE), digits =\n                    2)\n  ),\n  aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = .72, y = .1,\n                               label = \"Observed t\"),\n             aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = .72, y = .05,\n                               label = \".72, p=\"),\n             aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = 1.5,\n    y = .05,\n    label = round(pt(.72, 4, lower.tail = FALSE), digits =\n                    3)\n  ),\n  aes(x = x, y = y, label = label))\n\n\n\n\n\n\n\n\nFigure 8: A case where the observed value of t is much less than the critical value for a one-directional t-test.\n\n\n\n\n\nLet’s take this one step at a time. We have located the observed \\(t\\) of .72 on the graph. We shaded the right region all grey. What we see is that the grey region represents .256 or 25.6% of all \\(t\\) values. In other words, 25.6% of \\(t\\) values are .72 or larger than .72. You could expect, by chance alone, to a find a \\(t\\) value of .72 or larger, 25.6% of the time. That’s fairly often. We did find a \\(t\\) value of .72. Now that you know this kind of \\(t\\) value or larger occurs 25.6% of the time, would you be confident that the mean difference was not due to chance? Probably not, given that chance can produce this difference fairly often.\nFollowing the “standard” decision making procedure, we would claim that our \\(t\\) value was not statistically significant, because it was not large enough. If our observed value was larger than the critical \\(t\\) (larger than 2.13), defined by our alpha criterion, then we would claim that our \\(t\\) value was statistically significant. This would be equivalent to saying that we believe it is unlikely that the difference we observed was due to chance. In general, for any observed \\(t\\) value, the associated \\(p\\)-value tells you how likely a \\(t\\) of the observed size or larger would be observed. The \\(p\\)-value always refers to a range of \\(t\\)-values, never to a single \\(t\\)-value. Researchers use the alpha criterion of .05, as a matter of convenience and convention. There are other ways to interpret these values that do not rely on a strict (significant versus not) dichotomy.\n\n\n\nOK, so that was one-tailed tests… What are two tailed tests? The \\(p\\)-value that we originally calculated from our paired-samples \\(t\\)-test was for a 2-tailed test. Often, the default is that the \\(p\\)-value is for a two-tailed test.\nThe two-tailed test, is asking a more general question about whether a difference is likely to have been produced by chance. The question is: what is probability of any difference. It is also called a non-directional test, because here we don’t care about the direction or sign of the difference (positive or negative), we just care if there is any kind of difference.\nThe same basic things as before are involved. We define an alpha criterion (\\(\\alpha = 0.05\\)). And, we say that any observed \\(t\\) value that has a probability of \\(p\\) &lt;.05 (\\(p\\) is less than .05) will be called statistically significant, and ones that are more likely (\\(p\\) &gt;.05, \\(p\\) is greater than .05) will be called null-results, or not statistically significant. The only difference is how we draw the alpha range. Before it was on the right side of the \\(t\\) distribution (we were conducting a one-sided test remember, so we were only interested in one side).\nFigure 9 shows what the most extreme 5% of the \\(t\\)-values are when we ignore their sign (whether they are positive or negative).\n\n\nCode\nrange &lt;- seq(-4, 4, .1)\nnull_distribution &lt;- dt(range, 4, log = FALSE)\nplot_df &lt;- data.frame(range, null_distribution)\n\nt_ps &lt;- qt(seq(.1, .9, .1), 4)\n\nggplot(plot_df, aes(x = range, y = null_distribution)) +\n  geom_line() +\n  xlab(\"t-values\") +\n  ylab(\"Probability\") +\n  geom_vline(xintercept = qt(.975, 4, lower.tail = TRUE)) +\n  geom_vline(xintercept = qt(.025, 4, lower.tail = TRUE)) +\n  ggtitle(\"Critical ts for two-tailed test\") +\n  theme_classic(base_size = 10) +\n  theme(axis.text.y = element_blank(), axis.ticks = element_blank()) +\n  annotate(\n    \"rect\",\n    xmin = qt(.975, 4, lower.tail = TRUE),\n    xmax = 4,\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.5,\n    fill = \"green\"\n  ) +\n  geom_label(data = data.frame(x = 3.5, y = .2, label = \"2.5%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.975, 4, lower.tail = TRUE),\n    y = .3,\n    label = \"Critical t\"\n  ),\n  aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.975, 4, lower.tail = TRUE),\n    y = .25,\n    label = round(qt(.975, 4, lower.tail = TRUE), digits =\n                    2)\n  ),\n  aes(x = x, y = y, label = label)) +\n  annotate(\n    \"rect\",\n    xmin = -4,\n    xmax = qt(.025, 4, lower.tail = TRUE),\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.5,\n    fill = \"green\"\n  ) +\n  geom_label(data = data.frame(x = -3.5, y = .2, label = \"2.5%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.025, 4, lower.tail = TRUE),\n    y = .3,\n    label = \"Critical t\"\n  ),\n  aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.025, 4, lower.tail = TRUE),\n    y = .25,\n    label = round(qt(.025, 4, lower.tail = TRUE), digits =\n                    2)\n  ),\n  aes(x = x, y = y, label = label))\n\n\n\n\n\n\n\n\nFigure 9: Critical values for a two-tailed test. Each line represents the location where 2.5% of all \\(t\\)s are larger or smaller than critical value. The total for both tails is 5%\n\n\n\n\n\nHere is what we are seeing. A distribution of no differences (the null, which is what we are looking at), will produce \\(t\\)s that are 2.78 or greater 2.5% of the time, and \\(t\\)s that are -2.78 or smaller 2.5% of the time. 2.5% + 2.5% is a total of 5% of the time. We could also say that \\(t\\)s larger than +/- 2.78 occur 5% of the time.\nAs a result, the critical \\(t\\) value is (+/-) 2.78 for a two-tailed test. As you can see, the two-tailed test is blind to the direction or sign of the difference. Because of this, the critical \\(t\\) value is also higher for a two-tailed test, than for the one-tailed test that we did earlier. Hopefully, now you can see why it is called a two-tailed test. There are two tails of the distribution, one on the left and right, both shaded in green.\n\n\n\nNow that you know there are two kinds of tests, one-tailed, and two-tailed, which one should you use? There is some conventional wisdom on this, but also some debate. In the end, it is up to you to be able to justify your choice and why it is appropriate for you data. That is the real answer.\nThe conventional answer is that you use a one-tailed test when you have a theory or hypothesis that is making a directional prediction (the theory predicts that the difference will be positive, or negative). Similarly, use a two-tailed test when you are looking for any difference, and you don’t have a theory that makes a directional prediction (it just makes the prediction that there will be a difference, either positive or negative).\nAlso, people appear to choose one or two-tailed tests based on how risky they are as researchers. If you always ran one-tailed tests, your critical \\(t\\) values for your set alpha criterion would always be smaller than the critical \\(t\\)s for a two-tailed test. Over the long run, you would make more type I errors, because the criterion to detect an effect is a lower bar for one than two tailed tests.\n\nRemember type 1 errors occur when you reject the idea that chance could have caused your difference. You often never know when you make this error. It happens anytime that sampling error was the actual cause of the difference, but a researcher dismisses that possibility and concludes that their manipulation caused the difference.\n\nSimilarly, if you always ran two-tailed tests, even when you had a directional prediction, you would make fewer type I errors over the long run, because the \\(t\\) for a two-tailed test is higher than the \\(t\\) for a one-tailed test. It seems quite common for researchers to use a more conservative two-tailed test, even when they are making a directional prediction based on theory. In practice, researchers tend to adopt a standard for reporting that is common in their field. Whether or not the practice is justifiable can sometimes be an open question. The important task for any researcher, or student learning statistics, is to be able to justify their choice of test.\n\n\n\nBefore we finish up with paired-samples \\(t\\)-tests, we should talk about degrees of freedom. Our sense is that students don’t really understand degrees of freedom very well. If you are reading this textbook, you are probably still wondering what is degrees of freedom, seeing as we haven’t really talked about it all.\nFor the \\(t\\)-test, there is a formula for degrees of freedom. For the one-sample and paired sample \\(t\\)-tests, the formula is:\n\\(\\text{Degrees of Freedom} = \\text{df} = n-1\\). Where n is the number of samples in the test.\nIn our paired \\(t\\)-test example, there were 5 infants. Therefore, degrees of freedom = 5-1 = 4.\nOK, that’s a formula. Who cares about degrees of freedom, what does the number mean? And why do we report it when we report a \\(t\\)-test… you’ve probably noticed the number in parentheses e.g., \\(t\\)(4)=.72, the 4 is the \\(df\\), or degrees of freedom.\nDegrees of freedom is both a concept, and a correction. The concept is that if you estimate a property of the numbers, and you use this estimate, you will be forcing some constraints on your numbers.\nConsider the numbers: 1, 2, 3. The mean of these numbers is 2. Now, let’s say I told you that the mean of three numbers is 2. Then, how many of these three numbers have freedom? Funny question right. What we mean is, how many of the three numbers could be any number, or have the freedom to be any number.\nThe first two numbers could be any number. But, once those two numbers are set, the final number (the third number), MUST be a particular number that makes the mean 2. The first two numbers have freedom. The third number has no freedom.\nTo illustrate. Let’s freely pick two numbers: 51 and -3. I used my personal freedom to pick those two numbers. Now, if our three numbers are 51, -3, and x, and the mean of these three numbers is 2. There is only one solution, x has to be -42, otherwise the mean won’t be 2. This is one way to think about degrees of freedom. The degrees of freedom for these three numbers is n-1 = 3-1= 2, because 2 of the numbers can be free, but the last number has no freedom, it becomes fixed after the first two are decided.\nNow, statisticians often apply degrees of freedom to their calculations, especially when a second calculation relies on an estimated value. For example, when we calculate the standard deviation of a sample, we first calculate the mean of the sample right! By estimating the mean, we are fixing an aspect of our sample, and so, our sample now has n-1 degrees of freedom when we calculate the standard deviation (remember for the sample standard deviation, we divide by n-1…there’s that n-1 again.)\n\n\nThere are at least two ways to think the degrees of freedom for a \\(t\\)-test. For example, if you want to use math to compute aspects of the \\(t\\) distribution, then you need the degrees of freedom to plug in to the formula… If you want to see the formulas I’m talking about, scroll down on the \\(t\\)-test wikipedia page and look for the probability density or cumulative distribution functions…We think that is quite scary for most people, and one reason why degrees of freedom are not well-understood.\nIf we wanted to simulate the \\(t\\) distribution we could more easily see what influence degrees of freedom has on the shape of the distribution. Remember, \\(t\\) is a sample statistic, it is something we measure from the sample. So, we could simulate the process of measuring \\(t\\) from many different samples, then plot the histogram of \\(t\\) to show us the simulated \\(t\\) distribution.\n\n\nCode\nts &lt;- c(rt(10000, 4), rt(10000, 100))\ndfs &lt;- as.factor(rep(c(4, 100), each = 10000))\n\nt_df &lt;- data.frame(dfs, ts)\nt_df &lt;- t_df[abs(t_df$ts) &lt; 5, ]\n\nggplot(t_df, aes(x = ts, group = dfs, color = dfs)) +\n  geom_histogram() +\n  theme_classic() +\n  facet_wrap( ~ dfs) +\n  theme_classic(base_size=15)\n\n\n\n\n\n\n\n\nFigure 10: The width of the t distribution shrinks as sample size and degrees of freedom (from 4 to 100) increases.\n\n\n\n\n\nIn Figure 10 notice that the red distribution for \\(df = 4\\), is a little bit shorter, and a little bit wider than the bluey-green distribution for \\(df = 100\\). As degrees of freedom increase the \\(t\\) distribution gets taller (in the middle), and narrower in the range. It get’s more peaky. Can you guess the reason for this? Remember, we are estimating a sample statistic, and degrees of freedom is really just a number that refers to the number of subjects (well minus one). And, we already know that as we increase \\(n\\), our sample statistics become better estimates (less variance) of the distributional parameters they are estimating. So, \\(t\\) becomes a better estimate of it’s “true” value as sample size increase, resulting in a more narrow distribution of \\(t\\)s.\nThere is a slightly different \\(t\\) distribution for every degrees of freedom, and the critical regions associated with 5% of the extreme values are thus slightly different every time. This is why we report the degrees of freedom for each t-test, they define the distribution of \\(t\\) values for the sample-size in question. Why do we use n-1 and not n? Well, we calculate \\(t\\) using the sample standard deviation to estimate the standard error or the mean, that estimate uses n-1 in the denominator, so our \\(t\\) distribution is built assuming n-1. That’s enough for degrees of freedom…\n\n\n\n\n\nYou must be wondering if we will ever be finished talking about paired samples t-tests… why are we doing round 2, oh no! Don’t worry, we’re just going to 1) remind you about what we were doing with the infant study, and 2) do a paired samples t-test on the entire data set and discuss.\nRemember, we were wondering if the infants would look longer toward the singer who sang the familiar song during the test phase compared to the baseline phase. We showed you data from 5 infants, and walked through the computations for the \\(t\\)-test. As a reminder, it looked like this:\n\n\n\n\n\n\n\n\n\n\n\n\n\ninfant\nBaseline\nTest\ndifferences\ndiff_from_mean\nSquared_differences\n\n\n\n\n1\n0.44\n0.6\n0.16\n0.106\n0.011236\n\n\n2\n0.41\n0.68\n0.27\n0.216\n0.046656\n\n\n3\n0.75\n0.72\n-0.03\n-0.084\n0.00705600000000001\n\n\n4\n0.44\n0.28\n-0.16\n-0.214\n0.045796\n\n\n5\n0.47\n0.5\n0.03\n-0.024\n0.000575999999999999\n\n\nSums\n2.51\n2.78\n0.27\n0\n0.11132\n\n\nMeans\n0.502\n0.556\n0.054\n0\n0.022264\n\n\n\n\n\n\nsd\n0.167\n\n\n\n\n\n\nSEM\n0.075\n\n\n\n\n\n\nt\n0.72\n\n\n\n\n\n\n    One Sample t-test\n\ndata:  round(differences, digits = 2)\nt = 0.72381, df = 4, p-value = 0.5092\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -0.1531384  0.2611384\nsample estimates:\nmean of x \n    0.054 \n\n\nLet’s write down the finding one more time: The mean difference was 0.054, \\(t\\)(4) = .72, \\(p\\) =.509. We can also now confirm, that the \\(p\\)-value was from a two-tailed test. So, what does this all really mean.\nWe can say that a \\(t\\) value with an absolute of .72 or larger occurs 50.9% of the time. More precisely, the distribution of no differences (the null), will produce a \\(t\\) value this large or larger 50.9% of the time. In other words, chance alone good have easily produced the \\(t\\) value from our sample, and the mean difference we observed or .054, could easily have been a result of chance.\nLet’s quickly put all of the data in the \\(t\\)-test, and re-run the test using all of the infant subjects.\n\n\nCode\npaired_sample_df &lt;-  data.frame(infant=1:32, \n                               Baseline = round(experiment_one$Baseline_Proportion_Gaze_to_Singer[1:32],digits=2), \n                               Test = round(experiment_one$Test_Proportion_Gaze_to_Singer[1:32], digits=2))\n\ndifferences &lt;-  paired_sample_df$Test-paired_sample_df$Baseline\nt.test(differences,mu=0)\n\n\n\n    One Sample t-test\n\ndata:  differences\nt = 2.4388, df = 31, p-value = 0.02066\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 0.01192088 0.13370412\nsample estimates:\nmean of x \n0.0728125 \n\n\nNow we get a very different answer. We would summarize the results saying the mean difference was .073, t(31) = 2.44, p = 0.020. How many total infants were their? Well the degrees of freedom was 31, so there must have been 32 infants in the study. Now we see a much smaller \\(p\\)-value. This was also a two-tailed test, so we that observing a \\(t\\) value of 2.4 or greater (absolute value) only occurs 2% of the time. In other words, the distribution of no differences will produce the observed t-value very rarely. So, it is unlikely that the observed mean difference of .073 was due to chance (it could have been due to chance, but that is very unlikely). As a result, we can be somewhat confident in concluding that something about seeing and hearing a unfamiliar person sing a familiar song, causes an infant to draw their attention toward the singer, and this potentially benefits social learning on the part of the infant.\n\n\n\nIf you’ve been following the Star Wars references, we are on last movie (of the original trilogy)… the independent t-test. This is were basically the same story plays out as before, only slightly different.\nRemember there are different \\(t\\)-tests for different kinds of research designs. When your design is a between-subjects design, you use an independent samples t-test. Between-subjects design involve different people or subjects in each experimental condition. If there are two conditions, and 10 people in each, then there are 20 total people. And, there are no paired scores, because every single person is measured once, not twice, no repeated measures. Because there are no repeated measures we can’t look at the difference scores between conditions one and two. The scores are not paired in any meaningful way, to it doesn’t make sense to subtract them. So what do we do?\nThe logic of the independent samples t-test is the very same as the other \\(t\\)-tests. We calculated the means for each group, then we find the difference. That goes into the numerator of the t formula. Then we get an estimate of the variation for the denominator. We divide the mean difference by the estimate of the variation, and we get \\(t\\). It’s the same as before.\nThe only wrinkle here is what goes into the denominator? How should we calculate the estimate of the variance? It would be nice if we could do something very straightforward like this, say for an experiment with two groups A and B:\n\\(t = \\frac{\\bar{A}-\\bar{B}}{(\\frac{SEM_A+SEM_B}{2})}\\)\nIn plain language, this is just:\n\nFind the mean difference for the top part\nCompute the SEM (standard error of the mean) for each group, and average them together to make a single estimate, pooling over both samples.\n\nThis would be nice, but unfortunately, it turns out that finding the average of two standard errors of the mean is not the best way to do it. This would create a biased estimator of the variation for the hypothesized distribution of no differences. We won’t go into the math here, but instead of the above formula, we an use a different one that gives as an unbiased estimate of the pooled standard error of the sample mean. Our new and improved \\(t\\) formula would look like this:\n\\(t = \\frac{\\bar{X_A}-\\bar{X_B}}{s_p * \\sqrt{\\frac{1}{n_A} + \\frac{1}{n_B}}}\\)\nand, \\(s_p\\), which is the pooled sample standard deviation is defined as, note the $s$es in the formula are variances:\n\\(s_p = \\sqrt{\\frac{(n_A-1)s_A^2 + (n_B-1)s^2_B}{n_A +n_B -2}}\\)\nBelieve you me, that is so much more formula than I wanted to type out. Shall we do one independent \\(t\\)-test example by hand, just to see the computations? Let’s do it…but in a slightly different way than you expect. I show the steps using R. I made some fake scores for groups A and B. Then, I followed all of the steps from the formula, but made R do each of the calculations. This shows you the needed steps by following the code. At the end, I print the \\(t\\)-test values I computed “by hand”, and then the \\(t\\)-test value that the R software outputs using the \\(t\\)-test function. You should be able to get the same values for \\(t\\), if you were brave enough to compute \\(t\\) by hand.\n\n\nCode\n## By \"hand\" using R r code\na &lt;- c(1,2,3,4,5)\nb &lt;- c(3,5,4,7,9)\n\nmean_difference &lt;- mean(a)-mean(b) # compute mean difference\n\nvariance_a &lt;- var(a) # compute variance for A\nvariance_b &lt;- var(b) # compute variance for B\n\n# Compute top part and bottom part of sp formula\n\nsp_numerator &lt;- (4*variance_a + 4* variance_b) \nsp_denominator &lt;- 5+5-2\nsp &lt;- sqrt(sp_numerator/sp_denominator) # compute sp\n\n\n# compute t following formulat\n\nt &lt;- mean_difference / ( sp * sqrt( (1/5) +(1/5) ) )\n\nt # print results\n\n\n[1] -2.017991\n\n\nCode\n# using the R function t.test\nt.test(a,b, paired=FALSE, var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  a and b\nt = -2.018, df = 8, p-value = 0.0783\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -5.5710785  0.3710785\nsample estimates:\nmean of x mean of y \n      3.0       5.6 \n\n\n\n\n\nAn “advanced” topic for \\(t\\)-tests is the idea of using R to conduct simulations for \\(t\\)-tests.\nIf you recall, \\(t\\) is a property of a sample. We calculate \\(t\\) from our sample. The \\(t\\) distribution is the hypothetical behavior of our sample. That is, if we had taken thousands upon thousands of samples, and calculated \\(t\\) for each one, and then looked at the distribution of those \\(t\\)’s, we would have the sampling distribution of \\(t\\)!\nIt can be very useful to get in the habit of using R to simulate data under certain conditions, to see how your sample data, and things like \\(t\\) behave. Why is this useful? It mainly prepares you with some intuitions about how sampling error (random chance) can influence your results, given specific parameters of your design, such as sample-size, the size of the mean difference you expect to find in your data, and the amount of variation you might find. These methods can be used formally to conduct power-analyses. Or more informally for data sense.\n\n\nHere are the steps you might follow to simulate data for a one sample \\(t\\)-test.\n\nMake some assumptions about what your sample (that you might be planning to collect) might look like. For example, you might be planning to collect 30 subjects worth of data. The scores of those data points might come from a normal distribution (mean = 50, sd = 10).\nsample simulated numbers from the distribution, then conduct a \\(t\\)-test on the simulated numbers. Save the statistics you want (such as \\(t\\)s and \\(p\\)s), and then see how things behave.\n\nLet’s do this a couple different times. First, let’s simulate samples with N = 30, taken from a normal (mean= 50, sd = 25). We’ll do a simulation with 1000 simulations. For each simulation, we will compare the sample mean with a population mean of 50. There should be no difference on average here. Figure 11 is the null distribution that we are simulating.\n\n\nCode\n# steps to create fake data from a distribution\n# and conduct t-tests on the simulated data\nsave_ps &lt;- length(1000)\nsave_ts &lt;- length(1000)\nfor (i in 1:1000) {\n  my_sample &lt;- rnorm(n = 30, mean = 50, sd = 25)\n  t_test &lt;- t.test (my_sample, mu = 50)\n  save_ps[i] &lt;- t_test$p.value\n  save_ts[i] &lt;- t_test$statistic\n}\n\n\n\n\nCode\n#plot histograms of t and p values for 1000 simulations\nhist(save_ts)\n\n\n\n\n\n\n\n\nFigure 11: The distribution of \\(t\\)-values under the null. These are the \\(t\\) values that are produced by chance alone.\n\n\n\n\n\n\n\nCode\nhist(save_ps)\n\n\n\n\n\n\n\n\nFigure 12: The distribution of \\(p\\)-values that are observed is flat under the null.\n\n\n\n\n\nNeat. We see both a \\(t\\) distribution, that looks like \\(t\\) distribution as it should. And we see the \\(p\\) distribution. This shows us how often we get \\(t\\) values of particular sizes. You may find it interesting that the \\(p\\)-distribution is flat under the null, which we are simulating here. This means that you have the same chances of a getting a \\(t\\) with a p-value between 0 and 0.05, as you would for getting a \\(t\\) with a p-value between .90 and .95. Those ranges are both ranges of 5%, so there are an equal amount of \\(t\\) values in them by definition.\nHere’s another way to do the same simulation in R, using the replicate function, instead a for loop:\n\n\nCode\nsimulated_ts &lt;- replicate(1000,\n                          t.test(rnorm(30, 50, 25), mu = 50)$statistic)\nhist(simulated_ts)\n\n\n\n\n\n\n\n\nFigure 13: Simulating \\(t\\)s in R.\n\n\n\n\n\n\n\nCode\nsimulated_ps &lt;- replicate(1000,\n                          t.test(rnorm(30, 50, 25), mu = 50)$p.value)\nhist(simulated_ps)\n\n\n\n\n\n\n\n\nFigure 14: Simulating \\(p\\)s in R.\n\n\n\n\n\n\n\n\nThe code below is set up to sample 10 scores for condition A and B from the same normal distribution. The simulation is conducted 1000 times, and the \\(t\\)s and \\(p\\)s are saved and plotted for each.\n\n\nCode\nsave_ps &lt;- length(1000)\nsave_ts &lt;- length(1000)\nfor ( i in 1:1000 ){\n  condition_A &lt;- rnorm(10,10,5)\n  condition_B &lt;- rnorm(10,10,5)\n  differences &lt;- condition_A - condition_B\n  t_test &lt;- t.test(differences, mu=0)\n  save_ps[i] &lt;- t_test$p.value\n  save_ts[i] &lt;- t_test$statistic\n}\n\n\n\n\nCode\nhist(save_ts)\n\n\n\n\n\n\n\n\nFigure 15: 1000 simulated ts from the null distribution\n\n\n\n\n\n\n\nCode\nhist(save_ps)\n\n\n\n\n\n\n\n\nFigure 16: 1000 simulated ps from the null distribution\n\n\n\n\n\nAccording to the simulation. When there are no differences between the conditions, and the samples are being pulled from the very same distribution, you get these two distributions for \\(t\\) and \\(p\\). These again show how the null distribution of no differences behaves.\nFor any of these simulations, if you rejected the null-hypothesis (that your difference was only due to chance), you would be making a type I error. If you set your alpha criteria to \\(\\alpha = .05\\), we can ask how many type I errors were made in these 1000 simulations. The answer is:\n\n\nCode\nlength(save_ps[save_ps&lt;.05])\n\n\n[1] 40\n\n\nCode\nlength(save_ps[save_ps&lt;.05])/1000\n\n\n[1] 0.04\n\n\nWe happened to make 40. The expectation over the long run is 5% type I error rates (if your alpha is .05).\nWhat happens if there actually is a difference in the simulated data, let’s set one condition to have a larger mean than the other:\n\n\nCode\nsave_ps &lt;- length(1000)\nsave_ts &lt;- length(1000)\nfor ( i in 1:1000 ){\n  condition_A &lt;- rnorm(10,10,5)\n  condition_B &lt;- rnorm(10,13,5)\n  differences &lt;- condition_A - condition_B\n  t_test &lt;- t.test(differences, mu=0)\n  save_ps[i] &lt;- t_test$p.value\n  save_ts[i] &lt;- t_test$statistic\n}\n\n\n\n\nCode\nhist(save_ts)\n\n\n\n\n\n\n\n\nFigure 17: 1000 ts when there is a true difference\n\n\n\n\n\n\n\nCode\nhist(save_ps)\n\n\n\n\n\n\n\n\nFigure 18: 1000 ps when there is a true difference\n\n\n\n\n\nNow you can see that the \\(p\\)-value distribution is skewed to the left. This is because when there is a true effect, you will get p-values that are less than .05 more often. Or, rather, you get larger \\(t\\) values than you normally would if there were no differences.\nIn this case, we wouldn’t be making a type I error if we rejected the null when p was smaller than .05. How many times would we do that out of our 1000 experiments?\n\n\nCode\nlength(save_ps[save_ps&lt;.05])\n\n\n[1] 228\n\n\nCode\nlength(save_ps[save_ps&lt;.05])/1000\n\n\n[1] 0.228\n\n\nWe happened to get 228 simulations where p was less than .05, that’s only 0.228 experiments. If you were the researcher, would you want to run an experiment that would be successful only 0.228 of the time? I wouldn’t. I would run a better experiment.\nHow would you run a better simulated experiment? Well, you could increase \\(n\\), the number of subjects in the experiment. Let’s increase \\(n\\) from 10 to 100, and see what happens to the number of “significant” simulated experiments.\n\n\nCode\nsave_ps &lt;- length(1000)\nsave_ts &lt;- length(1000)\nfor ( i in 1:1000 ){\n  condition_A &lt;- rnorm(100,10,5)\n  condition_B &lt;- rnorm(100,13,5)\n  differences &lt;- condition_A - condition_B\n  t_test &lt;- t.test(differences, mu=0)\n  save_ps[i] &lt;- t_test$p.value\n  save_ts[i] &lt;- t_test$statistic\n}\n\n\n\n\nCode\nhist(save_ts)\n\n\n\n\n\n\n\n\nFigure 19: 1000 ts for n =100, when there is a true effect\n\n\n\n\n\n\n\nCode\nhist(save_ps)\n\n\nlength(save_ps[save_ps&lt;.05])\n\n\n[1] 990\n\n\nCode\nlength(save_ps[save_ps&lt;.05])/1000\n\n\n[1] 0.99\n\n\n\n\n\n\n\n\nFigure 20: 1000 ps for n =100, when there is a true effect\n\n\n\n\n\nCool, now almost all of the experiments show a \\(p\\)-value of less than .05 (using a two-tailed test, that’s the default in R). See, you could use this simulation process to determine how many subjects you need to reliably find your effect.\n\n\n\nJust change the t.test function like so… this is for the null, assuming no difference between groups.\n\n\nCode\nsave_ps &lt;- length(1000)\nsave_ts &lt;- length(1000)\nfor ( i in 1:1000 ){\n  group_A &lt;- rnorm(10,10,5)\n  group_B &lt;- rnorm(10,10,5)\n  t_test &lt;- t.test(group_A, group_B, paired=FALSE, var.equal=TRUE)\n  save_ps[i] &lt;- t_test$p.value\n  save_ts[i] &lt;- t_test$statistic\n}\n\n\n\n\nCode\nhist(save_ts)\n\n\n\n\n\n\n\n\nFigure 21: 1000 ts for n =100, when there is a true effect\n\n\n\n\n\n\n\nCode\nhist(save_ps)\n\n\nlength(save_ps[save_ps&lt;.05])\n\n\n[1] 40\n\n\nCode\nlength(save_ps[save_ps&lt;.05])/1000\n\n\n[1] 0.04\n\n\n\n\n\n\n\n\nFigure 22: 1000 ps for n =100, when there is a true effect\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGordon Original ## 1. Introduction\nThe t-test is a fundamental statistical method used in psychology to compare the means of two groups. This chapter will explore the theory behind t-tests, demonstrate practical applications using R, and provide a structured write-up in APA style. Whether you’re examining the effectiveness of a new therapy or comparing cognitive performance between groups, the t-test is an essential tool for psychological research.\n\n\n\n\n\n\nA t-test evaluates whether the means of two groups are statistically different from each other. The most common types are the independent samples t-test, paired samples t-test, and one-sample t-test. Each type tests different hypotheses and has unique assumptions.\n\n\nThis test compares the means of two independent groups to ascertain if there is statistical evidence that the associated population means are significantly different.\n\n\n\nThis test compares means from the same group at different times (e.g., before and after a treatment) or matched pairs.\n\n\n\nThis test determines whether the mean of a single group is different from a known mean.\n\n\n\n\n\nIndependence: Observations within each group must be independent.\nNormality: Data in each group should be approximately normally distributed.\nHomogeneity of Variance: Variances in the two groups should be roughly equal (for independent samples t-test).\n\n\n\n\n\nTo conduct a t-test, you need to: 1. Formulate the null (H0) and alternative (H1) hypotheses. 2. Collect and organize data. 3. Check assumptions. 4. Calculate the t-statistic and degrees of freedom. 5. Determine the p-value. 6. Make a decision to reject or fail to reject H0 based on the p-value.\n\n\nResearch Question: Does a new cognitive-behavioral therapy (CBT) improve anxiety levels more than a placebo?\nHypotheses: - H0: There is no difference in anxiety levels between the CBT and placebo groups. - H1: The CBT group has lower anxiety levels than the placebo group.\nMeasures: Anxiety levels are measured using a standardized anxiety inventory.\n\n\n\n\nLet’s use R for an independent samples t-test.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nThe t.test function provides the t-statistic, degrees of freedom, and p-value. If the p-value is less than the significance level (e.g., 0.05), we reject H0.\n    Welch Two Sample t-test\n\ndata:  anxiety by group\nt = -8.6943, df = 17.564, p-value = 8.922e-08\nalternative hypothesis: true difference in means between group CBT and group Placebo is not equal to 0\n95 percent confidence interval:\n -9.936595 -6.063405\nsample estimates:\n    mean in group CBT mean in group Placebo \n                 21.7                  29.7\n\n\n\n\n\n\nViolating assumptions (e.g., normality, homogeneity of variance) can lead to incorrect conclusions. Robust alternatives or data transformations may be necessary (Wilcox, 2012).\n\n\n\nOverreliance on p-values can lead to misinterpretation of results. It’s crucial to report effect sizes and confidence intervals (Cumming, 2014).\n\n\n\nConducting multiple t-tests increases the risk of Type I errors. Methods like Bonferroni correction adjust for this but can be overly conservative (Perneger, 1998).\n\n\n\n\nT-tests are a vital statistical method in psychological research for comparing means between groups. Understanding their theory, assumptions, and correct application in R can significantly enhance the rigor of your analyses. Always ensure to check assumptions, consider effect sizes, and be mindful of the limitations and debates surrounding t-tests.\n\n\nCumming, G. (2014). The new statistics: Why and how. Psychological Science, 25(1), 7-29.\nPerneger, T. V. (1998). What’s wrong with Bonferroni adjustments. BMJ, 316(7139), 1236-1238.\nWilcox, R. R. (2012). Modern statistics for the social and behavioral sciences: A practical introduction. CRC Press.\nThis chapter provides a comprehensive overview of conducting t-tests in R, essential for first-year psychology students. Future chapters will delve into more advanced statistical methods to further enhance your analytical skills.",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "T-Tests"
    ]
  },
  {
    "objectID": "week01/chapter.html#check-your-confidence-in-your-mean",
    "href": "week01/chapter.html#check-your-confidence-in-your-mean",
    "title": "T-Tests",
    "section": "",
    "text": "We’ve talked about getting a sample of data. We know we can find the mean, we know we can find the standard deviation. We know we can look at the data in a histogram. These are all useful things to do for us to learn something about the properties of our data.\nYou might be thinking of the mean and standard deviation as very different things that we would not put together. The mean is about central tendency (where most of the data is), and the standard deviation is about variance (where most of the data isn’t). Yes, they are different things, but we can use them together to create useful new things.\nWhat if I told you my sample mean was 50, and I told you nothing else about my sample. Would you be confident that most of the numbers were near 50? Would you wonder if there was a lot of variability in the sample, and many of the numbers were very different from 50. You should wonder all of those things. The mean alone, just by itself, doesn’t tell you anything about well the mean represents all of the numbers in the sample.\nIt could be a representative number, when the standard deviation is very small, and all the numbers are close to 50. It could be a non-representative number, when the standard deviation is large, and many of the numbers are not near 50. You need to know the standard deviation in order to be confident in how well the mean represents the data.\nHow can we put the mean and the standard deviation together, to give us a new number that tells us about confidence in the mean?\nWe can do this using a ratio:\n\\(\\frac{mean}{\\text{standard deviation}}\\)\nThink about what happens here. We are dividing a number by a number. Look at what happens:\n\\(\\frac{number}{\\text{same number}} = 1\\)\n\\(\\frac{number}{\\text{smaller number}} = \\text{big number}\\)\ncompared to:\n\\(\\frac{number}{\\text{bigger number}} = \\text{smaller number}\\)\nImagine we have a mean of 50, and a truly small standard deviation of 1. What do we get with our formula?\n\\(\\frac{50}{1} = 50\\)\nImagine we have a mean of 50, and a big standard deviation of 100. What do we get with our formula?\n\\(\\frac{50}{100} = 0.5\\)\nNotice, when we have a mean paired with a small standard deviation, our formula gives us a big number, like 50. When we have a mean paired with a large standard deviation, our formula gives us a small number, like 0.5. These numbers can tell us something about confidence in our mean, in a general way. We can be 50 confident in our mean in the first case, and only 0.5 (not at a lot) confident in the second case.\nWhat did we do here? We created a descriptive statistic by dividing the mean by the standard deviation. And, we have a sense of how to interpret this number, when it’s big we’re more confident that the mean represents all of the numbers, when it’s small we are less confident. This is a useful kind of number, a ratio between what we think about our sample (the mean), and the variability in our sample (the standard deviation). Get used to this idea. Almost everything that follows in this textbook is based on this kind of ratio. We will see that our ratio turns into different kinds of “statistics”, and the ratios will look like this in general:\n\\(\\text{name of statistic} = \\frac{\\text{measure of what we know}}{\\text{measure of what we don't know}}\\)\nor, to say it using different words:\n\\(\\text{name of statistic} = \\frac{\\text{measure of effect}}{\\text{measure of error}}\\)\nIn fact, this is the general formula for the t-test. Big surprise!",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "T-Tests"
    ]
  },
  {
    "objectID": "week01/chapter.html#one-sample-t-test-a-new-t-test",
    "href": "week01/chapter.html#one-sample-t-test-a-new-t-test",
    "title": "T-Tests",
    "section": "",
    "text": "Now we are ready to talk about t-test. We will talk about three of them. We start with the one-sample t-test.\nCommonly, the one-sample t-test is used to estimate the chances that your sample came from a particular population. Specifically, you might want to know whether the mean that you found from your sample, could have come from a particular population having a particular mean.\nStraight away, the one-sample t-test becomes a little confusing (and I haven’t even described it yet). Officially, it uses known parameters from the population, like the mean of the population and the standard deviation of the population. However, most times you don’t know those parameters of the population! So, you have to estimate them from your sample. Remember from the chapters on descriptive statistics and sampling, our sample mean is an unbiased estimate of the population mean. And, our sample standard deviation (the one where we divide by n-1) is an unbiased estimate of the population standard deviation. When Gosset developed the t-test, he recognized that he could use these estimates from his samples, to make the t-test. Here is the formula for the one sample t-test, we first use words, and then become more specific:\n\n\n\\(\\text{name of statistic} = \\frac{\\text{measure of effect}}{\\text{measure of error}}\\)\n\\(\\text{t} = \\frac{\\text{measure of effect}}{\\text{measure of error}}\\)\n\\(\\text{t} = \\frac{\\text{Mean difference}}{\\text{standard error}}\\)\n\\(\\text{t} = \\frac{\\bar{X}-u}{S_{\\bar{X}}}\\)\n\\(\\text{t} = \\frac{\\text{Sample Mean  - Population Mean}}{\\text{Sample Standard Error}}\\)\n\\(\\text{Estimated Standard Error} = \\text{Standard Error of Sample} = \\frac{s}{\\sqrt{N}}\\)\nWhere, s is the sample standard deviation.\nSome of you may have gone cross-eyed looking at all of this. Remember, we’ve seen it before when we divided our mean by the standard deviation in the first bit. The t-test is just a measure of a sample mean, divided by the standard error of the sample mean. That is it.\n\n\n\n\\(t\\) gives us a measure of confidence, just like our previous ratio for dividing the mean by a standard deviations. The only difference with \\(t\\), is that we divide by the standard error of mean (remember, this is also a standard deviation, it is the standard deviation of the sampling distribution of the mean)\n\n\n\n\n\n\nNote\n\n\n\nWhat does the t in t-test stand for? Apparently nothing. Gosset originally labelled it z. And, Fisher later called it t, perhaps because t comes after s, which is often used for the sample standard deviation.\n\n\n\\(t\\) is a property of the data that you collect. You compute it with a sample mean, and a sample standard error (there’s one more thing in the one-sample formula, the population mean, which we get to in a moment). This is why we call \\(t\\), a sample-statistic. It’s a statistic we compute from the sample.\nWhat kinds of numbers should we expect to find for these \\(ts\\)? How could we figure that out?\nLet’s start small and work through some examples. Imagine your sample mean is 5. You want to know if it came from a population that also has a mean of 5. In this case, what would \\(t\\) be? It would be zero: we first subtract the sample mean from the population mean, \\(5-5=0\\). Because the numerator is 0, \\(t\\) will be zero. So, \\(t\\) = 0, occurs, when there is no difference.\nLet’s say you take another sample, do you think the mean will be 5 every time, probably not. Let’s say the mean is 6. So, what can \\(t\\) be here? It will be a positive number, because 6-5= +1. But, will \\(t\\) be +1? That depends on the standard error of the sample. If the standard error of the sample is 1, then \\(t\\) could be 1, because 1/1 = 1.\nIf the sample standard error is smaller than 1, what happens to \\(t\\)? It get’s bigger right? For example, 1 divided by 0.5 = 2. If the sample standard error was 0.5, \\(t\\) would be 2. And, what could we do with this information? Well, it be like a measure of confidence. As \\(t\\) get’s bigger we could be more confident in the mean difference we are measuring.\nCan \\(t\\) be smaller than 1? Sure, it can. If the sample standard error is big, say like 2, then \\(t\\) will be smaller than one (in our case), e.g., 1/2 = .5. The direction of the difference between the sample mean and population mean, can also make the \\(t\\) become negative. What if our sample mean was 4. Well, then \\(t\\) will be negative, because the mean difference in the numerator will be negative, and the number in the bottom (denominator) will always be positive (remember why, it’s the standard error, computed from the sample standard deviation, which is always positive because of the squaring that we did.).\nSo, that is some intuitions about what the kinds of values t can take. \\(t\\) can be positive or negative, and big or small.\nLet’s do one more thing to build our intuitions about what \\(t\\) can look like. How about we sample some numbers and then measure the sample mean and the standard error of the mean, and then plot those two things against each each. This will show us how a sample mean typically varies with respect to the standard error of the mean.\nIn Figure 1, I pulled 1,000 samples of \\(N = 10\\) from a normal distribution (mean = 0, sd = 1). Each time I measured the mean and standard error of the sample. That gave two descriptive statistics for each sample, letting us plot each sample as dot in a scatter plot.\n\n\nCode\nlibrary(ggplot2)\n\n\n\n\nCode\nsample_mean &lt;- length(1000)\nsample_se &lt;- length(1000)\n\nfor (i in 1:1000) {\n  s &lt;- rnorm(10, 0, 1)\n  sample_mean[i] &lt;- mean(s)\n  sample_se[i] &lt;- sd(s) / sqrt(length(s))\n}\n\nplot(sample_mean, sample_se)\n\n\n\n\n\n\n\n\nFigure 1: A scatter plot with sample mean on the x-axis, and standard error of the mean on the y-axis\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nTake penguins, and then,\nadd new columns for the bill ratio and bill area.\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n1penguins |&gt;\n2  mutate(\n    bill_ratio = bill_depth_mm / bill_length_mm,\n    bill_area  = bill_depth_mm * bill_length_mm\n  )\n\n\n\n1\n\nTake penguins, and then,\n\n2\n\nadd new columns for the bill ratio and bill area.\n\n\n\n\n# A tibble: 344 × 10\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 4 more variables: sex &lt;fct&gt;, year &lt;int&gt;, bill_ratio &lt;dbl&gt;, bill_area &lt;dbl&gt;\n\n\n\n\nResultInteractive\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(palmerpenguins)\npenguins |&gt;                                      # &lt;1&gt;\n  mutate(                                        # &lt;2&gt;\n    bill_ratio = bill_depth_mm / bill_length_mm, # &lt;2&gt;\n    bill_area  = bill_depth_mm * bill_length_mm  # &lt;2&gt;\n  )         \n\n\n# A tibble: 344 × 10\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 4 more variables: sex &lt;fct&gt;, year &lt;int&gt;, bill_ratio &lt;dbl&gt;, bill_area &lt;dbl&gt;\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nWhat we get is a cloud of dots. You might notice the cloud has a circular quality. There’s more dots in the middle, and fewer dots as they radiate out from the middle. The dot cloud shows us the general range of the sample mean, for example most of the dots are in between -1 and 1. Similarly, the range for the sample standard error is roughly between .2 and .5. Remember, each dot represents one sample.\nWe can look at the same data a different way. For example, rather than using a scatter plot, we can divide the mean for each dot by the standard error for each dot. Figure 2 shows the result in a histogram.\n\n\nCode\nhist(sample_mean/sample_se, breaks=30)\n\n\n\n\n\n\n\n\nFigure 2: A histogram of the sample means divided by the sample standard errors, this is a t-distribution.\n\n\n\n\n\nInteresting, we can see the histogram is shaped like a normal curve. It is centered on 0, which is the most common value. As values become more extreme, they become less common. If you remember, our formula for \\(t\\), was the mean divided by the standard error of the mean. That’s what we did here. This histogram is showing you a \\(t\\)-distribution.\n\n\n\nLet’s briefly calculate a t-value from a small sample. Let’s say we had 10 students do a true/false quiz with 5 questions on it. There’s a 50% chance of getting each answer correct.\nEvery student completes the 5 questions, we grade them, and then we find their performance (mean percent correct). What we want to know is whether the students were guessing. If they were all guessing, then the sample mean should be about 50%, it shouldn’t be different from chance, which is 50%. Let’s look at Table 1.\n\n\n\n\nTable 1: Calculating the t-value for a one-sample test.\n\n\n\n\n\n\nstudents\nscores\nmean\nDifference_from_Mean\nSquared_Deviations\n\n\n\n\n1\n50\n61\n-11\n121\n\n\n2\n70\n61\n9\n81\n\n\n3\n60\n61\n-1\n1\n\n\n4\n40\n61\n-21\n441\n\n\n5\n80\n61\n19\n361\n\n\n6\n30\n61\n-31\n961\n\n\n7\n90\n61\n29\n841\n\n\n8\n60\n61\n-1\n1\n\n\n9\n70\n61\n9\n81\n\n\n10\n60\n61\n-1\n1\n\n\nSums\n610\n610\n0\n2890\n\n\nMeans\n61\n61\n0\n289\n\n\n\n\n\nsd\n17.92\n\n\n\n\n\nSEM\n5.67\n\n\n\n\n\nt\n1.94003527336861\n\n\n\n\n\n\n\n\nYou can see the scores column has all of the test scores for each of the 10 students. We did the things we need to do to compute the standard deviation.\nRemember the sample standard deviation is the square root of the sample variance, or:\n\\(\\text{sample standard deviation} = \\sqrt{\\frac{\\sum_{i}^{n}({x_{i}-\\bar{x})^2}}{N-1}}\\)\n\\(\\text{sd} = \\sqrt{\\frac{2890}{10-1}} = 17.92\\)\nThe standard error of the mean, is the standard deviation divided by the square root of N\n\\(\\text{SEM} = \\frac{s}{\\sqrt{N}} = \\frac{17.92}{10} = 5.67\\)\n\\(t\\) is the difference between our sample mean (61), and our population mean (50, assuming chance), divided by the standard error of the mean.\n\\(\\text{t} = \\frac{\\bar{X}-u}{S_{\\bar{X}}} = \\frac{\\bar{X}-u}{SEM} = \\frac{61-50}{5.67} = 1.94\\)\nAnd, that is you how calculate \\(t\\), by hand. It’s a pain. I was annoyed doing it this way. In the lab, you learn how to calculate \\(t\\) using software, so it will just spit out \\(t\\). For example in R, all you have to do is this:\n\n\nCode\nt.test(scores, mu=50)\n\n\n\n    One Sample t-test\n\ndata:  scores\nt = 1.9412, df = 9, p-value = 0.08415\nalternative hypothesis: true mean is not equal to 50\n95 percent confidence interval:\n 48.18111 73.81889\nsample estimates:\nmean of x \n       61 \n\n\n\n\n\nIf \\(t\\) is just a number that we can compute from our sample (it is), what can we do with it? How can we use \\(t\\) for statistical inference?\nRemember back to the chapter on sampling and distributions, that’s where we discussed the sampling distribution of the sample mean. Remember, we made a lot of samples, then computed the mean for each sample, then we plotted a histogram of the sample means. Later, in that same section, we mentioned that we could generate sampling distributions for any statistic. For each sample, we could compute the mean, the standard deviation, the standard error, and now even \\(t\\), if we wanted to. We could generate 10,000 samples, and draw four histograms, one for each sampling distribution for each statistic.\nThis is exactly what I did, and the results are shown in the four panels of Figure 3 below. I used a sample size of 20, and drew random observations for each sample from a normal distribution, with mean = 0, and standard deviation = 1. Let’s look at the sampling distributions for each of the statistics. \\(t\\) was computed assuming with the population mean assumed to be 0.\n\n\nCode\nall_df &lt;- data.frame()\nfor (i in 1:10000) {\n  sample &lt;- rnorm(20, 0, 1)\n  sample_mean &lt;- mean(sample)\n  sample_sd &lt;- sd(sample)\n  sample_se &lt;- sd(sample) / sqrt(length(sample))\n  sample_t &lt;- as.numeric(t.test(sample, mu = 0)$statistic)\n  t_df &lt;- data.frame(i, sample_mean, sample_sd, sample_se, sample_t)\n  all_df &lt;- rbind(all_df, t_df)\n}\n\nlibrary(ggpubr)\na &lt;- ggplot(all_df, aes(x = sample_mean)) +\n  geom_histogram(color = \"white\") +\n  theme_classic(base_size=20)\nb &lt;- ggplot(all_df, aes(x = sample_sd)) +\n  geom_histogram(color = \"white\") +\n  theme_classic(base_size=20)\nc &lt;- ggplot(all_df, aes(x = sample_se)) +\n  geom_histogram(color = \"white\") +\n  theme_classic(base_size=20)\nd &lt;- ggplot(all_df, aes(x = sample_t)) +\n  geom_histogram(color = \"white\") +\n  theme_classic(base_size=20)\n\nggarrange(a, b, c, d,\n          ncol = 2, nrow = 2)\n\n\n\n\n\n\n\n\nFigure 3: Sampling distributions for the mean, standard deviation, standard error of the mean, and \\(t\\).\n\n\n\n\n\nWe see four sampling distributions. This is how statistical summaries of these summaries behave. We have used the word chance windows before. These are four chance windows, measuring different aspects of the sample. In this case, all of the samples came from the same normal distribution. Because of sampling error, each sample is not identical. The means are not identical, the standard deviations are not identical, sample standard error of the means are not identical, and the \\(t\\)s of the samples are not identical. They all have some variation, as shown by the histograms. This is how samples of size 20 behave.\nWe can see straight away, that in this case, we are unlikely to get a sample mean of 2. That’s way outside the window. The range for the sampling distribution of the mean is around -.5 to +.5, and is centered on 0 (the population mean, would you believe!).\nWe are unlikely to get sample standard deviations of between .6 and 1.5, that is a different range, specific to the sample standard deviation.\nSame thing with the sample standard error of the mean, the range here is even smaller, mostly between .1, and .3. You would rarely find a sample with a standard error of the mean greater than .3. Virtually never would you find one of say 1 (for this situation).\nNow, look at \\(t\\). It’s range is basically between -3 and +3 here. 3s barely happen at all. You pretty much never see a 5 or -5 in this situation.\nAll of these sampling windows are chance windows, and they can all be used in the same way as we have used similar sampling distributions before (e.g., Crump Test, and Randomization Test) for statistical inference. For all of them we would follow the same process:\n\nGenerate these distributions\nLook at your sample statistics for the data you have (mean, SD, SEM, and \\(t\\))\nFind the likelihood of obtaining that value or greater\nObtain that probability\nSee if you think your sample statistics were probable or improbable.\n\nWe’ll formalize this in a second. I just want you to know that what you will be doing is something that you have already done before. For example, in the Crump test and the Randomization test we focused on the distribution of mean differences. We could do that again here, but instead, we will focus on the distribution of \\(t\\) values. We then apply the same kinds of decision rules to the \\(t\\) distribution, as we did for the other distributions. Below you will see a graph you have already seen, except this time it is a distribution of \\(t\\)s, not mean differences:\nRemember, if we obtained a single \\(t\\) from one sample we collected, we could consult the chance window in Figure 4 below to find out whether the \\(t\\) we obtained from the sample was likely or unlikely to occur by chance.\n\n\nCode\nsample_t &lt;- all_df$sample_t\n\nggplot(all_df, aes(x = sample_t)) +\n  annotate(\n    \"rect\",\n    xmin = min(sample_t),\n    xmax = max(sample_t),\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.5,\n    fill = \"red\"\n  ) +\n  annotate(\n    \"rect\",\n    xmin = min(sample_t),\n    xmax = -1.94,\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.7,\n    fill = \"light grey\"\n  ) +\n  annotate(\n    \"rect\",\n    xmin = 1.94,\n    xmax = max(sample_t),\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.7,\n    fill = \"light grey\"\n  ) +\n  geom_rect(aes(\n    xmin = -Inf,\n    xmax = min(sample_t),\n    ymin = 0,\n    ymax = Inf\n  ),\n  alpha = .5,\n  fill = \"lightgreen\") +\n  geom_rect(aes(\n    xmin = max(sample_t),\n    xmax = Inf,\n    ymin = 0,\n    ymax = Inf\n  ),\n  alpha = .5,\n  fill = \"lightgreen\") +\n  geom_histogram(bins = 50, color = \"white\") +\n  theme_classic() +\n  geom_vline(xintercept = min(sample_t)) +\n  geom_vline(xintercept = max(sample_t)) +\n  geom_vline(xintercept = -1.94) +\n  geom_vline(xintercept = 1.94) +\n  xlim(-8, 8) +\n  geom_label(data = data.frame(x = 0, y = 250, label = \"CHANCE\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = -7, y = 250, label = \"NOT \\n CHANCE\"),\n             aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = 7, y = 250, label = \"NOT \\n CHANCE\"),\n             aes(x = x, y = y, label = label)) +\n  #  geom_label(data = data.frame(x = min(sample_t), y = 600,\n  #                              label = paste0(\"min \\n\",round(min(sample_t)))),\n  #                             aes(x = x, y = y, label = label))+\n  #geom_label(data = data.frame(x = max(sample_t), y = 600,\n  #                            label = paste0(\"max \\n\",round(max(sample_t)))),\n  #                           aes(x = x, y = y, label = label))+\n  geom_label(data = data.frame(x = -4, y = 250,\n                               label = \"?\"),\n             aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = 4, y = 250,\n                               label = \"?\"),\n             aes(x = x, y = y, label = label)) +\n  xlab(\"mean sample_t\")\n\n\n\n\n\n\n\n\nFigure 4: Applying decision criteria to the \\(t\\)-distribution. Histogram of \\(t\\)s from samples (n=20) drawn from the same normal distribution (u=0, sd=1)\n\n\n\n\n\n\n\n\nFrom our early example involving the TRUE/FALSE quizzes, we are now ready to make some kind of decision about what happened there. We found a mean difference of 11. We found a \\(t\\) = 1.9411765. The probability of this \\(t\\) or larger occurring is \\(p\\) = 0.0841503. We were testing the idea that our sample mean of 61 could have come from a normal distribution with mean = 50. The \\(t\\) test tells us that the \\(t\\) for our sample, or a larger one, would happen with p = 0.0841503. In other words, chance can do it a kind of small amount of time, but not often. In English, this means that all of the students could have been guessing, but it wasn’t that likely that were just guessing.\nThe next \\(t\\)-test is called a paired samples t-test. And, spoiler alert, we will find out that a paired samples t-test is actually a one-sample t-test in disguise (WHAT!), yes it is. If the one-sample \\(t\\)-test didn’t make sense to you, read the next section.",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "T-Tests"
    ]
  },
  {
    "objectID": "week01/chapter.html#paired-samples-t-test",
    "href": "week01/chapter.html#paired-samples-t-test",
    "title": "T-Tests",
    "section": "",
    "text": "For me (Crump), many analyses often boil down to a paired samples t-test. It just happens that many things I do reduce down to a test like this.\nI am a cognitive psychologist, I conduct research about how people do things like remember, pay attention, and learn skills. There are lots of Psychologists like me, who do very similar things.\nWe all often conduct the same kinds of experiments. They go like this, and they are called repeated measures designs. They are called repeated measures designs, because we measure how one person does something more than once, we repeat the measure.\nSo, I might measure somebody doing something in condition A, and measure the same person doing something in Condition B, and then I see that same person does different things in the two conditions. I repeatedly measure the same person in both conditions. I am interested in whether the experimental manipulation changes something about how people perform the task in question.\n\n\nWe will introduce the paired-samples t-test with an example using real data, from a real study. (mehr20165?) were interested in whether singing songs to infants helps infants become more sensitive to social cues. For example, infants might need to learn to direct their attention toward people as a part of learning how to interact socially with people. Perhaps singing songs to infants aids this process of directing attention. When an infant hears a familiar song, they might start to pay more attention to the person singing that song, even after they are done singing the song. The person who sang the song might become more socially important to the infant. You will learn more about this study in the lab for this week. This example, prepares you for the lab activities. Here is a brief summary of what they did.\nFirst, parents were trained to sing a song to their infants. After many days of singing this song to the infants, a parent came into the lab with their infant. In the first session, parents sat with their infants on their knees, so the infant could watch two video presentations. There were two videos. Each video involved two unfamiliar new people the infant had never seen before. Each new person in the video (the singers) sang one song to the infant. One singer sang the “familiar” song the infant had learned from their parents. The other singer sang an “unfamiliar” song the infant had not hear before.\nThere were two really important measurement phases: the baseline phase, and the test phase.\nThe baseline phase occurred before the infants saw and heard each singer sing a song. During the baseline phase, the infants watched a video of both singers at the same time. The researchers recorded the proportion of time that the infant looked at each singer. The baseline phase was conducted to determine whether infants had a preference to look at either person (who would later sing them a song).\nThe test phase occurred after infants saw and heard each song, sung by each singer. During the test phase, each infant had an opportunity to watch silent videos of both singers. The researchers measured the proportion of time the infants spent looking at each person. The question of interest, was whether the infants would spend a greater proportion of time looking at the singer who sang the familiar song, compared to the singer who sang the unfamiliar song.\nThere is more than one way to describe the design of this study. We will describe it like this. It was a repeated measures design, with one independent (manipulation) variable called Viewing phase: Baseline versus Test. There was one dependent variable (the measurement), which was proportion looking time (to singer who sung familiar song). This was a repeated measures design because the researchers measured proportion looking time twice (they repeated the measure), once during baseline (before infants heard each singer sing a song), and again during test (after infants head each singer sing a song).\nThe important question was whether infants would change their looking time, and look more at the singer who sang the familiar song during the test phase, than they did during the baseline phase. This is a question about a change within individual infants. In general, the possible outcomes for the study are:\n\nNo change: The difference between looking time toward the singer of the familiar song during baseline and test is zero, no difference.\nPositive change: Infants will look longer toward the singer of the familiar song during the test phase (after they saw and heard the singers), compared to the baseline phase (before they saw and heard the singers). This is a positive difference if we use the formula: Test Phase Looking time - Baseline phase looking time (to familiar song singer).\nNegative change: Infants will look longer toward the singer of the unfamiliar song during the test phase (after they saw and heard the singers), compared to the baseline phase (before they saw and heard the singers). This is a negative difference if we use the same formula: Test Phase Looking time - Baseline phase looking time (to familiar song singer).\n\n\n\n\nLet’s take a look at the data for the first 5 infants in the study. This will help us better understand some properties of the data before we analyze it. We will see that the data is structured in a particular way that we can take advantage of with a paired samples t-test. Note, we look at the first 5 infants to show how the computations work. The results of the paired-samples t-test change when we use all of the data from the study.\nHere is a table of the data:\n\n\n\n\n\ninfant\nBaseline\nTest\n\n\n\n\n1\n0.44\n0.60\n\n\n2\n0.41\n0.68\n\n\n3\n0.75\n0.72\n\n\n4\n0.44\n0.28\n\n\n5\n0.47\n0.50\n\n\n\n\n\nThe table shows proportion looking times toward the singer of the familiar song during the Baseline and Test phases. Notice there are five different infants, (1 to 5). Each infant is measured twice, once during the Baseline phase, and once during the Test phase. To repeat from before, this is a repeated-measures design, because the infants are measured repeatedly (twice in this case). Or, this kind of design is also called a paired-samples design. Why? because each participant comes with a pair of samples (two samples), one for each level of the design.\nGreat, so what are we really interested in here? We want to know if the mean looking time toward the singer of the familiar song for the Test phase is higher than the Baseline phase. We are comparing the two sample means against each other and looking for a difference. We already know that differences could be obtained by chance alone, simply because we took two sets of samples, and we know that samples can be different. So, we are interested in knowing whether chance was likely or unlikely to have produced any difference we might observe.\nIn other words, we are interested in looking at the difference scores between the baseline and test phase for each infant. The question here is, for each infant, did their proportion looking time to the singer of the familiar song, increase during the test phase as compared to the baseline phase.\n\n\n\nLet’s add the difference scores to the table of data so it is easier to see what we are talking about. The first step in creating difference scores is to decide how you will take the difference, there are two options:\n\nTest phase score - Baseline Phase Score\nBaseline phase score - Test Phase score\n\nLet’s use the first formula. Why? Because it will give us positive differences when the test phase score is higher than the baseline phase score. This makes a positive score meaningful with respect to the study design, we know (because we defined it to be this way), that positive scores will refer to longer proportion looking times (to singer of familiar song) during the test phase compared to the baseline phase.\n\n\nCode\npaired_sample_df &lt;- cbind(paired_sample_df, \n                          differences = (paired_sample_df$Test-\n                                           paired_sample_df$Baseline))\nknitr::kable(paired_sample_df)\n\n\n\n\n\ninfant\nBaseline\nTest\ndifferences\n\n\n\n\n1\n0.44\n0.60\n0.16\n\n\n2\n0.41\n0.68\n0.27\n\n\n3\n0.75\n0.72\n-0.03\n\n\n4\n0.44\n0.28\n-0.16\n\n\n5\n0.47\n0.50\n0.03\n\n\n\n\n\nThere we have it, the difference scores. The first thing we can do here is look at the difference scores, and ask how many infants showed the effect of interest. Specifically, how many infants showed a positive difference score. We can see that three of five infants showed a positive difference (they looked more at the singer of the familiar song during the test than baseline phase), and two the infants showed the opposite effect (negative difference, they looked more at the singer of the familiar song during baseline than test).\n\n\n\nAs we have been discussing, the effect of interest in this study is the mean difference between the baseline and test phase proportion looking times. We can calculate the mean difference, by finding the mean of the difference scores. Let’s do that, in fact, for fun let’s calculate the mean of the baseline scores, the test scores, and the difference scores.\n\n\nCode\npaired_sample_df &lt;- paired_sample_df %&gt;%\n   rbind(c(\"Sums\",colSums(paired_sample_df[1:5,2:4]))) %&gt;%\n   rbind(c(\"Means\",colMeans(paired_sample_df[1:5,2:4])))\n  \nknitr::kable(paired_sample_df)\n\n\n\n\n\ninfant\nBaseline\nTest\ndifferences\n\n\n\n\n1\n0.44\n0.6\n0.16\n\n\n2\n0.41\n0.68\n0.27\n\n\n3\n0.75\n0.72\n-0.03\n\n\n4\n0.44\n0.28\n-0.16\n\n\n5\n0.47\n0.5\n0.03\n\n\nSums\n2.51\n2.78\n0.27\n\n\nMeans\n0.502\n0.556\n0.054\n\n\n\n\n\nWe can see there was a positive mean difference of 0.054, between the test and baseline phases.\nCan we rush to judgment and conclude that infants are more socially attracted to individuals who have sung them a familiar song? I would hope not based on this very small sample. First, the difference in proportion looking isn’t very large, and of course we recognize that this difference could have been produced by chance.\nWe will more formally evaluate whether this difference could have been caused by chance with the paired-samples t-test. But, before we do that, let’s again calculate \\(t\\) and discuss what \\(t\\) tells us over and above what our measure of the mean of the difference scores tells us.\n\n\n\nOK, so how do we calculate \\(t\\) for a paired-samples \\(t\\)-test? Surprise, we use the one-sample t-test formula that you already learned about! Specifically, we use the one-sample \\(t\\)-test formula on the difference scores. We have one sample of difference scores (you can see they are in one column), so we can use the one-sample \\(t\\)-test on the difference scores. Specifically, we are interested in comparing whether the mean of our difference scores came from a distribution with mean difference = 0. This is a special distribution we refer to as the null distribution. It is the distribution no differences. Of course, this null distribution can produce differences due to to sampling error, but those differences are not caused by any experimental manipulation, they caused by the random sampling process.\nWe calculate \\(t\\) in a moment. Let’s now consider again why we want to calculate \\(t\\)? Why don’t we just stick with the mean difference we already have?\nRemember, the whole concept behind \\(t\\), is that it gives an indication of how confident we should be in our mean. Remember, \\(t\\) involves a measure of the mean in the numerator, divided by a measure of variation (standard error of the sample mean) in the denominator. The resulting \\(t\\) value is small when the mean difference is small, or when the variation is large. So small \\(t\\)-values tell us that we shouldn’t be that confident in the estimate of our mean difference. Large \\(t\\)-values occur when the mean difference is large and/or when the measure of variation is small. So, large \\(t\\)-values tell us that we can be more confident in the estimate of our mean difference. Let’s find \\(t\\) for the mean difference scores. We use the same formulas as we did last time:\n\n\n\n\n\n\n\n\n\n\n\n\n\ninfant\nBaseline\nTest\ndifferences\ndiff_from_mean\nSquared_differences\n\n\n\n\n1\n0.44\n0.6\n0.16\n0.106\n0.011236\n\n\n2\n0.41\n0.68\n0.27\n0.216\n0.046656\n\n\n3\n0.75\n0.72\n-0.03\n-0.084\n0.00705600000000001\n\n\n4\n0.44\n0.28\n-0.16\n-0.214\n0.045796\n\n\n5\n0.47\n0.5\n0.03\n-0.024\n0.000575999999999999\n\n\nSums\n2.51\n2.78\n0.27\n0\n0.11132\n\n\nMeans\n0.502\n0.556\n0.054\n0\n0.022264\n\n\n\n\n\n\nsd\n0.167\n\n\n\n\n\n\nSEM\n0.075\n\n\n\n\n\n\nt\n0.72\n\n\n\n\n\nIf we did this test using R, we would obtain almost the same numbers (there is a little bit of rounding in the table).\n\n\nCode\nt.test(differences,mu=0)\n\n\n\n    One Sample t-test\n\ndata:  differences\nt = 0.72381, df = 4, p-value = 0.5092\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -0.1531384  0.2611384\nsample estimates:\nmean of x \n    0.054 \n\n\nHere is a quick write up of our t-test results, t(4) = .72, p = .509.\nWhat does all of that tell us? There’s a few things we haven’t gotten into much yet. For example, the 4 represents degrees of freedom, which we discuss later. The important part, the \\(t\\) value should start to be a little bit more meaningful. We got a kind of small t-value didn’t we. It’s .72. What can we tell from this value? First, it is positive, so we know the mean difference is positive. The sign of the \\(t\\)-value is always the same as the sign of the mean difference (ours was +0.054). We can also see that the p-value was .509. We’ve seen p-values before. This tells us that our \\(t\\) value or larger, occurs about 50.9% of the time… Actually it means more than this. And, to understand it, we need to talk about the concept of two-tailed and one-tailed tests.\n\n\n\nRemember what it is we are doing here. We are evaluating whether our sample data could have come from a particular kind of distribution. The null distribution of no differences. This is the distribution of \\(t\\)-values that would occur for samples of size 5, with a mean difference of 0, and a standard error of the sample mean of .075 (this is the SEM that we calculated from our sample). We can see what this particular null-distribution looks like in Figure 5.\n\n\nCode\nrange &lt;- seq(-3, 3, .1)\nnull_distribution &lt;- dt(range, 4, log = FALSE)\nplot_df &lt;- data.frame(range, null_distribution)\n\nggplot(plot_df, aes(x = range, y = null_distribution)) +\n  geom_line() +\n  xlab(\"t-values\") +\n  ylab(\"Probability\") +\n  theme(axis.text.y = element_blank(), axis.ticks = element_blank()) +\n  scale_x_continuous(breaks = (seq(-3, 3, .5))) +\n  geom_label(data = data.frame(x = -.7, y = .1, label = \"50% \\n (-)\"),\n             aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = .7, y = .1, label = \"50% \\n (+)\"), aes(x = x, y = y, label = label)) +\n  geom_vline(xintercept = 0)+\n  theme_classic(base_size = 20)\n\n\n\n\n\n\n\n\nFigure 5: A distribution of \\(t\\)-values that can occur by chance alone, when there is no difference between the sample and a population\n\n\n\n\n\nThe \\(t\\)-distribution above shows us the kinds of values \\(t\\) will will take by chance alone, when we measure the mean differences for pairs of 5 samples (like our current). \\(t\\) is most likely to be zero, which is good, because we are looking at the distribution of no-differences, which should most often be 0! But, sometimes, due to sampling error, we can get \\(t\\)s that are bigger than 0, either in the positive or negative direction. Notice the distribution is symmetrical, a \\(t\\) from the null-distribution will be positive half of the time, and negative half of the time, that is what we would expect by chance.\nSo, what kind of information do we want know when we find a particular \\(t\\) value from our sample? We want to know how likely the \\(t\\) value like the one we found occurs just by chance. This is actually a subtly nuanced kind of question. For example, any particular \\(t\\) value doesn’t have a specific probability of occurring. When we talk about probabilities, we are talking about ranges of probabilities. Let’s consider some probabilities. We will use the letter \\(p\\), to talk about the probabilities of particular \\(t\\) values.\n\nWhat is the probability that \\(t\\) is zero or positive or negative? The answer is p=1, or 100%. We will always have a \\(t\\) value that is zero or non-zero…Actually, if we can’t compute the t-value, for example when the standard deviation is undefined, I guess then we would have a non-number. But, assuming we can calculate \\(t\\), then it will always be 0 or positive or negative.\nWhat is the probability of \\(t\\) = 0 or greater than 0? The answer is p=.5, or 50%. 50% of \\(t\\)-values are 0 or greater.\nWhat is the of \\(t\\) = 0 or smaller than 0? The answer is p=.5, or 50%. 50% of \\(t\\)-values are 0 or smaller.\n\nWe can answer all of those questions just by looking at our t-distribution, and dividing it into two equal regions, the left side (containing 50% of the \\(t\\) values), and the right side containing 50% of the \\(t\\)-values).\nWhat if we wanted to take a more fine-grained approach, let’s say we were interested in regions of 10%. What kinds of \\(t\\)s occur 10% of the time. We would apply lines like the following. Notice, the likelihood of bigger numbers (positive or negative) gets smaller, so we have to increase the width of the bars for each of the intervals between the bars to contain 10% of the \\(t\\)-values, it looks like Figure 6.\n\n\nCode\nrange &lt;- seq(-3, 3, .1)\nnull_distribution &lt;- dt(range, 4, log = FALSE)\nplot_df &lt;- data.frame(range, null_distribution)\n\nt_ps &lt;- qt(seq(.1, .9, .1), 4)\n\nggplot(plot_df, aes(x = range, y = null_distribution)) +\n  geom_line() +\n  xlab(\"t-values\") +\n  ylab(\"Probability\") +\n  geom_vline(xintercept = t_ps) +\n  theme_classic(base_size = 15) +\n  theme(axis.text.y = element_blank(), axis.ticks = element_blank()) +\n  scale_x_continuous(breaks = round(t_ps, digits = 1)) +\n  geom_label(data = data.frame(x = -2.5, y = .2, label = \"10%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = -1.3, y = .2, label = \"10%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = 2.5, y = .2, label = \"10%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = 1.3, y = .2, label = \"10%\"), aes(x = x, y = y, label = label))\n\n\n\n\n\n\n\n\nFigure 6: Splitting the t distribution up into regions each containing 10% of the \\(t\\)-values. The width between the bars narrows as they approach the center of the distribution, where there are more \\(t\\)-values.\n\n\n\n\n\nConsider the probabilities (\\(p\\)) of \\(t\\) for the different ranges.\n\n\\(t\\) &lt;= -1.5 (\\(t\\) is less than or equal to -1.5), \\(p\\) = 10%\n-1.5 &gt;= \\(t\\) &lt;= -0.9 (\\(t\\) is equal to or between -1.5 and -.9), \\(p\\) = 10%\n-.9 &gt;= \\(t\\) &lt;= -0.6 (\\(t\\) is equal to or between -.9 and -.6), \\(p\\) = 10%\n\\(t\\) &gt;= 1.5 (\\(t\\) is greater than or equal to 1.5), \\(p\\) = 10%\n\nNotice, that the \\(p\\)s are always 10%. \\(t\\)s occur in these ranges with 10% probability.\n\n\n\nYou might be wondering where I am getting some of these values from. For example, how do I know that 10% of \\(t\\) values (for this null distribution) have a value of approximately 1.5 or greater than 1.5? The answer is I used R to tell me.\nIn most statistics textbooks the answer would be: there is a table at the back of the book where you can look these things up…This textbook has no such table. We could make one for you. And, we might do that. But, we didn’t do that yet…\nSo, where do these values come from, how can you figure out what they are? The complicated answer is that we are not going to explain the math behind finding these values because, 1) the authors (some of us) admittedly don’t know the math well enough to explain it, and 2) it would sidetrack us to much, 3) you will learn how to get these numbers in the lab with software, 4) you will learn how to get these numbers in lab without the math, just by doing a simulation, and 5) you can do it in R, or excel, or you can use an online calculator.\nThis is all to say that you can find the \\(t\\)s and their associated \\(p\\)s using software. But, the software won’t tell you what these values mean. That’s we are doing here. You will also see that software wants to know a few more things from you, such as the degrees of freedom for the test, and whether the test is one-tailed or two tailed. We haven’t explained any of these things yet. That’s what we are going to do now. Note, we explain degrees of freedom last. First, we start with a one-tailed test.\n\n\n\nA one-tailed test is sometimes also called a directional test. It is called a directional test, because a researcher might have a hypothesis in mind suggesting that the difference they observe in their means is going to have a particular direction, either a positive difference, or a negative difference.\nTypically, a researcher would set an alpha criterion. The alpha criterion describes a line in the sand for the researcher. Often, the alpha criterion is set at \\(p = .05\\). What does this mean? Figure 7 shows the \\(t\\)-distribution and the alpha criterion.\n\n\nCode\nrange &lt;- seq(-3, 3, .1)\nnull_distribution &lt;- dt(range, 4, log = FALSE)\nplot_df &lt;- data.frame(range, null_distribution)\n\nt_ps &lt;- qt(seq(.1, .9, .1), 4)\n\nggplot(plot_df, aes(x = range, y = null_distribution)) +\n  geom_line() +\n  xlab(\"t-values\") +\n  ylab(\"Probability\") +\n  geom_vline(xintercept = qt(.95, 4, lower.tail = TRUE)) +\n  ggtitle(\"Critical t for one-tailed test\") +\n  theme_classic(base_size = 10) +\n  theme(axis.text.y = element_blank(), axis.ticks = element_blank()) +\n  annotate(\n    \"rect\",\n    xmin = qt(.95, 4, lower.tail = TRUE),\n    xmax = 3,\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.5,\n    fill = \"green\"\n  ) +\n  geom_label(data = data.frame(x = 2.5, y = .2, label = \"5%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.95, 4, lower.tail = TRUE),\n    y = .3,\n    label = \"Critical t\"\n  ),\n  aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.95, 4, lower.tail = TRUE),\n    y = .25,\n    label = round(qt(.95, 4, lower.tail = TRUE), digits =\n                    2)\n  ),\n  aes(x = x, y = y, label = label))\n\n\n\n\n\n\n\n\nFigure 7: The critical value of t for an alpha criterion of 0.05. 5% of all ts are at this value or larger\n\n\n\n\n\nThe figure shows that \\(t\\) values of +2.13 or greater occur 5% of the time. Because the t-distribution is symmetrical, we also know that \\(t\\) values of -2.13 or smaller also occur 5% of the time. Both of these properties are true under the null distribution of no differences. This means, that when there really are no differences, a researcher can expect to find \\(t\\) values of 2.13 or larger 5% of the time.\nLet’s review and connect some of the terms:\n\nalpha criterion: the criterion set by the researcher to make decisions about whether they believe chance did or did not cause the difference. The alpha criterion here is set to \\(p = .05\\).\nCritical \\(t\\). The critical \\(t\\) is the \\(t\\)-value associated with the alpha-criterion. In this case for a one-tailed test, it is the \\(t\\) value where 5% of all \\(t\\)s are this number or greater. In our example, the critical \\(t\\) is 2.13. 5% of all \\(t\\) values (with degrees of freedom = 4) are +2.13, or greater than +2.13.\nObserved \\(t\\). The observed \\(t\\) is the one that you calculated from your sample. In our example about the infants, the observed \\(t\\) was \\(t\\) (4) = 0.72.\np-value. The \\(p\\)-value is the probability of obtaining the observed \\(t\\) value or larger. Now, you could look back at our previous example, and find that the \\(p\\)-value for \\(t\\) (4) = .72, was \\(p = .509\\) . HOWEVER, this p-value was not calculated for a one-directional test…(we talk about what .509 means in the next section).\n\nFigure 8 shows what the \\(p\\)-value for \\(t\\) (4) = .72 using a one-directional test would would look like:\n\n\nCode\nrange &lt;- seq(-3, 3, .1)\nnull_distribution &lt;- dt(range, 4, log = FALSE)\nplot_df &lt;- data.frame(range, null_distribution)\n\nt_ps &lt;- qt(seq(.1, .9, .1), 4)\n\nggplot(plot_df, aes(x = range, y = null_distribution)) +\n  geom_line() +\n  xlab(\"t-values\") +\n  ylab(\"Probability\") +\n  geom_vline(xintercept = .72) +\n  geom_vline(xintercept = qt(.95, 4, lower.tail = TRUE)) +\n  ggtitle(\"t value and p-range for one-directional test\") +\n  theme_classic(base_size = 10) +\n  theme(axis.text.y = element_blank(), axis.ticks = element_blank()) +\n  annotate(\n    \"rect\",\n    xmin = .72,\n    xmax = 3,\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.5,\n    fill = \"grey\"\n  ) +\n  annotate(\n    \"rect\",\n    xmin = qt(.95, 4, lower.tail = TRUE),\n    xmax = 3,\n    ymin = 0,\n    ymax = .25,\n    alpha = 0.5,\n    fill = \"green\"\n  ) +\n  geom_label(data = data.frame(x = 2.5, y = .2, label = \"5%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.95, 4, lower.tail = TRUE),\n    y = .3,\n    label = \"Critical t\"\n  ),\n  aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.95, 4, lower.tail = TRUE),\n    y = .25,\n    label = round(qt(.95, 4, lower.tail = TRUE), digits =\n                    2)\n  ),\n  aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = .72, y = .1,\n                               label = \"Observed t\"),\n             aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(x = .72, y = .05,\n                               label = \".72, p=\"),\n             aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = 1.5,\n    y = .05,\n    label = round(pt(.72, 4, lower.tail = FALSE), digits =\n                    3)\n  ),\n  aes(x = x, y = y, label = label))\n\n\n\n\n\n\n\n\nFigure 8: A case where the observed value of t is much less than the critical value for a one-directional t-test.\n\n\n\n\n\nLet’s take this one step at a time. We have located the observed \\(t\\) of .72 on the graph. We shaded the right region all grey. What we see is that the grey region represents .256 or 25.6% of all \\(t\\) values. In other words, 25.6% of \\(t\\) values are .72 or larger than .72. You could expect, by chance alone, to a find a \\(t\\) value of .72 or larger, 25.6% of the time. That’s fairly often. We did find a \\(t\\) value of .72. Now that you know this kind of \\(t\\) value or larger occurs 25.6% of the time, would you be confident that the mean difference was not due to chance? Probably not, given that chance can produce this difference fairly often.\nFollowing the “standard” decision making procedure, we would claim that our \\(t\\) value was not statistically significant, because it was not large enough. If our observed value was larger than the critical \\(t\\) (larger than 2.13), defined by our alpha criterion, then we would claim that our \\(t\\) value was statistically significant. This would be equivalent to saying that we believe it is unlikely that the difference we observed was due to chance. In general, for any observed \\(t\\) value, the associated \\(p\\)-value tells you how likely a \\(t\\) of the observed size or larger would be observed. The \\(p\\)-value always refers to a range of \\(t\\)-values, never to a single \\(t\\)-value. Researchers use the alpha criterion of .05, as a matter of convenience and convention. There are other ways to interpret these values that do not rely on a strict (significant versus not) dichotomy.\n\n\n\nOK, so that was one-tailed tests… What are two tailed tests? The \\(p\\)-value that we originally calculated from our paired-samples \\(t\\)-test was for a 2-tailed test. Often, the default is that the \\(p\\)-value is for a two-tailed test.\nThe two-tailed test, is asking a more general question about whether a difference is likely to have been produced by chance. The question is: what is probability of any difference. It is also called a non-directional test, because here we don’t care about the direction or sign of the difference (positive or negative), we just care if there is any kind of difference.\nThe same basic things as before are involved. We define an alpha criterion (\\(\\alpha = 0.05\\)). And, we say that any observed \\(t\\) value that has a probability of \\(p\\) &lt;.05 (\\(p\\) is less than .05) will be called statistically significant, and ones that are more likely (\\(p\\) &gt;.05, \\(p\\) is greater than .05) will be called null-results, or not statistically significant. The only difference is how we draw the alpha range. Before it was on the right side of the \\(t\\) distribution (we were conducting a one-sided test remember, so we were only interested in one side).\nFigure 9 shows what the most extreme 5% of the \\(t\\)-values are when we ignore their sign (whether they are positive or negative).\n\n\nCode\nrange &lt;- seq(-4, 4, .1)\nnull_distribution &lt;- dt(range, 4, log = FALSE)\nplot_df &lt;- data.frame(range, null_distribution)\n\nt_ps &lt;- qt(seq(.1, .9, .1), 4)\n\nggplot(plot_df, aes(x = range, y = null_distribution)) +\n  geom_line() +\n  xlab(\"t-values\") +\n  ylab(\"Probability\") +\n  geom_vline(xintercept = qt(.975, 4, lower.tail = TRUE)) +\n  geom_vline(xintercept = qt(.025, 4, lower.tail = TRUE)) +\n  ggtitle(\"Critical ts for two-tailed test\") +\n  theme_classic(base_size = 10) +\n  theme(axis.text.y = element_blank(), axis.ticks = element_blank()) +\n  annotate(\n    \"rect\",\n    xmin = qt(.975, 4, lower.tail = TRUE),\n    xmax = 4,\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.5,\n    fill = \"green\"\n  ) +\n  geom_label(data = data.frame(x = 3.5, y = .2, label = \"2.5%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.975, 4, lower.tail = TRUE),\n    y = .3,\n    label = \"Critical t\"\n  ),\n  aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.975, 4, lower.tail = TRUE),\n    y = .25,\n    label = round(qt(.975, 4, lower.tail = TRUE), digits =\n                    2)\n  ),\n  aes(x = x, y = y, label = label)) +\n  annotate(\n    \"rect\",\n    xmin = -4,\n    xmax = qt(.025, 4, lower.tail = TRUE),\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.5,\n    fill = \"green\"\n  ) +\n  geom_label(data = data.frame(x = -3.5, y = .2, label = \"2.5%\"), aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.025, 4, lower.tail = TRUE),\n    y = .3,\n    label = \"Critical t\"\n  ),\n  aes(x = x, y = y, label = label)) +\n  geom_label(data = data.frame(\n    x = qt(.025, 4, lower.tail = TRUE),\n    y = .25,\n    label = round(qt(.025, 4, lower.tail = TRUE), digits =\n                    2)\n  ),\n  aes(x = x, y = y, label = label))\n\n\n\n\n\n\n\n\nFigure 9: Critical values for a two-tailed test. Each line represents the location where 2.5% of all \\(t\\)s are larger or smaller than critical value. The total for both tails is 5%\n\n\n\n\n\nHere is what we are seeing. A distribution of no differences (the null, which is what we are looking at), will produce \\(t\\)s that are 2.78 or greater 2.5% of the time, and \\(t\\)s that are -2.78 or smaller 2.5% of the time. 2.5% + 2.5% is a total of 5% of the time. We could also say that \\(t\\)s larger than +/- 2.78 occur 5% of the time.\nAs a result, the critical \\(t\\) value is (+/-) 2.78 for a two-tailed test. As you can see, the two-tailed test is blind to the direction or sign of the difference. Because of this, the critical \\(t\\) value is also higher for a two-tailed test, than for the one-tailed test that we did earlier. Hopefully, now you can see why it is called a two-tailed test. There are two tails of the distribution, one on the left and right, both shaded in green.\n\n\n\nNow that you know there are two kinds of tests, one-tailed, and two-tailed, which one should you use? There is some conventional wisdom on this, but also some debate. In the end, it is up to you to be able to justify your choice and why it is appropriate for you data. That is the real answer.\nThe conventional answer is that you use a one-tailed test when you have a theory or hypothesis that is making a directional prediction (the theory predicts that the difference will be positive, or negative). Similarly, use a two-tailed test when you are looking for any difference, and you don’t have a theory that makes a directional prediction (it just makes the prediction that there will be a difference, either positive or negative).\nAlso, people appear to choose one or two-tailed tests based on how risky they are as researchers. If you always ran one-tailed tests, your critical \\(t\\) values for your set alpha criterion would always be smaller than the critical \\(t\\)s for a two-tailed test. Over the long run, you would make more type I errors, because the criterion to detect an effect is a lower bar for one than two tailed tests.\n\nRemember type 1 errors occur when you reject the idea that chance could have caused your difference. You often never know when you make this error. It happens anytime that sampling error was the actual cause of the difference, but a researcher dismisses that possibility and concludes that their manipulation caused the difference.\n\nSimilarly, if you always ran two-tailed tests, even when you had a directional prediction, you would make fewer type I errors over the long run, because the \\(t\\) for a two-tailed test is higher than the \\(t\\) for a one-tailed test. It seems quite common for researchers to use a more conservative two-tailed test, even when they are making a directional prediction based on theory. In practice, researchers tend to adopt a standard for reporting that is common in their field. Whether or not the practice is justifiable can sometimes be an open question. The important task for any researcher, or student learning statistics, is to be able to justify their choice of test.\n\n\n\nBefore we finish up with paired-samples \\(t\\)-tests, we should talk about degrees of freedom. Our sense is that students don’t really understand degrees of freedom very well. If you are reading this textbook, you are probably still wondering what is degrees of freedom, seeing as we haven’t really talked about it all.\nFor the \\(t\\)-test, there is a formula for degrees of freedom. For the one-sample and paired sample \\(t\\)-tests, the formula is:\n\\(\\text{Degrees of Freedom} = \\text{df} = n-1\\). Where n is the number of samples in the test.\nIn our paired \\(t\\)-test example, there were 5 infants. Therefore, degrees of freedom = 5-1 = 4.\nOK, that’s a formula. Who cares about degrees of freedom, what does the number mean? And why do we report it when we report a \\(t\\)-test… you’ve probably noticed the number in parentheses e.g., \\(t\\)(4)=.72, the 4 is the \\(df\\), or degrees of freedom.\nDegrees of freedom is both a concept, and a correction. The concept is that if you estimate a property of the numbers, and you use this estimate, you will be forcing some constraints on your numbers.\nConsider the numbers: 1, 2, 3. The mean of these numbers is 2. Now, let’s say I told you that the mean of three numbers is 2. Then, how many of these three numbers have freedom? Funny question right. What we mean is, how many of the three numbers could be any number, or have the freedom to be any number.\nThe first two numbers could be any number. But, once those two numbers are set, the final number (the third number), MUST be a particular number that makes the mean 2. The first two numbers have freedom. The third number has no freedom.\nTo illustrate. Let’s freely pick two numbers: 51 and -3. I used my personal freedom to pick those two numbers. Now, if our three numbers are 51, -3, and x, and the mean of these three numbers is 2. There is only one solution, x has to be -42, otherwise the mean won’t be 2. This is one way to think about degrees of freedom. The degrees of freedom for these three numbers is n-1 = 3-1= 2, because 2 of the numbers can be free, but the last number has no freedom, it becomes fixed after the first two are decided.\nNow, statisticians often apply degrees of freedom to their calculations, especially when a second calculation relies on an estimated value. For example, when we calculate the standard deviation of a sample, we first calculate the mean of the sample right! By estimating the mean, we are fixing an aspect of our sample, and so, our sample now has n-1 degrees of freedom when we calculate the standard deviation (remember for the sample standard deviation, we divide by n-1…there’s that n-1 again.)\n\n\nThere are at least two ways to think the degrees of freedom for a \\(t\\)-test. For example, if you want to use math to compute aspects of the \\(t\\) distribution, then you need the degrees of freedom to plug in to the formula… If you want to see the formulas I’m talking about, scroll down on the \\(t\\)-test wikipedia page and look for the probability density or cumulative distribution functions…We think that is quite scary for most people, and one reason why degrees of freedom are not well-understood.\nIf we wanted to simulate the \\(t\\) distribution we could more easily see what influence degrees of freedom has on the shape of the distribution. Remember, \\(t\\) is a sample statistic, it is something we measure from the sample. So, we could simulate the process of measuring \\(t\\) from many different samples, then plot the histogram of \\(t\\) to show us the simulated \\(t\\) distribution.\n\n\nCode\nts &lt;- c(rt(10000, 4), rt(10000, 100))\ndfs &lt;- as.factor(rep(c(4, 100), each = 10000))\n\nt_df &lt;- data.frame(dfs, ts)\nt_df &lt;- t_df[abs(t_df$ts) &lt; 5, ]\n\nggplot(t_df, aes(x = ts, group = dfs, color = dfs)) +\n  geom_histogram() +\n  theme_classic() +\n  facet_wrap( ~ dfs) +\n  theme_classic(base_size=15)\n\n\n\n\n\n\n\n\nFigure 10: The width of the t distribution shrinks as sample size and degrees of freedom (from 4 to 100) increases.\n\n\n\n\n\nIn Figure 10 notice that the red distribution for \\(df = 4\\), is a little bit shorter, and a little bit wider than the bluey-green distribution for \\(df = 100\\). As degrees of freedom increase the \\(t\\) distribution gets taller (in the middle), and narrower in the range. It get’s more peaky. Can you guess the reason for this? Remember, we are estimating a sample statistic, and degrees of freedom is really just a number that refers to the number of subjects (well minus one). And, we already know that as we increase \\(n\\), our sample statistics become better estimates (less variance) of the distributional parameters they are estimating. So, \\(t\\) becomes a better estimate of it’s “true” value as sample size increase, resulting in a more narrow distribution of \\(t\\)s.\nThere is a slightly different \\(t\\) distribution for every degrees of freedom, and the critical regions associated with 5% of the extreme values are thus slightly different every time. This is why we report the degrees of freedom for each t-test, they define the distribution of \\(t\\) values for the sample-size in question. Why do we use n-1 and not n? Well, we calculate \\(t\\) using the sample standard deviation to estimate the standard error or the mean, that estimate uses n-1 in the denominator, so our \\(t\\) distribution is built assuming n-1. That’s enough for degrees of freedom…",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "T-Tests"
    ]
  },
  {
    "objectID": "week01/chapter.html#the-paired-samples-t-test-strikes-back",
    "href": "week01/chapter.html#the-paired-samples-t-test-strikes-back",
    "title": "T-Tests",
    "section": "",
    "text": "You must be wondering if we will ever be finished talking about paired samples t-tests… why are we doing round 2, oh no! Don’t worry, we’re just going to 1) remind you about what we were doing with the infant study, and 2) do a paired samples t-test on the entire data set and discuss.\nRemember, we were wondering if the infants would look longer toward the singer who sang the familiar song during the test phase compared to the baseline phase. We showed you data from 5 infants, and walked through the computations for the \\(t\\)-test. As a reminder, it looked like this:\n\n\n\n\n\n\n\n\n\n\n\n\n\ninfant\nBaseline\nTest\ndifferences\ndiff_from_mean\nSquared_differences\n\n\n\n\n1\n0.44\n0.6\n0.16\n0.106\n0.011236\n\n\n2\n0.41\n0.68\n0.27\n0.216\n0.046656\n\n\n3\n0.75\n0.72\n-0.03\n-0.084\n0.00705600000000001\n\n\n4\n0.44\n0.28\n-0.16\n-0.214\n0.045796\n\n\n5\n0.47\n0.5\n0.03\n-0.024\n0.000575999999999999\n\n\nSums\n2.51\n2.78\n0.27\n0\n0.11132\n\n\nMeans\n0.502\n0.556\n0.054\n0\n0.022264\n\n\n\n\n\n\nsd\n0.167\n\n\n\n\n\n\nSEM\n0.075\n\n\n\n\n\n\nt\n0.72\n\n\n\n\n\n\n    One Sample t-test\n\ndata:  round(differences, digits = 2)\nt = 0.72381, df = 4, p-value = 0.5092\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -0.1531384  0.2611384\nsample estimates:\nmean of x \n    0.054 \n\n\nLet’s write down the finding one more time: The mean difference was 0.054, \\(t\\)(4) = .72, \\(p\\) =.509. We can also now confirm, that the \\(p\\)-value was from a two-tailed test. So, what does this all really mean.\nWe can say that a \\(t\\) value with an absolute of .72 or larger occurs 50.9% of the time. More precisely, the distribution of no differences (the null), will produce a \\(t\\) value this large or larger 50.9% of the time. In other words, chance alone good have easily produced the \\(t\\) value from our sample, and the mean difference we observed or .054, could easily have been a result of chance.\nLet’s quickly put all of the data in the \\(t\\)-test, and re-run the test using all of the infant subjects.\n\n\nCode\npaired_sample_df &lt;-  data.frame(infant=1:32, \n                               Baseline = round(experiment_one$Baseline_Proportion_Gaze_to_Singer[1:32],digits=2), \n                               Test = round(experiment_one$Test_Proportion_Gaze_to_Singer[1:32], digits=2))\n\ndifferences &lt;-  paired_sample_df$Test-paired_sample_df$Baseline\nt.test(differences,mu=0)\n\n\n\n    One Sample t-test\n\ndata:  differences\nt = 2.4388, df = 31, p-value = 0.02066\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 0.01192088 0.13370412\nsample estimates:\nmean of x \n0.0728125 \n\n\nNow we get a very different answer. We would summarize the results saying the mean difference was .073, t(31) = 2.44, p = 0.020. How many total infants were their? Well the degrees of freedom was 31, so there must have been 32 infants in the study. Now we see a much smaller \\(p\\)-value. This was also a two-tailed test, so we that observing a \\(t\\) value of 2.4 or greater (absolute value) only occurs 2% of the time. In other words, the distribution of no differences will produce the observed t-value very rarely. So, it is unlikely that the observed mean difference of .073 was due to chance (it could have been due to chance, but that is very unlikely). As a result, we can be somewhat confident in concluding that something about seeing and hearing a unfamiliar person sing a familiar song, causes an infant to draw their attention toward the singer, and this potentially benefits social learning on the part of the infant.",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "T-Tests"
    ]
  },
  {
    "objectID": "week01/chapter.html#independent-samples-t-test-the-return-of-the-t-test",
    "href": "week01/chapter.html#independent-samples-t-test-the-return-of-the-t-test",
    "title": "T-Tests",
    "section": "",
    "text": "If you’ve been following the Star Wars references, we are on last movie (of the original trilogy)… the independent t-test. This is were basically the same story plays out as before, only slightly different.\nRemember there are different \\(t\\)-tests for different kinds of research designs. When your design is a between-subjects design, you use an independent samples t-test. Between-subjects design involve different people or subjects in each experimental condition. If there are two conditions, and 10 people in each, then there are 20 total people. And, there are no paired scores, because every single person is measured once, not twice, no repeated measures. Because there are no repeated measures we can’t look at the difference scores between conditions one and two. The scores are not paired in any meaningful way, to it doesn’t make sense to subtract them. So what do we do?\nThe logic of the independent samples t-test is the very same as the other \\(t\\)-tests. We calculated the means for each group, then we find the difference. That goes into the numerator of the t formula. Then we get an estimate of the variation for the denominator. We divide the mean difference by the estimate of the variation, and we get \\(t\\). It’s the same as before.\nThe only wrinkle here is what goes into the denominator? How should we calculate the estimate of the variance? It would be nice if we could do something very straightforward like this, say for an experiment with two groups A and B:\n\\(t = \\frac{\\bar{A}-\\bar{B}}{(\\frac{SEM_A+SEM_B}{2})}\\)\nIn plain language, this is just:\n\nFind the mean difference for the top part\nCompute the SEM (standard error of the mean) for each group, and average them together to make a single estimate, pooling over both samples.\n\nThis would be nice, but unfortunately, it turns out that finding the average of two standard errors of the mean is not the best way to do it. This would create a biased estimator of the variation for the hypothesized distribution of no differences. We won’t go into the math here, but instead of the above formula, we an use a different one that gives as an unbiased estimate of the pooled standard error of the sample mean. Our new and improved \\(t\\) formula would look like this:\n\\(t = \\frac{\\bar{X_A}-\\bar{X_B}}{s_p * \\sqrt{\\frac{1}{n_A} + \\frac{1}{n_B}}}\\)\nand, \\(s_p\\), which is the pooled sample standard deviation is defined as, note the $s$es in the formula are variances:\n\\(s_p = \\sqrt{\\frac{(n_A-1)s_A^2 + (n_B-1)s^2_B}{n_A +n_B -2}}\\)\nBelieve you me, that is so much more formula than I wanted to type out. Shall we do one independent \\(t\\)-test example by hand, just to see the computations? Let’s do it…but in a slightly different way than you expect. I show the steps using R. I made some fake scores for groups A and B. Then, I followed all of the steps from the formula, but made R do each of the calculations. This shows you the needed steps by following the code. At the end, I print the \\(t\\)-test values I computed “by hand”, and then the \\(t\\)-test value that the R software outputs using the \\(t\\)-test function. You should be able to get the same values for \\(t\\), if you were brave enough to compute \\(t\\) by hand.\n\n\nCode\n## By \"hand\" using R r code\na &lt;- c(1,2,3,4,5)\nb &lt;- c(3,5,4,7,9)\n\nmean_difference &lt;- mean(a)-mean(b) # compute mean difference\n\nvariance_a &lt;- var(a) # compute variance for A\nvariance_b &lt;- var(b) # compute variance for B\n\n# Compute top part and bottom part of sp formula\n\nsp_numerator &lt;- (4*variance_a + 4* variance_b) \nsp_denominator &lt;- 5+5-2\nsp &lt;- sqrt(sp_numerator/sp_denominator) # compute sp\n\n\n# compute t following formulat\n\nt &lt;- mean_difference / ( sp * sqrt( (1/5) +(1/5) ) )\n\nt # print results\n\n\n[1] -2.017991\n\n\nCode\n# using the R function t.test\nt.test(a,b, paired=FALSE, var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  a and b\nt = -2.018, df = 8, p-value = 0.0783\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -5.5710785  0.3710785\nsample estimates:\nmean of x mean of y \n      3.0       5.6",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "T-Tests"
    ]
  },
  {
    "objectID": "week01/chapter.html#simulating-data-for-t-tests",
    "href": "week01/chapter.html#simulating-data-for-t-tests",
    "title": "T-Tests",
    "section": "",
    "text": "An “advanced” topic for \\(t\\)-tests is the idea of using R to conduct simulations for \\(t\\)-tests.\nIf you recall, \\(t\\) is a property of a sample. We calculate \\(t\\) from our sample. The \\(t\\) distribution is the hypothetical behavior of our sample. That is, if we had taken thousands upon thousands of samples, and calculated \\(t\\) for each one, and then looked at the distribution of those \\(t\\)’s, we would have the sampling distribution of \\(t\\)!\nIt can be very useful to get in the habit of using R to simulate data under certain conditions, to see how your sample data, and things like \\(t\\) behave. Why is this useful? It mainly prepares you with some intuitions about how sampling error (random chance) can influence your results, given specific parameters of your design, such as sample-size, the size of the mean difference you expect to find in your data, and the amount of variation you might find. These methods can be used formally to conduct power-analyses. Or more informally for data sense.\n\n\nHere are the steps you might follow to simulate data for a one sample \\(t\\)-test.\n\nMake some assumptions about what your sample (that you might be planning to collect) might look like. For example, you might be planning to collect 30 subjects worth of data. The scores of those data points might come from a normal distribution (mean = 50, sd = 10).\nsample simulated numbers from the distribution, then conduct a \\(t\\)-test on the simulated numbers. Save the statistics you want (such as \\(t\\)s and \\(p\\)s), and then see how things behave.\n\nLet’s do this a couple different times. First, let’s simulate samples with N = 30, taken from a normal (mean= 50, sd = 25). We’ll do a simulation with 1000 simulations. For each simulation, we will compare the sample mean with a population mean of 50. There should be no difference on average here. Figure 11 is the null distribution that we are simulating.\n\n\nCode\n# steps to create fake data from a distribution\n# and conduct t-tests on the simulated data\nsave_ps &lt;- length(1000)\nsave_ts &lt;- length(1000)\nfor (i in 1:1000) {\n  my_sample &lt;- rnorm(n = 30, mean = 50, sd = 25)\n  t_test &lt;- t.test (my_sample, mu = 50)\n  save_ps[i] &lt;- t_test$p.value\n  save_ts[i] &lt;- t_test$statistic\n}\n\n\n\n\nCode\n#plot histograms of t and p values for 1000 simulations\nhist(save_ts)\n\n\n\n\n\n\n\n\nFigure 11: The distribution of \\(t\\)-values under the null. These are the \\(t\\) values that are produced by chance alone.\n\n\n\n\n\n\n\nCode\nhist(save_ps)\n\n\n\n\n\n\n\n\nFigure 12: The distribution of \\(p\\)-values that are observed is flat under the null.\n\n\n\n\n\nNeat. We see both a \\(t\\) distribution, that looks like \\(t\\) distribution as it should. And we see the \\(p\\) distribution. This shows us how often we get \\(t\\) values of particular sizes. You may find it interesting that the \\(p\\)-distribution is flat under the null, which we are simulating here. This means that you have the same chances of a getting a \\(t\\) with a p-value between 0 and 0.05, as you would for getting a \\(t\\) with a p-value between .90 and .95. Those ranges are both ranges of 5%, so there are an equal amount of \\(t\\) values in them by definition.\nHere’s another way to do the same simulation in R, using the replicate function, instead a for loop:\n\n\nCode\nsimulated_ts &lt;- replicate(1000,\n                          t.test(rnorm(30, 50, 25), mu = 50)$statistic)\nhist(simulated_ts)\n\n\n\n\n\n\n\n\nFigure 13: Simulating \\(t\\)s in R.\n\n\n\n\n\n\n\nCode\nsimulated_ps &lt;- replicate(1000,\n                          t.test(rnorm(30, 50, 25), mu = 50)$p.value)\nhist(simulated_ps)\n\n\n\n\n\n\n\n\nFigure 14: Simulating \\(p\\)s in R.\n\n\n\n\n\n\n\n\nThe code below is set up to sample 10 scores for condition A and B from the same normal distribution. The simulation is conducted 1000 times, and the \\(t\\)s and \\(p\\)s are saved and plotted for each.\n\n\nCode\nsave_ps &lt;- length(1000)\nsave_ts &lt;- length(1000)\nfor ( i in 1:1000 ){\n  condition_A &lt;- rnorm(10,10,5)\n  condition_B &lt;- rnorm(10,10,5)\n  differences &lt;- condition_A - condition_B\n  t_test &lt;- t.test(differences, mu=0)\n  save_ps[i] &lt;- t_test$p.value\n  save_ts[i] &lt;- t_test$statistic\n}\n\n\n\n\nCode\nhist(save_ts)\n\n\n\n\n\n\n\n\nFigure 15: 1000 simulated ts from the null distribution\n\n\n\n\n\n\n\nCode\nhist(save_ps)\n\n\n\n\n\n\n\n\nFigure 16: 1000 simulated ps from the null distribution\n\n\n\n\n\nAccording to the simulation. When there are no differences between the conditions, and the samples are being pulled from the very same distribution, you get these two distributions for \\(t\\) and \\(p\\). These again show how the null distribution of no differences behaves.\nFor any of these simulations, if you rejected the null-hypothesis (that your difference was only due to chance), you would be making a type I error. If you set your alpha criteria to \\(\\alpha = .05\\), we can ask how many type I errors were made in these 1000 simulations. The answer is:\n\n\nCode\nlength(save_ps[save_ps&lt;.05])\n\n\n[1] 40\n\n\nCode\nlength(save_ps[save_ps&lt;.05])/1000\n\n\n[1] 0.04\n\n\nWe happened to make 40. The expectation over the long run is 5% type I error rates (if your alpha is .05).\nWhat happens if there actually is a difference in the simulated data, let’s set one condition to have a larger mean than the other:\n\n\nCode\nsave_ps &lt;- length(1000)\nsave_ts &lt;- length(1000)\nfor ( i in 1:1000 ){\n  condition_A &lt;- rnorm(10,10,5)\n  condition_B &lt;- rnorm(10,13,5)\n  differences &lt;- condition_A - condition_B\n  t_test &lt;- t.test(differences, mu=0)\n  save_ps[i] &lt;- t_test$p.value\n  save_ts[i] &lt;- t_test$statistic\n}\n\n\n\n\nCode\nhist(save_ts)\n\n\n\n\n\n\n\n\nFigure 17: 1000 ts when there is a true difference\n\n\n\n\n\n\n\nCode\nhist(save_ps)\n\n\n\n\n\n\n\n\nFigure 18: 1000 ps when there is a true difference\n\n\n\n\n\nNow you can see that the \\(p\\)-value distribution is skewed to the left. This is because when there is a true effect, you will get p-values that are less than .05 more often. Or, rather, you get larger \\(t\\) values than you normally would if there were no differences.\nIn this case, we wouldn’t be making a type I error if we rejected the null when p was smaller than .05. How many times would we do that out of our 1000 experiments?\n\n\nCode\nlength(save_ps[save_ps&lt;.05])\n\n\n[1] 228\n\n\nCode\nlength(save_ps[save_ps&lt;.05])/1000\n\n\n[1] 0.228\n\n\nWe happened to get 228 simulations where p was less than .05, that’s only 0.228 experiments. If you were the researcher, would you want to run an experiment that would be successful only 0.228 of the time? I wouldn’t. I would run a better experiment.\nHow would you run a better simulated experiment? Well, you could increase \\(n\\), the number of subjects in the experiment. Let’s increase \\(n\\) from 10 to 100, and see what happens to the number of “significant” simulated experiments.\n\n\nCode\nsave_ps &lt;- length(1000)\nsave_ts &lt;- length(1000)\nfor ( i in 1:1000 ){\n  condition_A &lt;- rnorm(100,10,5)\n  condition_B &lt;- rnorm(100,13,5)\n  differences &lt;- condition_A - condition_B\n  t_test &lt;- t.test(differences, mu=0)\n  save_ps[i] &lt;- t_test$p.value\n  save_ts[i] &lt;- t_test$statistic\n}\n\n\n\n\nCode\nhist(save_ts)\n\n\n\n\n\n\n\n\nFigure 19: 1000 ts for n =100, when there is a true effect\n\n\n\n\n\n\n\nCode\nhist(save_ps)\n\n\nlength(save_ps[save_ps&lt;.05])\n\n\n[1] 990\n\n\nCode\nlength(save_ps[save_ps&lt;.05])/1000\n\n\n[1] 0.99\n\n\n\n\n\n\n\n\nFigure 20: 1000 ps for n =100, when there is a true effect\n\n\n\n\n\nCool, now almost all of the experiments show a \\(p\\)-value of less than .05 (using a two-tailed test, that’s the default in R). See, you could use this simulation process to determine how many subjects you need to reliably find your effect.\n\n\n\nJust change the t.test function like so… this is for the null, assuming no difference between groups.\n\n\nCode\nsave_ps &lt;- length(1000)\nsave_ts &lt;- length(1000)\nfor ( i in 1:1000 ){\n  group_A &lt;- rnorm(10,10,5)\n  group_B &lt;- rnorm(10,10,5)\n  t_test &lt;- t.test(group_A, group_B, paired=FALSE, var.equal=TRUE)\n  save_ps[i] &lt;- t_test$p.value\n  save_ts[i] &lt;- t_test$statistic\n}\n\n\n\n\nCode\nhist(save_ts)\n\n\n\n\n\n\n\n\nFigure 21: 1000 ts for n =100, when there is a true effect\n\n\n\n\n\n\n\nCode\nhist(save_ps)\n\n\nlength(save_ps[save_ps&lt;.05])\n\n\n[1] 40\n\n\nCode\nlength(save_ps[save_ps&lt;.05])/1000\n\n\n[1] 0.04\n\n\n\n\n\n\n\n\nFigure 22: 1000 ps for n =100, when there is a true effect",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "T-Tests"
    ]
  },
  {
    "objectID": "week01/chapter.html#videos",
    "href": "week01/chapter.html#videos",
    "title": "T-Tests",
    "section": "",
    "text": "Gordon Original ## 1. Introduction\nThe t-test is a fundamental statistical method used in psychology to compare the means of two groups. This chapter will explore the theory behind t-tests, demonstrate practical applications using R, and provide a structured write-up in APA style. Whether you’re examining the effectiveness of a new therapy or comparing cognitive performance between groups, the t-test is an essential tool for psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "T-Tests"
    ]
  },
  {
    "objectID": "week01/chapter.html#main-content",
    "href": "week01/chapter.html#main-content",
    "title": "T-Tests",
    "section": "",
    "text": "A t-test evaluates whether the means of two groups are statistically different from each other. The most common types are the independent samples t-test, paired samples t-test, and one-sample t-test. Each type tests different hypotheses and has unique assumptions.\n\n\nThis test compares the means of two independent groups to ascertain if there is statistical evidence that the associated population means are significantly different.\n\n\n\nThis test compares means from the same group at different times (e.g., before and after a treatment) or matched pairs.\n\n\n\nThis test determines whether the mean of a single group is different from a known mean.\n\n\n\n\n\nIndependence: Observations within each group must be independent.\nNormality: Data in each group should be approximately normally distributed.\nHomogeneity of Variance: Variances in the two groups should be roughly equal (for independent samples t-test).",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "T-Tests"
    ]
  },
  {
    "objectID": "week01/chapter.html#methods-and-measures",
    "href": "week01/chapter.html#methods-and-measures",
    "title": "T-Tests",
    "section": "",
    "text": "To conduct a t-test, you need to: 1. Formulate the null (H0) and alternative (H1) hypotheses. 2. Collect and organize data. 3. Check assumptions. 4. Calculate the t-statistic and degrees of freedom. 5. Determine the p-value. 6. Make a decision to reject or fail to reject H0 based on the p-value.\n\n\nResearch Question: Does a new cognitive-behavioral therapy (CBT) improve anxiety levels more than a placebo?\nHypotheses: - H0: There is no difference in anxiety levels between the CBT and placebo groups. - H1: The CBT group has lower anxiety levels than the placebo group.\nMeasures: Anxiety levels are measured using a standardized anxiety inventory.",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "T-Tests"
    ]
  },
  {
    "objectID": "week01/chapter.html#analysis-with-r-code",
    "href": "week01/chapter.html#analysis-with-r-code",
    "title": "T-Tests",
    "section": "",
    "text": "Let’s use R for an independent samples t-test.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nThe t.test function provides the t-statistic, degrees of freedom, and p-value. If the p-value is less than the significance level (e.g., 0.05), we reject H0.\n    Welch Two Sample t-test\n\ndata:  anxiety by group\nt = -8.6943, df = 17.564, p-value = 8.922e-08\nalternative hypothesis: true difference in means between group CBT and group Placebo is not equal to 0\n95 percent confidence interval:\n -9.936595 -6.063405\nsample estimates:\n    mean in group CBT mean in group Placebo \n                 21.7                  29.7",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "T-Tests"
    ]
  },
  {
    "objectID": "week01/chapter.html#debates-and-controversies",
    "href": "week01/chapter.html#debates-and-controversies",
    "title": "T-Tests",
    "section": "",
    "text": "Violating assumptions (e.g., normality, homogeneity of variance) can lead to incorrect conclusions. Robust alternatives or data transformations may be necessary (Wilcox, 2012).\n\n\n\nOverreliance on p-values can lead to misinterpretation of results. It’s crucial to report effect sizes and confidence intervals (Cumming, 2014).\n\n\n\nConducting multiple t-tests increases the risk of Type I errors. Methods like Bonferroni correction adjust for this but can be overly conservative (Perneger, 1998).",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "T-Tests"
    ]
  },
  {
    "objectID": "week01/chapter.html#conclusion",
    "href": "week01/chapter.html#conclusion",
    "title": "T-Tests",
    "section": "",
    "text": "T-tests are a vital statistical method in psychological research for comparing means between groups. Understanding their theory, assumptions, and correct application in R can significantly enhance the rigor of your analyses. Always ensure to check assumptions, consider effect sizes, and be mindful of the limitations and debates surrounding t-tests.\n\n\nCumming, G. (2014). The new statistics: Why and how. Psychological Science, 25(1), 7-29.\nPerneger, T. V. (1998). What’s wrong with Bonferroni adjustments. BMJ, 316(7139), 1236-1238.\nWilcox, R. R. (2012). Modern statistics for the social and behavioral sciences: A practical introduction. CRC Press.\nThis chapter provides a comprehensive overview of conducting t-tests in R, essential for first-year psychology students. Future chapters will delve into more advanced statistical methods to further enhance your analytical skills.",
    "crumbs": [
      "Schedule",
      "Content",
      "Week01",
      "T-Tests"
    ]
  },
  {
    "objectID": "DataSkills/dataskills02.html",
    "href": "DataSkills/dataskills02.html",
    "title": "DataSkill 2: Advanced literature search techniques",
    "section": "",
    "text": "This session focuses on Advanced literature search techniques and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 2: Advanced literature search techniques"
    ]
  },
  {
    "objectID": "DataSkills/dataskills02.html#skill-overview",
    "href": "DataSkills/dataskills02.html#skill-overview",
    "title": "DataSkill 2: Advanced literature search techniques",
    "section": "",
    "text": "This session focuses on Advanced literature search techniques and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 2: Advanced literature search techniques"
    ]
  },
  {
    "objectID": "DataSkills/dataskills02.html#learning-objectives",
    "href": "DataSkills/dataskills02.html#learning-objectives",
    "title": "DataSkill 2: Advanced literature search techniques",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this session, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 2: Advanced literature search techniques"
    ]
  },
  {
    "objectID": "DataSkills/dataskills02.html#key-concepts",
    "href": "DataSkills/dataskills02.html#key-concepts",
    "title": "DataSkill 2: Advanced literature search techniques",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 2: Advanced literature search techniques"
    ]
  },
  {
    "objectID": "DataSkills/dataskills02.html#practical-exercise",
    "href": "DataSkills/dataskills02.html#practical-exercise",
    "title": "DataSkill 2: Advanced literature search techniques",
    "section": "Practical Exercise",
    "text": "Practical Exercise\n[Brief description of a hands-on exercise related to Advanced literature search techniques]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 2: Advanced literature search techniques"
    ]
  },
  {
    "objectID": "DataSkills/dataskills02.html#tips-and-best-practices",
    "href": "DataSkills/dataskills02.html#tips-and-best-practices",
    "title": "DataSkill 2: Advanced literature search techniques",
    "section": "Tips and Best Practices",
    "text": "Tips and Best Practices\n\n[Tip 1]\n[Tip 2]\n[Tip 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 2: Advanced literature search techniques"
    ]
  },
  {
    "objectID": "DataSkills/dataskills02.html#additional-resources",
    "href": "DataSkills/dataskills02.html#additional-resources",
    "title": "DataSkill 2: Advanced literature search techniques",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n[Resource 1: e.g., software download link, tutorial video, etc.]\n[Resource 2]\n[Resource 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 2: Advanced literature search techniques"
    ]
  },
  {
    "objectID": "DataSkills/dataskills02.html#reflection-questions",
    "href": "DataSkills/dataskills02.html#reflection-questions",
    "title": "DataSkill 2: Advanced literature search techniques",
    "section": "Reflection Questions",
    "text": "Reflection Questions\n\nHow might Advanced literature search techniques enhance your research capabilities?\nWhat challenges did you face when learning about or applying Advanced literature search techniques?\nHow could you integrate Advanced literature search techniques into your current or future research projects?",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 2: Advanced literature search techniques"
    ]
  },
  {
    "objectID": "DataSkills/dataskills07.html",
    "href": "DataSkills/dataskills07.html",
    "title": "DataSkill 7: Alternatives to SPSS for data analysis",
    "section": "",
    "text": "This session focuses on Alternatives to SPSS for data analysis and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 7: Alternatives to SPSS for data analysis"
    ]
  },
  {
    "objectID": "DataSkills/dataskills07.html#skill-overview",
    "href": "DataSkills/dataskills07.html#skill-overview",
    "title": "DataSkill 7: Alternatives to SPSS for data analysis",
    "section": "",
    "text": "This session focuses on Alternatives to SPSS for data analysis and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 7: Alternatives to SPSS for data analysis"
    ]
  },
  {
    "objectID": "DataSkills/dataskills07.html#learning-objectives",
    "href": "DataSkills/dataskills07.html#learning-objectives",
    "title": "DataSkill 7: Alternatives to SPSS for data analysis",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this session, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 7: Alternatives to SPSS for data analysis"
    ]
  },
  {
    "objectID": "DataSkills/dataskills07.html#key-concepts",
    "href": "DataSkills/dataskills07.html#key-concepts",
    "title": "DataSkill 7: Alternatives to SPSS for data analysis",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 7: Alternatives to SPSS for data analysis"
    ]
  },
  {
    "objectID": "DataSkills/dataskills07.html#practical-exercise",
    "href": "DataSkills/dataskills07.html#practical-exercise",
    "title": "DataSkill 7: Alternatives to SPSS for data analysis",
    "section": "Practical Exercise",
    "text": "Practical Exercise\n[Brief description of a hands-on exercise related to Alternatives to SPSS for data analysis]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 7: Alternatives to SPSS for data analysis"
    ]
  },
  {
    "objectID": "DataSkills/dataskills07.html#tips-and-best-practices",
    "href": "DataSkills/dataskills07.html#tips-and-best-practices",
    "title": "DataSkill 7: Alternatives to SPSS for data analysis",
    "section": "Tips and Best Practices",
    "text": "Tips and Best Practices\n\n[Tip 1]\n[Tip 2]\n[Tip 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 7: Alternatives to SPSS for data analysis"
    ]
  },
  {
    "objectID": "DataSkills/dataskills07.html#additional-resources",
    "href": "DataSkills/dataskills07.html#additional-resources",
    "title": "DataSkill 7: Alternatives to SPSS for data analysis",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n[Resource 1: e.g., software download link, tutorial video, etc.]\n[Resource 2]\n[Resource 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 7: Alternatives to SPSS for data analysis"
    ]
  },
  {
    "objectID": "DataSkills/dataskills07.html#reflection-questions",
    "href": "DataSkills/dataskills07.html#reflection-questions",
    "title": "DataSkill 7: Alternatives to SPSS for data analysis",
    "section": "Reflection Questions",
    "text": "Reflection Questions\n\nHow might Alternatives to SPSS for data analysis enhance your research capabilities?\nWhat challenges did you face when learning about or applying Alternatives to SPSS for data analysis?\nHow could you integrate Alternatives to SPSS for data analysis into your current or future research projects?",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 7: Alternatives to SPSS for data analysis"
    ]
  },
  {
    "objectID": "DataSkills/dataskills06.html",
    "href": "DataSkills/dataskills06.html",
    "title": "DataSkill 6: Three flavours of ANOVA data",
    "section": "",
    "text": "This session focuses on Three flavours of ANOVA data and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 6: Three flavours of ANOVA data"
    ]
  },
  {
    "objectID": "DataSkills/dataskills06.html#skill-overview",
    "href": "DataSkills/dataskills06.html#skill-overview",
    "title": "DataSkill 6: Three flavours of ANOVA data",
    "section": "",
    "text": "This session focuses on Three flavours of ANOVA data and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 6: Three flavours of ANOVA data"
    ]
  },
  {
    "objectID": "DataSkills/dataskills06.html#learning-objectives",
    "href": "DataSkills/dataskills06.html#learning-objectives",
    "title": "DataSkill 6: Three flavours of ANOVA data",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this session, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 6: Three flavours of ANOVA data"
    ]
  },
  {
    "objectID": "DataSkills/dataskills06.html#key-concepts",
    "href": "DataSkills/dataskills06.html#key-concepts",
    "title": "DataSkill 6: Three flavours of ANOVA data",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 6: Three flavours of ANOVA data"
    ]
  },
  {
    "objectID": "DataSkills/dataskills06.html#practical-exercise",
    "href": "DataSkills/dataskills06.html#practical-exercise",
    "title": "DataSkill 6: Three flavours of ANOVA data",
    "section": "Practical Exercise",
    "text": "Practical Exercise\n[Brief description of a hands-on exercise related to Three flavours of ANOVA data]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 6: Three flavours of ANOVA data"
    ]
  },
  {
    "objectID": "DataSkills/dataskills06.html#tips-and-best-practices",
    "href": "DataSkills/dataskills06.html#tips-and-best-practices",
    "title": "DataSkill 6: Three flavours of ANOVA data",
    "section": "Tips and Best Practices",
    "text": "Tips and Best Practices\n\n[Tip 1]\n[Tip 2]\n[Tip 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 6: Three flavours of ANOVA data"
    ]
  },
  {
    "objectID": "DataSkills/dataskills06.html#additional-resources",
    "href": "DataSkills/dataskills06.html#additional-resources",
    "title": "DataSkill 6: Three flavours of ANOVA data",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n[Resource 1: e.g., software download link, tutorial video, etc.]\n[Resource 2]\n[Resource 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 6: Three flavours of ANOVA data"
    ]
  },
  {
    "objectID": "DataSkills/dataskills06.html#reflection-questions",
    "href": "DataSkills/dataskills06.html#reflection-questions",
    "title": "DataSkill 6: Three flavours of ANOVA data",
    "section": "Reflection Questions",
    "text": "Reflection Questions\n\nHow might Three flavours of ANOVA data enhance your research capabilities?\nWhat challenges did you face when learning about or applying Three flavours of ANOVA data?\nHow could you integrate Three flavours of ANOVA data into your current or future research projects?",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 6: Three flavours of ANOVA data"
    ]
  },
  {
    "objectID": "DataSkills/dataskills20.html",
    "href": "DataSkills/dataskills20.html",
    "title": "DataSkill 20: Pre-Submission Checklist and Reflection",
    "section": "",
    "text": "This session focuses on Pre-Submission Checklist and Reflection and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 20: Pre-Submission Checklist and Reflection"
    ]
  },
  {
    "objectID": "DataSkills/dataskills20.html#skill-overview",
    "href": "DataSkills/dataskills20.html#skill-overview",
    "title": "DataSkill 20: Pre-Submission Checklist and Reflection",
    "section": "",
    "text": "This session focuses on Pre-Submission Checklist and Reflection and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 20: Pre-Submission Checklist and Reflection"
    ]
  },
  {
    "objectID": "DataSkills/dataskills20.html#learning-objectives",
    "href": "DataSkills/dataskills20.html#learning-objectives",
    "title": "DataSkill 20: Pre-Submission Checklist and Reflection",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this session, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 20: Pre-Submission Checklist and Reflection"
    ]
  },
  {
    "objectID": "DataSkills/dataskills20.html#key-concepts",
    "href": "DataSkills/dataskills20.html#key-concepts",
    "title": "DataSkill 20: Pre-Submission Checklist and Reflection",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 20: Pre-Submission Checklist and Reflection"
    ]
  },
  {
    "objectID": "DataSkills/dataskills20.html#practical-exercise",
    "href": "DataSkills/dataskills20.html#practical-exercise",
    "title": "DataSkill 20: Pre-Submission Checklist and Reflection",
    "section": "Practical Exercise",
    "text": "Practical Exercise\n[Brief description of a hands-on exercise related to Pre-Submission Checklist and Reflection]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 20: Pre-Submission Checklist and Reflection"
    ]
  },
  {
    "objectID": "DataSkills/dataskills20.html#tips-and-best-practices",
    "href": "DataSkills/dataskills20.html#tips-and-best-practices",
    "title": "DataSkill 20: Pre-Submission Checklist and Reflection",
    "section": "Tips and Best Practices",
    "text": "Tips and Best Practices\n\n[Tip 1]\n[Tip 2]\n[Tip 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 20: Pre-Submission Checklist and Reflection"
    ]
  },
  {
    "objectID": "DataSkills/dataskills20.html#additional-resources",
    "href": "DataSkills/dataskills20.html#additional-resources",
    "title": "DataSkill 20: Pre-Submission Checklist and Reflection",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n[Resource 1: e.g., software download link, tutorial video, etc.]\n[Resource 2]\n[Resource 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 20: Pre-Submission Checklist and Reflection"
    ]
  },
  {
    "objectID": "DataSkills/dataskills20.html#reflection-questions",
    "href": "DataSkills/dataskills20.html#reflection-questions",
    "title": "DataSkill 20: Pre-Submission Checklist and Reflection",
    "section": "Reflection Questions",
    "text": "Reflection Questions\n\nHow might Pre-Submission Checklist and Reflection enhance your research capabilities?\nWhat challenges did you face when learning about or applying Pre-Submission Checklist and Reflection?\nHow could you integrate Pre-Submission Checklist and Reflection into your current or future research projects?",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 20: Pre-Submission Checklist and Reflection"
    ]
  },
  {
    "objectID": "DataSkills/dataskills19.html",
    "href": "DataSkills/dataskills19.html",
    "title": "DataSkill 19: Creating effective scientific posters and presentations",
    "section": "",
    "text": "This session focuses on Creating effective scientific posters and presentations and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 19: Creating effective scientific posters and presentations"
    ]
  },
  {
    "objectID": "DataSkills/dataskills19.html#skill-overview",
    "href": "DataSkills/dataskills19.html#skill-overview",
    "title": "DataSkill 19: Creating effective scientific posters and presentations",
    "section": "",
    "text": "This session focuses on Creating effective scientific posters and presentations and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 19: Creating effective scientific posters and presentations"
    ]
  },
  {
    "objectID": "DataSkills/dataskills19.html#learning-objectives",
    "href": "DataSkills/dataskills19.html#learning-objectives",
    "title": "DataSkill 19: Creating effective scientific posters and presentations",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this session, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 19: Creating effective scientific posters and presentations"
    ]
  },
  {
    "objectID": "DataSkills/dataskills19.html#key-concepts",
    "href": "DataSkills/dataskills19.html#key-concepts",
    "title": "DataSkill 19: Creating effective scientific posters and presentations",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 19: Creating effective scientific posters and presentations"
    ]
  },
  {
    "objectID": "DataSkills/dataskills19.html#practical-exercise",
    "href": "DataSkills/dataskills19.html#practical-exercise",
    "title": "DataSkill 19: Creating effective scientific posters and presentations",
    "section": "Practical Exercise",
    "text": "Practical Exercise\n[Brief description of a hands-on exercise related to Creating effective scientific posters and presentations]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 19: Creating effective scientific posters and presentations"
    ]
  },
  {
    "objectID": "DataSkills/dataskills19.html#tips-and-best-practices",
    "href": "DataSkills/dataskills19.html#tips-and-best-practices",
    "title": "DataSkill 19: Creating effective scientific posters and presentations",
    "section": "Tips and Best Practices",
    "text": "Tips and Best Practices\n\n[Tip 1]\n[Tip 2]\n[Tip 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 19: Creating effective scientific posters and presentations"
    ]
  },
  {
    "objectID": "DataSkills/dataskills19.html#additional-resources",
    "href": "DataSkills/dataskills19.html#additional-resources",
    "title": "DataSkill 19: Creating effective scientific posters and presentations",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n[Resource 1: e.g., software download link, tutorial video, etc.]\n[Resource 2]\n[Resource 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 19: Creating effective scientific posters and presentations"
    ]
  },
  {
    "objectID": "DataSkills/dataskills19.html#reflection-questions",
    "href": "DataSkills/dataskills19.html#reflection-questions",
    "title": "DataSkill 19: Creating effective scientific posters and presentations",
    "section": "Reflection Questions",
    "text": "Reflection Questions\n\nHow might Creating effective scientific posters and presentations enhance your research capabilities?\nWhat challenges did you face when learning about or applying Creating effective scientific posters and presentations?\nHow could you integrate Creating effective scientific posters and presentations into your current or future research projects?",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 19: Creating effective scientific posters and presentations"
    ]
  },
  {
    "objectID": "DataSkills/dataskills08.html",
    "href": "DataSkills/dataskills08.html",
    "title": "DataSkill 8: Excel Bootcamp (and other resources)",
    "section": "",
    "text": "This session focuses on Excel Bootcamp (and other resources) and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 8: Excel Bootcamp (and other resources)"
    ]
  },
  {
    "objectID": "DataSkills/dataskills08.html#skill-overview",
    "href": "DataSkills/dataskills08.html#skill-overview",
    "title": "DataSkill 8: Excel Bootcamp (and other resources)",
    "section": "",
    "text": "This session focuses on Excel Bootcamp (and other resources) and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 8: Excel Bootcamp (and other resources)"
    ]
  },
  {
    "objectID": "DataSkills/dataskills08.html#learning-objectives",
    "href": "DataSkills/dataskills08.html#learning-objectives",
    "title": "DataSkill 8: Excel Bootcamp (and other resources)",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this session, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 8: Excel Bootcamp (and other resources)"
    ]
  },
  {
    "objectID": "DataSkills/dataskills08.html#key-concepts",
    "href": "DataSkills/dataskills08.html#key-concepts",
    "title": "DataSkill 8: Excel Bootcamp (and other resources)",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 8: Excel Bootcamp (and other resources)"
    ]
  },
  {
    "objectID": "DataSkills/dataskills08.html#practical-exercise",
    "href": "DataSkills/dataskills08.html#practical-exercise",
    "title": "DataSkill 8: Excel Bootcamp (and other resources)",
    "section": "Practical Exercise",
    "text": "Practical Exercise\n[Brief description of a hands-on exercise related to Excel Bootcamp (and other resources)]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 8: Excel Bootcamp (and other resources)"
    ]
  },
  {
    "objectID": "DataSkills/dataskills08.html#tips-and-best-practices",
    "href": "DataSkills/dataskills08.html#tips-and-best-practices",
    "title": "DataSkill 8: Excel Bootcamp (and other resources)",
    "section": "Tips and Best Practices",
    "text": "Tips and Best Practices\n\n[Tip 1]\n[Tip 2]\n[Tip 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 8: Excel Bootcamp (and other resources)"
    ]
  },
  {
    "objectID": "DataSkills/dataskills08.html#additional-resources",
    "href": "DataSkills/dataskills08.html#additional-resources",
    "title": "DataSkill 8: Excel Bootcamp (and other resources)",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n[Resource 1: e.g., software download link, tutorial video, etc.]\n[Resource 2]\n[Resource 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 8: Excel Bootcamp (and other resources)"
    ]
  },
  {
    "objectID": "DataSkills/dataskills08.html#reflection-questions",
    "href": "DataSkills/dataskills08.html#reflection-questions",
    "title": "DataSkill 8: Excel Bootcamp (and other resources)",
    "section": "Reflection Questions",
    "text": "Reflection Questions\n\nHow might Excel Bootcamp (and other resources) enhance your research capabilities?\nWhat challenges did you face when learning about or applying Excel Bootcamp (and other resources)?\nHow could you integrate Excel Bootcamp (and other resources) into your current or future research projects?",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 8: Excel Bootcamp (and other resources)"
    ]
  },
  {
    "objectID": "DataSkills/dataskills16.html",
    "href": "DataSkills/dataskills16.html",
    "title": "DataSkill 16: SPSS, JAMOVI and R - three flavours of ANOVA",
    "section": "",
    "text": "This session focuses on SPSS, JAMOVI and R - three flavours of ANOVA and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 16: SPSS, JAMOVI and R - three flavours of ANOVA"
    ]
  },
  {
    "objectID": "DataSkills/dataskills16.html#skill-overview",
    "href": "DataSkills/dataskills16.html#skill-overview",
    "title": "DataSkill 16: SPSS, JAMOVI and R - three flavours of ANOVA",
    "section": "",
    "text": "This session focuses on SPSS, JAMOVI and R - three flavours of ANOVA and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 16: SPSS, JAMOVI and R - three flavours of ANOVA"
    ]
  },
  {
    "objectID": "DataSkills/dataskills16.html#learning-objectives",
    "href": "DataSkills/dataskills16.html#learning-objectives",
    "title": "DataSkill 16: SPSS, JAMOVI and R - three flavours of ANOVA",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this session, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 16: SPSS, JAMOVI and R - three flavours of ANOVA"
    ]
  },
  {
    "objectID": "DataSkills/dataskills16.html#key-concepts",
    "href": "DataSkills/dataskills16.html#key-concepts",
    "title": "DataSkill 16: SPSS, JAMOVI and R - three flavours of ANOVA",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 16: SPSS, JAMOVI and R - three flavours of ANOVA"
    ]
  },
  {
    "objectID": "DataSkills/dataskills16.html#practical-exercise",
    "href": "DataSkills/dataskills16.html#practical-exercise",
    "title": "DataSkill 16: SPSS, JAMOVI and R - three flavours of ANOVA",
    "section": "Practical Exercise",
    "text": "Practical Exercise\n[Brief description of a hands-on exercise related to SPSS, JAMOVI and R - three flavours of ANOVA]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 16: SPSS, JAMOVI and R - three flavours of ANOVA"
    ]
  },
  {
    "objectID": "DataSkills/dataskills16.html#tips-and-best-practices",
    "href": "DataSkills/dataskills16.html#tips-and-best-practices",
    "title": "DataSkill 16: SPSS, JAMOVI and R - three flavours of ANOVA",
    "section": "Tips and Best Practices",
    "text": "Tips and Best Practices\n\n[Tip 1]\n[Tip 2]\n[Tip 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 16: SPSS, JAMOVI and R - three flavours of ANOVA"
    ]
  },
  {
    "objectID": "DataSkills/dataskills16.html#additional-resources",
    "href": "DataSkills/dataskills16.html#additional-resources",
    "title": "DataSkill 16: SPSS, JAMOVI and R - three flavours of ANOVA",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n[Resource 1: e.g., software download link, tutorial video, etc.]\n[Resource 2]\n[Resource 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 16: SPSS, JAMOVI and R - three flavours of ANOVA"
    ]
  },
  {
    "objectID": "DataSkills/dataskills16.html#reflection-questions",
    "href": "DataSkills/dataskills16.html#reflection-questions",
    "title": "DataSkill 16: SPSS, JAMOVI and R - three flavours of ANOVA",
    "section": "Reflection Questions",
    "text": "Reflection Questions\n\nHow might SPSS, JAMOVI and R - three flavours of ANOVA enhance your research capabilities?\nWhat challenges did you face when learning about or applying SPSS, JAMOVI and R - three flavours of ANOVA?\nHow could you integrate SPSS, JAMOVI and R - three flavours of ANOVA into your current or future research projects?",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 16: SPSS, JAMOVI and R - three flavours of ANOVA"
    ]
  },
  {
    "objectID": "DataSkills/dataskills13.html",
    "href": "DataSkills/dataskills13.html",
    "title": "DataSkill 13: Advanced data visualization techniques",
    "section": "",
    "text": "This session focuses on Advanced data visualization techniques and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 13: Advanced data visualization techniques"
    ]
  },
  {
    "objectID": "DataSkills/dataskills13.html#skill-overview",
    "href": "DataSkills/dataskills13.html#skill-overview",
    "title": "DataSkill 13: Advanced data visualization techniques",
    "section": "",
    "text": "This session focuses on Advanced data visualization techniques and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 13: Advanced data visualization techniques"
    ]
  },
  {
    "objectID": "DataSkills/dataskills13.html#learning-objectives",
    "href": "DataSkills/dataskills13.html#learning-objectives",
    "title": "DataSkill 13: Advanced data visualization techniques",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this session, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 13: Advanced data visualization techniques"
    ]
  },
  {
    "objectID": "DataSkills/dataskills13.html#key-concepts",
    "href": "DataSkills/dataskills13.html#key-concepts",
    "title": "DataSkill 13: Advanced data visualization techniques",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 13: Advanced data visualization techniques"
    ]
  },
  {
    "objectID": "DataSkills/dataskills13.html#practical-exercise",
    "href": "DataSkills/dataskills13.html#practical-exercise",
    "title": "DataSkill 13: Advanced data visualization techniques",
    "section": "Practical Exercise",
    "text": "Practical Exercise\n[Brief description of a hands-on exercise related to Advanced data visualization techniques]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 13: Advanced data visualization techniques"
    ]
  },
  {
    "objectID": "DataSkills/dataskills13.html#tips-and-best-practices",
    "href": "DataSkills/dataskills13.html#tips-and-best-practices",
    "title": "DataSkill 13: Advanced data visualization techniques",
    "section": "Tips and Best Practices",
    "text": "Tips and Best Practices\n\n[Tip 1]\n[Tip 2]\n[Tip 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 13: Advanced data visualization techniques"
    ]
  },
  {
    "objectID": "DataSkills/dataskills13.html#additional-resources",
    "href": "DataSkills/dataskills13.html#additional-resources",
    "title": "DataSkill 13: Advanced data visualization techniques",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n[Resource 1: e.g., software download link, tutorial video, etc.]\n[Resource 2]\n[Resource 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 13: Advanced data visualization techniques"
    ]
  },
  {
    "objectID": "DataSkills/dataskills13.html#reflection-questions",
    "href": "DataSkills/dataskills13.html#reflection-questions",
    "title": "DataSkill 13: Advanced data visualization techniques",
    "section": "Reflection Questions",
    "text": "Reflection Questions\n\nHow might Advanced data visualization techniques enhance your research capabilities?\nWhat challenges did you face when learning about or applying Advanced data visualization techniques?\nHow could you integrate Advanced data visualization techniques into your current or future research projects?",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 13: Advanced data visualization techniques"
    ]
  },
  {
    "objectID": "DataSkills/dataskills10.html",
    "href": "DataSkills/dataskills10.html",
    "title": "DataSkill 10: Reflective Review of the first half",
    "section": "",
    "text": "This session focuses on Reflective Review of the first half and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 10: Reflective Review of the first half"
    ]
  },
  {
    "objectID": "DataSkills/dataskills10.html#skill-overview",
    "href": "DataSkills/dataskills10.html#skill-overview",
    "title": "DataSkill 10: Reflective Review of the first half",
    "section": "",
    "text": "This session focuses on Reflective Review of the first half and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 10: Reflective Review of the first half"
    ]
  },
  {
    "objectID": "DataSkills/dataskills10.html#learning-objectives",
    "href": "DataSkills/dataskills10.html#learning-objectives",
    "title": "DataSkill 10: Reflective Review of the first half",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this session, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 10: Reflective Review of the first half"
    ]
  },
  {
    "objectID": "DataSkills/dataskills10.html#key-concepts",
    "href": "DataSkills/dataskills10.html#key-concepts",
    "title": "DataSkill 10: Reflective Review of the first half",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 10: Reflective Review of the first half"
    ]
  },
  {
    "objectID": "DataSkills/dataskills10.html#practical-exercise",
    "href": "DataSkills/dataskills10.html#practical-exercise",
    "title": "DataSkill 10: Reflective Review of the first half",
    "section": "Practical Exercise",
    "text": "Practical Exercise\n[Brief description of a hands-on exercise related to Reflective Review of the first half]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 10: Reflective Review of the first half"
    ]
  },
  {
    "objectID": "DataSkills/dataskills10.html#tips-and-best-practices",
    "href": "DataSkills/dataskills10.html#tips-and-best-practices",
    "title": "DataSkill 10: Reflective Review of the first half",
    "section": "Tips and Best Practices",
    "text": "Tips and Best Practices\n\n[Tip 1]\n[Tip 2]\n[Tip 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 10: Reflective Review of the first half"
    ]
  },
  {
    "objectID": "DataSkills/dataskills10.html#additional-resources",
    "href": "DataSkills/dataskills10.html#additional-resources",
    "title": "DataSkill 10: Reflective Review of the first half",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n[Resource 1: e.g., software download link, tutorial video, etc.]\n[Resource 2]\n[Resource 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 10: Reflective Review of the first half"
    ]
  },
  {
    "objectID": "DataSkills/dataskills10.html#reflection-questions",
    "href": "DataSkills/dataskills10.html#reflection-questions",
    "title": "DataSkill 10: Reflective Review of the first half",
    "section": "Reflection Questions",
    "text": "Reflection Questions\n\nHow might Reflective Review of the first half enhance your research capabilities?\nWhat challenges did you face when learning about or applying Reflective Review of the first half?\nHow could you integrate Reflective Review of the first half into your current or future research projects?",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 10: Reflective Review of the first half"
    ]
  },
  {
    "objectID": "DataSkills/dataskills03.html",
    "href": "DataSkills/dataskills03.html",
    "title": "DataSkill 3: IPIP Open Source Questionnaires",
    "section": "",
    "text": "This session focuses on IPIP Open Source Questionnaires and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 3: IPIP Open Source Questionnaires"
    ]
  },
  {
    "objectID": "DataSkills/dataskills03.html#skill-overview",
    "href": "DataSkills/dataskills03.html#skill-overview",
    "title": "DataSkill 3: IPIP Open Source Questionnaires",
    "section": "",
    "text": "This session focuses on IPIP Open Source Questionnaires and its importance in psychological research.",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 3: IPIP Open Source Questionnaires"
    ]
  },
  {
    "objectID": "DataSkills/dataskills03.html#learning-objectives",
    "href": "DataSkills/dataskills03.html#learning-objectives",
    "title": "DataSkill 3: IPIP Open Source Questionnaires",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nAfter completing this session, you should be able to: 1. [Learning objective 1] 2. [Learning objective 2] 3. [Learning objective 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 3: IPIP Open Source Questionnaires"
    ]
  },
  {
    "objectID": "DataSkills/dataskills03.html#key-concepts",
    "href": "DataSkills/dataskills03.html#key-concepts",
    "title": "DataSkill 3: IPIP Open Source Questionnaires",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n[Key concept 1]\n[Key concept 2]\n[Key concept 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 3: IPIP Open Source Questionnaires"
    ]
  },
  {
    "objectID": "DataSkills/dataskills03.html#practical-exercise",
    "href": "DataSkills/dataskills03.html#practical-exercise",
    "title": "DataSkill 3: IPIP Open Source Questionnaires",
    "section": "Practical Exercise",
    "text": "Practical Exercise\n[Brief description of a hands-on exercise related to IPIP Open Source Questionnaires]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 3: IPIP Open Source Questionnaires"
    ]
  },
  {
    "objectID": "DataSkills/dataskills03.html#tips-and-best-practices",
    "href": "DataSkills/dataskills03.html#tips-and-best-practices",
    "title": "DataSkill 3: IPIP Open Source Questionnaires",
    "section": "Tips and Best Practices",
    "text": "Tips and Best Practices\n\n[Tip 1]\n[Tip 2]\n[Tip 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 3: IPIP Open Source Questionnaires"
    ]
  },
  {
    "objectID": "DataSkills/dataskills03.html#additional-resources",
    "href": "DataSkills/dataskills03.html#additional-resources",
    "title": "DataSkill 3: IPIP Open Source Questionnaires",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n[Resource 1: e.g., software download link, tutorial video, etc.]\n[Resource 2]\n[Resource 3]",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 3: IPIP Open Source Questionnaires"
    ]
  },
  {
    "objectID": "DataSkills/dataskills03.html#reflection-questions",
    "href": "DataSkills/dataskills03.html#reflection-questions",
    "title": "DataSkill 3: IPIP Open Source Questionnaires",
    "section": "Reflection Questions",
    "text": "Reflection Questions\n\nHow might IPIP Open Source Questionnaires enhance your research capabilities?\nWhat challenges did you face when learning about or applying IPIP Open Source Questionnaires?\nHow could you integrate IPIP Open Source Questionnaires into your current or future research projects?",
    "crumbs": [
      "Schedule",
      "Content",
      "DataSkills",
      "DataSkill 3: IPIP Open Source Questionnaires"
    ]
  },
  {
    "objectID": "week04/chapter.html",
    "href": "week04/chapter.html",
    "title": "Chapter 2 - Week 2 Stuff",
    "section": "",
    "text": "insert week 2 stuff",
    "crumbs": [
      "Schedule",
      "Content",
      "Week04",
      "Chapter 2 - Week 2 Stuff"
    ]
  },
  {
    "objectID": "week04/chapter.html#week-2-stuff",
    "href": "week04/chapter.html#week-2-stuff",
    "title": "Chapter 2 - Week 2 Stuff",
    "section": "",
    "text": "insert week 2 stuff",
    "crumbs": [
      "Schedule",
      "Content",
      "Week04",
      "Chapter 2 - Week 2 Stuff"
    ]
  },
  {
    "objectID": "webr.html",
    "href": "webr.html",
    "title": "webR in Quarto HTML Documents",
    "section": "",
    "text": "Each class session has an interactive lesson that you will work through after doing the readings and watching the lecture. These lessons are a central part of the class—they will teach you how to use {ggplot2} and other packages in the tidyverse to create beautiful and truthful visualizations with R.\nInteractive code sections look like this. Make changes in the text box and click on the green “Run Code” button to see the results. Sometimes there will be a tab with a hint or solution.\n\n\n\n\n\n\nYour turn\n\n\n\nModify the code here to show the relationship between health and wealth for 2002 instead of 2007.\n\n Interactive editor Hint\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nHint: You’ll want to change something in the code that creates gapminder_filtered. The text in the subtitle won’t change automatically, so you’ll want to edit that too.\n\n\n\n\n\nIf you’re curious how this works, each interactive code section uses the amazing {quarto-webr} package to run R directly in your browser.",
    "crumbs": [
      "Schedule",
      "Content",
      "webR in Quarto HTML Documents"
    ]
  },
  {
    "objectID": "week02/chapter 2.html",
    "href": "week02/chapter 2.html",
    "title": "Chapter 2 - Week 2 Stuff",
    "section": "",
    "text": "insert week 2 stuff",
    "crumbs": [
      "Schedule",
      "Content",
      "Week02",
      "Chapter 2 - Week 2 Stuff"
    ]
  },
  {
    "objectID": "week02/chapter 2.html#week-2-stuff",
    "href": "week02/chapter 2.html#week-2-stuff",
    "title": "Chapter 2 - Week 2 Stuff",
    "section": "",
    "text": "insert week 2 stuff",
    "crumbs": [
      "Schedule",
      "Content",
      "Week02",
      "Chapter 2 - Week 2 Stuff"
    ]
  },
  {
    "objectID": "week02/chapter.html",
    "href": "week02/chapter.html",
    "title": "Chapter 2 - Week 2 Stuff",
    "section": "",
    "text": "insert week 2 stuff",
    "crumbs": [
      "Schedule",
      "Content",
      "Week02",
      "Chapter 2 - Week 2 Stuff"
    ]
  },
  {
    "objectID": "week02/chapter.html#week-2-stuff",
    "href": "week02/chapter.html#week-2-stuff",
    "title": "Chapter 2 - Week 2 Stuff",
    "section": "",
    "text": "insert week 2 stuff",
    "crumbs": [
      "Schedule",
      "Content",
      "Week02",
      "Chapter 2 - Week 2 Stuff"
    ]
  }
]